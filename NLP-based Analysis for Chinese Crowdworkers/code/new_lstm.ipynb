{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import sys\n",
    "# reload(sys)\n",
    "from sklearn.model_selection import train_test_split\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "import gensim\n",
    "from keras.preprocessing import sequence\n",
    "from tensorflow.keras import Sequential, regularizers\n",
    "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dropout, Dense, Activation\n",
    "from keras.layers.core import Dense, Dropout,Activation\n",
    "from keras.models import model_from_yaml\n",
    "np.random.seed(1337)  # For Reproducibility\n",
    "import jieba\n",
    "import pandas as pd\n",
    "import sys\n",
    "from gensim.corpora import Dictionary\n",
    "sys.setrecursionlimit(1000000)\n",
    "# set parameters:\n",
    "vocab_dim = 100\n",
    "maxlen = 100\n",
    "n_iterations = 300  # ideally more..\n",
    "n_exposures = 10\n",
    "window_size = 7\n",
    "batch_size = 32\n",
    "n_epoch = 4\n",
    "input_length = 100\n",
    "cpu_count = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load training data\n",
    "neg = pd.read_csv('../data/neg.csv', header=None,encoding='gb18030')\n",
    "pos = pd.read_csv('../data/pos.csv', header=None,encoding='gb18030')\n",
    "\n",
    "combined=np.concatenate((pos[0], neg[0]))\n",
    "y = np.concatenate((np.ones(len(pos),dtype=int), np.zeros(len(neg),dtype=int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def negation_handling(words):\n",
    "    negations = {'不', '没', '无', '非', '莫', '未', '否'}\n",
    "    transformed_words = []\n",
    "    negate = False\n",
    "    for word in words:\n",
    "        if word in negations:\n",
    "            negate = not negate\n",
    "        else:\n",
    "            if negate:\n",
    "                transformed_words.append('NOT_' + word)\n",
    "            else:\n",
    "                transformed_words.append(word)\n",
    "            negate = False\n",
    "    return transformed_words\n",
    "def transition_handling(words):\n",
    "    transitions = {'但是', '然而', '可是', '不过','以前','现在'}\n",
    "    transformed_words = []\n",
    "    prefix = ''\n",
    "    for word in words:\n",
    "        if word in transitions:\n",
    "            prefix = 'BUT_'\n",
    "        else:\n",
    "            transformed_words.append(prefix + word)\n",
    "            prefix = ''\n",
    "    return transformed_words\n",
    "def tokenizer(text):\n",
    "    text = [jieba.lcut(document.replace('\\n', '')) for document in text]\n",
    "    text = [negation_handling(sentence) for sentence in text]\n",
    "    text = [transition_handling(sentence) for sentence in text]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train word2vec model\n",
    "def word2vec_train(combined):\n",
    "    model = gensim.models.Word2Vec(vector_size=100, min_count=10, window=7, workers=multiprocessing.cpu_count(),epochs=5)\n",
    "    model.build_vocab(combined)\n",
    "    model.train(combined, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "    model.save(\"lstm_word2vec.model\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_preprocessing import sequence\n",
    "from gensim.corpora import Dictionary\n",
    "def data_transformation(model=None, combined=None):\n",
    "    if (combined is not None) and (model is not None):\n",
    "        gensim_dict = Dictionary()\n",
    "        gensim_dict.add_documents([model.wv.key_to_index], prune_at=None)\n",
    "        w2indx = {v: k+1 for k, v in gensim_dict.items()} \n",
    "        w2vec = {word: model.wv.get_vector(word) for word in w2indx.keys()} \n",
    "        data = []\n",
    "        for sentence in combined:\n",
    "            new_txt = []\n",
    "            for word in sentence:\n",
    "                try:\n",
    "                    new_txt.append(w2indx[word])\n",
    "                except:\n",
    "                    new_txt.append(0)\n",
    "            data.append(new_txt)\n",
    "        combined = data\n",
    "        combined = sequence.pad_sequences(combined, maxlen=maxlen)\n",
    "    else:\n",
    "        print('No data provided...')\n",
    "    n_symbols = len(w2indx) + 1  # 所有单词的索引数，频数小于10的词语索引为0，所以加1\n",
    "    embedding_weights = np.zeros((n_symbols, vocab_dim))#索引为0的词语，词向量全为0\n",
    "    for word, index in w2indx.items():#从索引为1的词语开始，对每个词语对应其词向量\n",
    "        embedding_weights[index, :] = w2vec[word]\n",
    "    return n_symbols, embedding_weights, w2indx, w2vec, combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Bidirectional, Flatten\n",
    "from keras_self_attention import SeqSelfAttention\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "##定义网络结构\n",
    "def build_lstm(n_symbols, embedding_weights, x_train, y_train, x_test, y_test):\n",
    "    print('Defining an Attention-based Keras Model...')\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(output_dim=vocab_dim,\n",
    "                        input_dim=n_symbols,\n",
    "                        mask_zero=True,\n",
    "                        weights=[embedding_weights],\n",
    "                        input_length=input_length))\n",
    "\n",
    "    # 添加双向 LSTM\n",
    "    #model.add(Bidirectional(LSTM(units=100, activation='tanh', return_sequences=True, kernel_regularizer=regularizers.l2(1e-6))))\n",
    "    model.add(LSTM(units=100, activation='sigmoid',recurrent_activation='hard_sigmoid'))\n",
    "\n",
    "    # 添加注意力层\n",
    "    # model.add(SeqSelfAttention(attention_type=SeqSelfAttention.ATTENTION_TYPE_MUL,\n",
    "                            #    kernel_regularizer=regularizers.l2(1e-6),\n",
    "                            #    bias_regularizer=regularizers.l1(1e-4),\n",
    "                            #    attention_regularizer_weight=1e-4,\n",
    "                            #    name='Attention'))\n",
    "    \n",
    "    model.add(Dropout(0.5))\n",
    "    # 添加全连接层\n",
    "    # model.add(Flatten())\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "\n",
    "    print('Compiling the Model...')\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    print(\"Train...\")\n",
    "    #early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "    history = model.fit(x_train, y_train, batch_size=batch_size, epochs=n_epoch, verbose=1, validation_data=(x_test, y_test))\n",
    "\n",
    "    \n",
    "    print(\"Evaluate...\")\n",
    "    score = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
    "\n",
    "    # 绘制训练和验证的损失值和准确率\n",
    "    plot_history(history)\n",
    "\n",
    "    model.save('attention_lstm.h5')\n",
    "    print('Test score:', score)\n",
    "\n",
    "def plot_history(history):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model Loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defining an Attention-based Keras Model...\n",
      "Compiling the Model...\n",
      "Train...\n",
      "Epoch 1/4\n",
      "528/528 [==============================] - 36s 66ms/step - loss: 0.5586 - accuracy: 0.7057 - val_loss: 0.3637 - val_accuracy: 0.8591\n",
      "Epoch 2/4\n",
      "528/528 [==============================] - 35s 65ms/step - loss: 0.3114 - accuracy: 0.8797 - val_loss: 0.2494 - val_accuracy: 0.9051\n",
      "Epoch 3/4\n",
      "528/528 [==============================] - 35s 66ms/step - loss: 0.2063 - accuracy: 0.9286 - val_loss: 0.2200 - val_accuracy: 0.9160\n",
      "Epoch 4/4\n",
      "528/528 [==============================] - 35s 66ms/step - loss: 0.1499 - accuracy: 0.9502 - val_loss: 0.2158 - val_accuracy: 0.9219\n",
      "Evaluate...\n",
      "132/132 [==============================] - 2s 13ms/step - loss: 0.2158 - accuracy: 0.9219\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: [0.21584074199199677, 0.921875]\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(data_transformation(word2vec_train(tokenizer(combined)),tokenizer(combined))[4], y, test_size=0.2, random_state=42)\n",
    "n_symbols,embedding_weights = data_transformation(word2vec_train(tokenizer(combined)),tokenizer(combined))[0:2]\n",
    "build_lstm(n_symbols,embedding_weights,x_train,y_train,x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 2s 13ms/step\n",
      "Accuracy: 0.9219\n",
      "Precision: 0.9130\n",
      "Recall: 0.9366\n",
      "F1 Score: 0.9247\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "model = load_model('attention_lstm.h5')\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_binary = np.round(y_pred).astype(int)\n",
    "accuracy = accuracy_score(y_test, y_pred_binary)\n",
    "precision = precision_score(y_test, y_pred_binary)\n",
    "recall = recall_score(y_test, y_pred_binary)\n",
    "f1 = f1_score(y_test, y_pred_binary)\n",
    "print(\"Accuracy: {:.4f}\".format(accuracy))\n",
    "print(\"Precision: {:.4f}\".format(precision))\n",
    "print(\"Recall: {:.4f}\".format(recall))\n",
    "print(\"F1 Score: {:.4f}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_transform(string):\n",
    "    words=jieba.lcut(string)\n",
    "    words=np.array(words).reshape(1,-1)\n",
    "    model=gensim.models.Word2Vec.load(\"lstm_word2vec.model\")\n",
    "    combined = data_transformation(model,words)[4]\n",
    "    return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "def lstm_predict(string):\n",
    "    print('loading model......')\n",
    "    model = load_model('lstm.h5')\n",
    "    print('loading weights......')\n",
    "    model.load_weights('lstm.h5')\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                    optimizer='adam',metrics=['accuracy'])\n",
    "    data = input_transform(string)\n",
    "    data.reshape(1,-1)\n",
    "    result = model.predict(data)\n",
    "    threshold = 0.5\n",
    "    predicted_labels = np.zeros_like(result)\n",
    "    predicted_labels[result >= threshold] = 1\n",
    "    return predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model......\n",
      "loading weights......\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x2c27dc3a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 93ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.]], dtype=float32)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string = '我不知道你们为什么要喷八戒？八戒的项目不够好吗？收的钱还不够少吗？客服态度不够好吗？我的项目在八戒上就运行的不错，才被坑10来万而已！'\n",
    "lstm_predict(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>内容</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>八戒，陪你玩了7年了，感觉你现在眼里除了钱就是钱，我们像是被你锁在笼子里开膛破肚取胆汁的月熊...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>哎 现在想进入其实不是好时候了</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>打算进去做推广 看见现在这版面 直接退出了</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>猪八戒已经不是以前的猪八戒，唯利是图</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>是的..猪八戒现在就是个LJ...我也离开了...以前还是挺感激猪八戒的..也赚到了第一桶金...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1197</th>\n",
       "      <td>然后细心看了一下那个雇主的任务，所有交稿的人都不合格！！虽然没去看其他人的稿子有没有用过，但...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1198</th>\n",
       "      <td>我又看了看这个人的资料，他提出的需求中，别人交稿的基本上没几个是合格的。所以说，这个人骗人已...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199</th>\n",
       "      <td>所以，建议大家在猪八戒做任务的时候注意一些无良雇主。第一，不要看着价格高点儿就做，有些时候很...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1200</th>\n",
       "      <td>自言自语了这么多，说出来就舒坦些了。但愿对大家有些帮助，谨防骗子！！！</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1201</th>\n",
       "      <td>还是蛮多的，现在官方都在考虑雇主，却很少考虑到一些小服务商的利益，时间精力很多都白搭</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1202 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     内容\n",
       "0     八戒，陪你玩了7年了，感觉你现在眼里除了钱就是钱，我们像是被你锁在笼子里开膛破肚取胆汁的月熊...\n",
       "1                                       哎 现在想进入其实不是好时候了\n",
       "2                                 打算进去做推广 看见现在这版面 直接退出了\n",
       "3                                    猪八戒已经不是以前的猪八戒，唯利是图\n",
       "4     是的..猪八戒现在就是个LJ...我也离开了...以前还是挺感激猪八戒的..也赚到了第一桶金...\n",
       "...                                                 ...\n",
       "1197  然后细心看了一下那个雇主的任务，所有交稿的人都不合格！！虽然没去看其他人的稿子有没有用过，但...\n",
       "1198  我又看了看这个人的资料，他提出的需求中，别人交稿的基本上没几个是合格的。所以说，这个人骗人已...\n",
       "1199  所以，建议大家在猪八戒做任务的时候注意一些无良雇主。第一，不要看着价格高点儿就做，有些时候很...\n",
       "1200                自言自语了这么多，说出来就舒坦些了。但愿对大家有些帮助，谨防骗子！！！\n",
       "1201         还是蛮多的，现在官方都在考虑雇主，却很少考虑到一些小服务商的利益，时间精力很多都白搭\n",
       "\n",
       "[1202 rows x 1 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zbj = pd.read_csv('../data/zbj_new.csv',encoding='utf-8')\n",
    "zbj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 312ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 104ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 104ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 104ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 104ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 104ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 154ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 104ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "loading model......\n",
      "loading weights......\n",
      "1/1 [==============================] - 0s 114ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'八戒，陪你玩了7年了，感觉你现在眼里除了钱就是钱，我们像是被你锁在笼子里开膛破肚取胆汁的月熊，你总是喂不饱，但我们却越来越痛苦，一路走来，你每改一次版就走一批服务商，现在身边的那些老牌的，有实力的基本都看不到了，全部都是新面孔，今年的规则你们做的这么绝，我打算也不陪你玩了，玩不起，也好累，当然，你并不会在乎，各自安好吧。我并不想骂你，毕竟你以前是那么优秀并且给了我们小服务商那么多机会。足矣！': array([0.], dtype=float32),\n",
       " '哎 现在想进入其实不是好时候了': array([0.], dtype=float32),\n",
       " '打算进去做推广 看见现在这版面 直接退出了': array([0.], dtype=float32),\n",
       " '猪八戒已经不是以前的猪八戒，唯利是图': array([0.], dtype=float32),\n",
       " '是的..猪八戒现在就是个LJ...我也离开了...以前还是挺感激猪八戒的..也赚到了第一桶金...现在粉转黑了..': array([0.], dtype=float32),\n",
       " '我干八戒四年了，现在看到八戒也很恶心，就是希望十天后一万的保证金能退出来！以后别恶心我们服务商了！': array([0.], dtype=float32),\n",
       " '唉，中介费这么高，感觉现在就是一个坑啊': array([0.], dtype=float32),\n",
       " '已退坑！！': array([0.], dtype=float32),\n",
       " '抓八戒是怎么活下来的，全是要钱要钱要钱，我是真的服了，刚才打开猪八戒一看，全是钱钱钱钱。要脸不要！': array([0.], dtype=float32),\n",
       " '刚开始的时候，后来越来越不把设计师当人看，早就退坑了': array([0.], dtype=float32),\n",
       " '曝光猪八戒网上的一个服务商，河南千真信息科技有限公司和河南扬名网络科技有限公司是同一个公司，9天工期，半年没给我交付，强行不退款，强行拿其他软件顶我的项目金。猪八戒官方一再包庇，说我证据不足？我天，那签合同都不顶用的吗？9天工期，半年没交付我，还***证据不足，猪八戒吃相太难看了。《重庆晚报》出身的董事长果然不同常人啊。': array([0.], dtype=float32),\n",
       " '弱弱的问一句，怎么举报猪八戒这个平台啊，至少怎么能让它下架。双方收钱，猪八戒的吃相太难看了！': array([0.], dtype=float32),\n",
       " '猪八戒平台的确存在欺诈行为，付了20000元，拖了几个月，什么结果都没交付钱一分都不退，是有八戒平台内部操作。': array([0.], dtype=float32),\n",
       " '猪八戒算是最大的骗子平台了，他们太偏向服务商了，发起合同，说服务商没签。一大堆理由就是不退款。同时想说下以后大家在网上找设计，装修什么的千万不要选择广州聚图设计，我是体验过的有多么坑人与垃圾。如果你们有不信的可以去试试。': array([0.], dtype=float32),\n",
       " '我也被猪八戒网骗了，担保注册商标，不成功全额退款，打款显示几个月时间了就是不退款，一直以反馈也借口，得不到任何解决，我也在找方法投诉举报': array([0.], dtype=float32),\n",
       " '确实恶心的一笔，坑比平台': array([0.], dtype=float32),\n",
       " '这不挺好的嘛？没这些东西怎么衰败下去呢？': array([0.], dtype=float32),\n",
       " '我们交了钱的！~都投不了标！真是坑！': array([0.], dtype=float32),\n",
       " '现在我看单子都没人投了，估计过一阵还会改成免费投标的模式。因为有很多单子质量很差，花30投标真的很不值得。这种杀鸡取卵的方式肯定会失败的。': array([0.], dtype=float32),\n",
       " '投标 一年了  打电话 不知道打过多少  不是说已经找到人了  就是说 不做了  ，问客服，客服说那是因为投标的单子都是先派送给花钱的服务商，返送几次没谈成然后在施舍性的发布出去，之前买过3600一年的八戒通  最后到期  就投标中过一次500 单子   ，这样算下来赔了3000多 不算电话费。有快半年没上猪八戒 今天上去投标还投标不了，一个300的标 投标需要话30多，即使想花30多还不行，前提是要交6000年费卡 才能花30买一次投标机会，然后投标上了打电话对方说不做了。': array([0.], dtype=float32),\n",
       " '现在收20%手续费太高了，之前收10% ，去年花6000加入八戒通收2%，后来八戒通不卖了，改成银卡，还是要6000，可投标还要花钱，一个标都是几十个机会豆，几十块钱投个标，质量还不咋地。这开通有啥意义，不缴纳保证金，不开通银卡及以上，出售的服务别人都找不到，太**坑了，杀鸡取卵， 没良心的企业。不知道缴纳多少钱才能喂得饱。': array([0.], dtype=float32),\n",
       " '不知说啥了，杀鸡取卵，简直了。。。': array([0.], dtype=float32),\n",
       " '打投诉电话了，客服态度还一副“规则就是这样的你能咋地”的态度。投诉无门。这样简直是不给服务商活路了。说投标10个成一个那还是好的，我这软件开发投30个能成一个都算大吉大利了！': array([0.], dtype=float32),\n",
       " '急切希望有个其它类似网站出来消灭猪八戒，这个网站老板人品不行，走不长久。': array([0.], dtype=float32),\n",
       " '快凉了~~！！猪八戒网快凉了！不得民心，赶紧退钱吧~！': array([0.], dtype=float32),\n",
       " '祝猪八戒早日凉凉': array([1.], dtype=float32),\n",
       " '不敢交了……本来就是兼职来做……怕赔里边……网站的规则不知道变了多少回了……每次都有新花样，但是圈钱从未变过……': array([0.], dtype=float32),\n",
       " '开始会员按月收费，一个月几百块钱，接完任务再扣手续费、税金。虽然黑，但是还给大家留点汤。现在倒好，汤汁都没了。做个任务，活干完了，商家不付款。猪八戒客服也不管。钱就在猪八戒上压着。真是一幅死猪不怕开水烫的嘴脸。谁拿钱就是大爷，有奶便是娘。把那些辛辛苦苦干活的当什么了？真是爹累死了，有娘在就行是吧。。。': array([0.], dtype=float32),\n",
       " '猪八戒合伙人，是一个巨坑！！！！！猪八戒合伙人里面分销，分销的收益为猪豆，10猪豆 = 1元刚开始签署合伙人时，业务人员告诉我，可以发展下线分销，下线分销以猪豆奖励，并告知分销可以自行兑换猪豆获得收益！坑爹的来了，半年后（2018年6月份）被告知所有猪豆将清零！纳尼！！！！这也会清零，就好像老板给你工资卡打工资，某天和你说“你工资卡里面的工资还不取出来就会被收回”一样！好吧，既然你说要清零，那就兑换成现金吧，天坑出现了！当分销商兑换猪豆时告知，必须签约城市合伙人才能兑换，千万匹****在奔腾！！！！！意味着什么，意味着分销用户白白的干了半年，你好不容易推荐几个朋友注册了商标，你得了几百的猪豆，等兑现时告知你要充5000元签约城市合伙人！那城市合伙人的意义在哪里呢?一个公司有10个人，总经理签了城市合伙人，把9个同事纳入到分销，总经理没出去跑业务，业务为0，其他9个同事每个人跑了40000猪豆的业务(相当于4000元)，等兑换成现金时，告诉你只有你们总经理能兑换，你们其他人不能兑换，如果要兑换每个人都要交5000元签约成合伙人！那总经理签合伙人的意义在哪？': array([0.], dtype=float32),\n",
       " '猪八戒五年老店，曾做到板块内收入排名第一。现在对八戒网很失望，准备正式脱离猪八戒网。现在本来成交量就不高，还要交1万的诚信金，近期的小单的收入也被你们冻结三个月，我们服务商只能呵呵了。。一个单本来就千把来块钱。。你们还要收这么高的诚信金。。再见了，猪八戒网~！一个到处圈钱的网站~！': array([0.], dtype=float32),\n",
       " '你太天真了，你以为只有开通银卡的6000元么？开完银卡，还有5000元保证金，平台给你托管1000，自己还需要付款4000托管。正常开通银卡，整个下来要1W。新的需求大厅就是一个新坑，等服务商来跳。投标一次40-10元。同时满足2个条件，1是推出竞标，2是必须是认定需求与实际不匹配，才可以申请退钱。否则是不会给你退钱的，模式可以参考，赌石。平台服务费10%，广告费看你准不准备做，不投广告，基本没生意，开不开卡都一样。': array([0.], dtype=float32),\n",
       " '我今天也刚申请退出保证金了了··以前能投稿都接不到几个单~~现在还要6000的最低年消费~~呵呵哒~~交钱可以~你得让我看到收益~看不到收益你还追加费用~~也是**的不行了~~~': array([0.], dtype=float32),\n",
       " '感觉这网站有点背离了自己的初心，说直白点，现在的吃相比以往这么多年来讲，更加难看。我做了十来年了，我想我还是有这个资格聊这个东西。这个平台最早是希望你们来，而且什么都不花钱。到现在，它一天到晚改版，变着法子搞一些收费项目。17年的悬赏通，一万多一年，我买了，说变就变，都不用跟服务商打招呼的，改成了众包，就是客户花钱买盲盒的模式，开20个稿，花一笔钱，然后看中了某一个，再花钱买原文件。后来猪网自己都玩不下去了，好了一两年，现在这个比稿付费好像是从十一月份开始上线的，不便宜啊，投一个稿，自己费时费力还要花钱，要合到一块多一单。初次购买会打折，二次购买会提示你不是首次购的服务商，花费会更高。这个我也不说了，确实有点黑，当年是鼓励自主创业，给予有一技之长的人在家通过自己的劳动也可以挣到钱，现在倒好了，你平台后面的老板也要扪心自问一下了，要不要这么吸血。我比稿的钱投了，还时常碰到一些假任务需求，或者是客诉退款的需求，我们个体服务商的保障又在哪里？': array([0.], dtype=float32),\n",
       " '好多这种，就跟闹着玩似的。花了不少冤枉钱，弃标打赏为极少数，能拿到打赏，都是人为操控，有点类似于滴滴杀熟。': array([0.], dtype=float32),\n",
       " '这兼职，各种信息差，资质啥的。本质上就很难搞。加上内卷，平台运营接单能力，模式。危地勿留。': array([0.], dtype=float32),\n",
       " '比稿本来就是小概率成单，付出心血没有回报，自己也没话说！如今比稿也要收费，而且最少要充50元，还一个月有效，本来就是有时间了做做看，一个月也不见得会去做，这种付费不就是打水漂': array([0.], dtype=float32),\n",
       " '投标后，给顾客打电话，对方不接，打了三次全部拒接，然后发短信也不回复，花了快20元投标': array([0.], dtype=float32),\n",
       " '个人感觉猪八戒就此走上灭亡路': array([0.], dtype=float32),\n",
       " '好生气啊 半年多没上了 今天说做点任务挣点零花钱  费了两天功夫做完一个海报  交稿提示让花钱  好生气  能选上也行  问题是选不上的话交稿费就打水漂了呗  无语 现在拿着一个做好的东西不知道怎么让雇主看到  无语 浪费感情': array([0.], dtype=float32),\n",
       " '我做十二年了 从去年年底改收费之后买了一次它们所谓的比稿易 结果基本没中啥标 投入时间长了反而受益没了 所以早就弃坑了 这网站现在内卷严重 各种黑洞等着填补 真的离倒闭破产没多远了': array([0.], dtype=float32),\n",
       " '猪八戒网同一品威客、时间财富网、汇图网等现在比起来在比稿任务排列优化方面可以说是最差的了，汇图网比稿任务排列有个截止时间选项，时间财富网则是快结束选项，一品威客比稿任务排列则有个投稿到期选项，基本上都是让参加任务威客可以优先做快结束的任务，最高效节省安排自己的时间，而猪八戒在比稿任务排列则根本看不到这个类似选项，确实是很奇葩，不知道网页设计人员心里是怎么在想事情，根本不从参加任务威客的角度思考问题。更奇怪的事，有些比稿任务打开时已经选出了中标任务，这样的任务还放在任务列表中是准备浪费参加任务威客时间用的吗？相比而言一品威客、时间财富网在这方面做的人性化多了，已参加了的任务都会显示出已参与。现在的猪八戒网比稿任务参加还开始收费了，哪怕雇主最后申请退款参加费用也不会退，各方面都不如以前了，在威客网站中还能领先多久？………': array([0.], dtype=float32),\n",
       " '我有问题，我也发现这个软件现在在坑钱了，所以有没有什么别的找兼职的网站或是软件推荐？？': array([0.], dtype=float32),\n",
       " '再次提价，现在大环境这么不好，疫情等等，都不知道说什么好了，这吃相。。原来的C套餐是128，现在又直接上涨了20元。这玩意真是单方面口嗨说涨就涨吗？从0费用，到一次又一次的明面上说升级产品，实际上就是搞钱。还有就是，这个贴吧全是工作人员自问自答，水军一堆全一级小号，大家不要相信。你发个负面的，他就发很多其它内容顶下去。这个吧90%的内容都是假大空，只有这个吧的吧主，是真网友，他是这个吧的最后一道防线了。': array([0.], dtype=float32),\n",
       " '我是2008年猪八戒网刚开始起步就开始做猪八戒设计了，起初是很好做的，收入也累计达到了几十个W，现在已经放弃了，各种想着法子收费，以前是任务可靠而且基本不额外收费（当然20%的佣金平台是一直在收的）。': array([1.], dtype=float32),\n",
       " '现在投个标改成用商机豆了，投一个标少的也要三四十块钱，还有很多标要100多块，真是想钱想疯了吧？关键你投了标还不一定中，猪八戒现在吃相越来越难看了，我已经放弃这个平台了': array([0.], dtype=float32),\n",
       " '我们公司是猪八戒网长期客户了，这次八八节才下单几项服务，今年活动力度太大了': array([0.], dtype=float32),\n",
       " '在猪八戒网上找服务的人还是蛮多的，服务种类多，可供选择性强。': array([1.], dtype=float32),\n",
       " '服务有保障，值得信任': array([1.], dtype=float32),\n",
       " '对于一个企业服务是否怎样，我只能中肯的说出我的看法。  处于悖论之中的猪八戒网，我是觉得他们的服务是可以的，虽然有很多人在吐槽说猪八戒网各各地方的不好，但不能否认的是猪八戒网一直在盈利，哪怕在经济困难的2020年。可能那些骂声就是吃不到葡萄说葡萄酸吧。': array([0.], dtype=float32),\n",
       " '我最初开始用猪八戒网，是因为我想找兼职。我大学学的是商务英语专业的，我把能考的专业证都考到手了，我就想着在闲暇时光做一点翻译文章的兼职。对于翻译这个职业我是很有底气，但当时就在烦恼找兼职没有渠道。那时是一个跟我同专业比我大两届的学长，给我推荐这个网站。说他就是在这个这个网站找到的兼职，上面的招聘信息有很多，并且会进行实时更新。那是我第一次接触这个网站，网站确实和学长说的那样，招聘信息有很多。然后我看中了一个对景点简介和详细介绍的的翻译的单子。并按照规定的时间内完成了任务。我也得到我应有的报酬。这整个过程比我想象的要正规和安全，完全没有套路。而且，我发现互联网对人才的需求量还是很多的。我在大学期间。做翻译文章挣的钱正好能补贴我的生活费。我每次接的兼职甲方都没有拖欠工资或者故意拖延结算。这我感到非常有安全感。我大学毕业之后。找到第一份工作就是在这个网站上找的。我被一家公司招聘做翻译，偶尔也会和领导一起出差做涉外商务谈判工作。我们公司有时需要拟合同或者要用一些PPT的平面设计。会把任务发布在这个网站上。就会有人来投稿，经我们筛选。我的兼职和我的工作都是在这个网站上找的。都还是挺不错的。服务还是很到位的。': array([1.], dtype=float32),\n",
       " '我朋友一直在用猪八戒网发布一些招聘信息，他在公司是做设计的，经常会有很多单子堆在一起做不完，但是他说用了猪八戒网站的招聘平台之后，再也不怕任务堆成山了，跟老板那边也好交差。猪八戒网站对于有需求的企业来说服务还是很好的，可以直接在平台上与应聘者沟通，尤其是今年的八八节打折力度很大，有专门为企业设置的特惠服务，全场两折起，能比平常优惠很多。网站上的人才质量也都很高，我朋友说用过这么多回，每回兼职者交回来的作品质量都很不错，在老板跟前儿也经常受到表扬。去年因为疫情我也待业在家，朋友就把猪八戒网推荐给了我。他说很多企业都会在这个网站上找求职者，让我可以注册一个看看。本身我以前就是做文案编辑、设计的，看了一眼这个平台关于这类的需求挺多的，就注册可以了。令人没想到的是猪八戒网对于兼职者也很友好，兼职网页一目了然，八八节的是也有关于求职者的培训费，疫情期间全指望着它赚一点生活费了。': array([1.], dtype=float32),\n",
       " '猪八戒吃相难看我是受害者': array([0.], dtype=float32),\n",
       " '是个坑谁入谁知道': array([0.], dtype=float32),\n",
       " '2月26日我们经过第三方平台猪八戒网签署了开发合同并于当天支付了两万元定金。 2022年3月4日我和开发者沟通是否能够提前完成开发任务，经过商讨开发者同意提前八天(2022年3月18日）完成任务，前提条件是我在预付8千元并在任务完成后额外支付五千元，意见达成一致。 2022年3月12日我询问是否完成任务。开发者回应还在测试。一直到3月18日中午12点我一直在催促开发者，他也以各种理由推脱不予交付软件。自2022年3月12日以后对方就再也没有回复过. 2022年3月21日我向猪八戒网客服申请介入处理，客服回应只能尽量联系对方，猪八戒网可以出具开发者账号实名注册信息以供调查，我于3月21日当天向猪八戒网以邮件形式发送申请披露账号实名认证信息。 现在我对对方进行了起诉，法院要求平台出具被告未完成任务证明和资金流向证明，我随后咨询猪八戒客服，客服回应猪八戒平台没有出这个证明的业务无法协助。 总之猪八戒平台就是只收钱出了问题被骗不管，能联系对方赔偿他就打几个电话，电话打不通的就不管了你想怎么办怎么办。 希望大家多加小心': array([0.], dtype=float32),\n",
       " '我们现在在对猪八戒维权': array([0.], dtype=float32),\n",
       " '我交了1580担保注册商标都1年多了也不见商标也不退钱闹心把猪八戒当大平台结果闹心': array([0.], dtype=float32),\n",
       " '我们公司注册就是找的猪八戒，挺靠谱的，流程这些也很快。': array([0.], dtype=float32),\n",
       " '大部分代理都是靠谱的': array([0.], dtype=float32),\n",
       " '靠不靠谱还是看平台吧，像猪八戒网这样运营了十多年的大平台，里面代理注册的靠谱程度已经比其他很多地方高了。': array([0.], dtype=float32),\n",
       " '找正规且售后流程完整的平台进行代理注册还是挺靠谱的，我当时就是找猪八戒网代理注册的，就是看中这个平台比较出名，整个注册过程也很速度，当时也向相关的对接人员请教了很多问题，少走了很多弯路。': array([0.], dtype=float32),\n",
       " '猪八戒商业诈骗，每次改版之前就让服务商狠狠购买一波之前得产品，然后就立马降权，出新的产品，那么你想要继续做，你就必须继续买，不买就降权，你之前买的根本没有任何流量，之前做的得保障完全视若无睹': array([0.], dtype=float32),\n",
       " '抖音发起让更多人知道别上当了，我已上当！我到处发帖知道给我退钱': array([0.], dtype=float32),\n",
       " '天天违法骗钱，仗着政府撑腰，': array([0.], dtype=float32),\n",
       " '猪八戒网存在欺骗消费者行为，消费者的权利得不到保护，猪八戒纵容那些可恶的骗子服务商在上面接任务赚钱，服务商抄袭别人作品来赚钱，也不管，服务商睁着眼说瞎话，仗着猪八戒网的漏洞，肆意的骗取他人钱财，其心可诛！！！！！': array([0.], dtype=float32),\n",
       " '一个猪八戒号称什么领导的员工，猪八戒的客服永远不懂得尊重客户，和百度和阿里那些客服比，猪八戒的员工一个个就像大爷一样，反正就对你说爱怎么样怎么样，反正我们没办法，你有本事告我去，客服都能把你给气死了，猪八戒早点倒闭': array([0.], dtype=float32),\n",
       " '我想问一下，上边假标那么多，也不处理一下，天天在干什么': array([0.], dtype=float32),\n",
       " '难道都不审核吗？还是说为了签单，内部投的': array([0.], dtype=float32),\n",
       " '猪八戒就是一个诈骗犯聚集地请大家注意事件开始是2022年2月26日  我与猪八戒的一个服务商达成协议开发软件  软件总金额5万元，定金2万元，开发周期一个月。到了3月8号的时候由于时间紧迫我就申请能不能加急做，服务商同意，但是需要加8000元定金，我就同意了到了3月18日验收的时候服务商电话不接   微信不回 平台也不回复消息  我就提交了申诉客服告诉我  现在服务商的平台账户里边没有钱赔付，而且我支付的钱也已经被提现了。事件总结第一步我支付了28000元第二步服务商提现了28000元第三步服务商用朋友的账号发起了雇佣任务，两天后用朋友的账户发起了申诉把这个8000元保证金此时 服务商账户里就一分钱没有了  到我申诉的时候就无法赔付了而且猪八戒平台无法处理  需要法院处理  这时候猪八戒平台会向你提供证据合同一些文件，需要收费3000元总值 你被骗了猪八戒不管，想要证据也行 给钱': array([0.], dtype=float32),\n",
       " '猪八戒吃相太难看抖音发起让更多人知道': array([0.], dtype=float32),\n",
       " '首先现在弄了一个筋斗云，吃相太难看，相比以前，单子的质量大大下降！另外费用要比以前高，成交一个订单，费用比以前要高出三到五倍！改版之后，给分类！以前所有订单可以看到，可以接！但是现在，即使你花钱订阅多个，也只能看到一个类的！说是让客户自己切换（挺麻烦的，耽误事），你不觉得这样设计sb嘛！既然人家花钱订阅了，就应该让人家正常的看到！总之现在改版之后，订单质量垃圾多了，费用比原来高出了好几倍！这就是你们销售说的筛选后的好单子。。。。。': array([0.], dtype=float32),\n",
       " '根本就接不到。还浪费钱': array([0.], dtype=float32),\n",
       " '就是猪八戒网的一个促销活动，每年八月左右就会开启，已经连续创办七年了吧，活动力度还蛮大的，入口就在猪八戒网官网首页，很明显。': array([1.], dtype=float32),\n",
       " '其实我也是刚知道八八节这个东西，刚去活动页面看了看，针对企业的各种服务应有尽有，比如知识产权、工商财税、品牌设计、营销推广等等）、还有针对初创企业推出的八戒创业管家、针对个人推出的兼职易产品等。还有很多服务，具体的你可以去活动页面看看。': array([0.], dtype=float32),\n",
       " '购买过猪八戒网的一些服务，这次八八节对比了下价格，确实划算了很多，而且还有抽奖福利，不过购买的是刚需，而且交给猪八戒网也省心不少，如果这段时间正好有需求的，一定不要错过这个机会。': array([1.], dtype=float32),\n",
       " '是的，越来越坑了，感觉这个网站应该是穷途末路了。现在投稿的人少了很多': array([1.], dtype=float32),\n",
       " '这个主要得看你的个人能力了，如果你自己愿意动脑子，愿意参与竞争，能力水平又比较出色的，比稿往往挣到的回报还是挺可观的，我之前在比稿大厅中一次就2000多，一个月两单就很舒服了，不过我是兼职，全职的话如果你个人能力较强还是比较吃香的。': array([1.], dtype=float32),\n",
       " '大小单子都接过，不过我是兼职，小单最少也有好几百吧，只要愿意做，一个月几单下来，收入还是蛮可观的。': array([1.], dtype=float32),\n",
       " '事件开始是2022年2月26日  我与猪八戒的一个服务商达成协议开发软件  软件总金额5万元，定金2万元，开发周期一个月。到了3月8号的时候由于时间紧迫我就申请能不能加急做，服务商同意，但是需要加8000元定金，我就同意了到了3月18日验收的时候服务商电话不接   微信不回 平台也不回复消息  我就提交了申诉客服告诉我  现在服务商的平台账户里边没有钱赔付，而且我支付的钱也已经被提现了。事件总结第一步我支付了28000元第二步服务商提现了28000元第三步服务商用朋友的账号发起了雇佣任务，两天后用朋友的账户发起了申诉把这个8000元保证金此时 服务商账户里就一分钱没有了  到我申诉的时候就无法赔付了而且猪八戒平台无法处理  需要法院处理  这时候猪八戒平台会向你提供证据合同一些文件，需要收费3000元总值 你被骗了猪八戒不管，想要证据也行 给钱': array([0.], dtype=float32),\n",
       " '在猪八戒网接单有2年了。如果楼主是新人的话，建议还是去交易大厅。交易大厅里的雇主一般对服务的要求不高，你可以先去里面试试水。交易大厅里面有好几种交易方式，应该是招标、比稿、计件还有大赛，好像还有雇佣。对于新人的话，建议先从比稿做起吧。这个交易模式门槛低，操作起来也很简单，只要你作品好，雇主就很大几率会选择你。。其它的感兴趣你可以了解一下，感觉自己的可以的话可以去也可以去试试。': array([1.], dtype=float32),\n",
       " '3年接单经验、2年入驻商家路过。先说说怎么接单吧。首先进入官网，然后登录。登录之后有个实名认证，实名认证可以跳过，但是我建议是完成认证。因为大多数单都是要求接单的人完成实名认证，提现的是时候只有实名认证了才能提到自己的账号上。而且毕竟雇主肯定看到实名认证的人有安全感。你不认证别人怎么敢把单子交给你呀。实名认证环节结束后，进入交易中心里的任务大厅。任务大厅里你就可以根据你的选择来筛选一些单子了。只要你符合雇主的要求，你就可以投标。中不中标就看你的实力和运气了。任务大厅里有5种交易模式，其中招标是对新手最友好的了。所以建议楼主先去招标那里试试水，积攒一些服务经验。之后在去其它模式。不同的服务适用于不同的交易模式，这个你在猪八戒网待久了就会发现的。我建议你刚开始可以接一下要求较低的单，虽然佣金可能不算高吧，但是贵在能成。不过你要是行业大牛，就当我没说。我当初是接的UI设计，小白一个，一步一步做，边做边学，不过也算顺利，在猪八戒网上赚了不少钱，现在我也已经入驻成为商家了。': array([1.], dtype=float32),\n",
       " '我来！在猪八戒开了3年店铺，之前接了2年的单。简单说一下吧。我建议小白先从招标模式下开始。因为招标是所有交易模式中最简单、要求最低的一种。赚外快的话是一定可以满足的，如果想多赚一些，一定要边做边学，不断提升自己的能力，完善对猪八戒的了解。在能力提升之后，你可以在比稿、计件等交易模式里交易，这样接的单子不就多了么。比稿和计件了解吧？比稿就是比比谁的“稿”好。这个“稿”并不只是文稿，还有画稿，比如一些logo设计图之类的。反正囊括的范围很大。而计件就是雇主挑符合要求的给钱，看不上的就不给。这2个的竞争都是比较激烈的。有能力的小伙伴可以去试一下。我当初可是吃了不少苦。还有一点就是要积攒作品和口碑。雇主一般都是会选能力强和口碑好的人。好的口碑和能力会让你发展的越来越快，大家从零开始一定要努力，好的服务态度是最基本的。除此以外就是实名认证。不然接单得到的钱是没有办法提现的。虽然不实名认证也可以接单，但是单量真的是少之又少。我刚开始的时候就不想实名认证，结果接不到几个单子。雇主一般会偏向选择有实名认证的服务商，实名认证的人开起来靠谱，所以新手最好进行实名认证。': array([1.], dtype=float32),\n",
       " '在猪八戒网上接单也有些时间了，也走了不少弯路，今天就帮大家避个雷。猪八戒网上有多种交易模式，相比大家都知道吧？招标、雇佣、比稿、计件等。这些交易模式截然不同而且适用于不同的行业。如果在错误的模式下寻找你的对口任务的话，你找的合适的单子的机会就不是很大。以下是我多年经验总结，全是干货：第一，招标是雇主发布需求后，众多服务商参与报价，雇主选择中意的服务商中标后，再开始一对一交易的交易模式。适合网站开发、软件开发、装修设计等周期较长、工作较复杂的项目类需求。需要有一定经验的专业人才，优秀的案例和良好的口碑容易被雇主选中。第二，雇佣是雇主与服务商的一对一交易，包括直接店铺雇佣和购买服务。这个如果你没有较强的实力是比较难达成的。第三，比稿是雇主发布需求后，众多服务商提交稿件，参与需求的模式，比较适合设计类。简单来说就是雇主从众多作品中选合适的。我建议小白可以先从这个模式入手，操作简单，门槛也不高。第四，计件是雇主按需求审核服务商投标的时候，按照约定单价，合格一个就支付一个的方式进行选标的交易模式。门槛低，单小、简单上上，小白可以试试。': array([0.], dtype=float32),\n",
       " \"~ o(*￣▽￣*)o大神虽然谈不上，但是我也算个小神吧。在猪八戒网1年半了，对猪八戒也很了解，所以我就来说说吧。楼主如果就是想赚个外快的话，交易大厅里的比稿应该就可以了。这是我认为门槛最低、最容易达成交易的交易模式了。而且里面的单子也很多，每天最基本的生活费还是能赚够的。实力强的话，赚钱也是根本不在话下。如果楼主想在猪八戒网上发展的话，那就应该上点心了。要从平日里的单子中积累经验，不断的学习。我从事的是Logo设计，平日里就经常记录一些好的点子，然后保存起来。总有一天用的到的。当你觉得自己的能力较强时，可以去交易大厅的招标试试，这种交易模式对实力的要求稍高，如果你的服务能得到大多数雇主的认可，说明你的服务已经有开店铺的能力了，可以考虑开一个店铺哦O(∩_∩)O我最近也在准备入驻店铺，不得不说猪八戒网的是能赚到钱的，感兴趣的朋友可以自己了解一下。在这里就不多多赘述了。希望我的回答有帮到楼主(●'◡'●)\": array([0.], dtype=float32),\n",
       " '现在的电子商务想要更好的销售渠道，必须学会运营推广，做好产品推广渠道和运营管理方案。现在流量这么快，如何推广很重要。这个平台会告诉你该怎样运营起来，要结合产品选择推广渠道和推广方式，吸引更多的消费者，最终转化为营业额。我觉得挺好的，收获很大，毕竟人家是专业的。': array([1.], dtype=float32),\n",
       " '猪八戒开了1年了店铺了，效益还算不错': array([1.], dtype=float32),\n",
       " '猪八戒接单可以啊，我在里头有接了一些': array([1.], dtype=float32),\n",
       " '有接到，我开了几个月就有单子了，可以去试试': array([0.], dtype=float32),\n",
       " '不懂如何吧，不过我朋友做的貌似还行，有接到挺多单的': array([0.], dtype=float32),\n",
       " '猪八戒这个平台还是不错的，值得信赖。': array([1.], dtype=float32),\n",
       " '我朋友有做过这个平台，挺不错的！我也正想接入这个平台': array([0.], dtype=float32),\n",
       " '我觉得猪八戒网站还是很靠谱的，比较经营时间也是很长，口碑也是不错的，你们可以去了解下': array([1.], dtype=float32),\n",
       " '这个网站还是可以的，我已经入住一段时间了，也开了几个单子。': array([1.], dtype=float32),\n",
       " '这个网站还是不错的，值得去关注一下，里面的效益也不错，试试吧': array([1.], dtype=float32),\n",
       " '这个平台模式挺好的': array([1.], dtype=float32),\n",
       " '猪八戒还是很良心的': array([0.], dtype=float32),\n",
       " '猪八戒网正能量，放飞自我，享受每一天的快乐': array([1.], dtype=float32),\n",
       " '猪八戒这个平台不错呀，有接单还挺多的，值得信赖哦，': array([1.], dtype=float32),\n",
       " '我之前用过，感觉还挺好，多劳多得嘛': array([1.], dtype=float32),\n",
       " '哇这，看着挺不错的勒': array([1.], dtype=float32),\n",
       " '猪八戒还是蛮不错的，值得信赖': array([1.], dtype=float32),\n",
       " '猪八戒网挺好的，顶起来': array([1.], dtype=float32),\n",
       " '猪八戒网吧是一个非常好的平台，我经常观顾店铺下单，是一个值得信赖平台！': array([0.], dtype=float32),\n",
       " '这猪八戒网店，还是很吸引人的。': array([0.], dtype=float32),\n",
       " '这个网还是很方便的': array([1.], dtype=float32),\n",
       " '猪八戒网系统性能很稳定': array([1.], dtype=float32),\n",
       " '猪八戒网确实不错，有创业想法的可以试试。很简单不复杂。进来你就会发现原来赚钱也不是那么难': array([1.], dtype=float32),\n",
       " '猪八戒网还是很不错的，只要你勤奋，赚点钱没问题': array([1.], dtype=float32),\n",
       " '猪八戒网站接单挺好的，效益还可以。': array([1.], dtype=float32),\n",
       " '猪八戒网站还是比较可靠的，模式也是比较简单易懂，新人上手也是很快的': array([1.], dtype=float32),\n",
       " '这个平台还可以，我好几个朋友都在做！值得信赖': array([1.], dtype=float32),\n",
       " '平台很棒 每天固定接': array([1.], dtype=float32),\n",
       " '猪八戒店铺确实好，我经常去买东西，双十一还去打卡！': array([1.], dtype=float32),\n",
       " '真想参与这个平台点赞点赞': array([1.], dtype=float32),\n",
       " '猪八戒网真的不错，优化坐的很好啊': array([1.], dtype=float32),\n",
       " '我用过猪八戒网旗下的那个筋斗云，挺不错的，可以很好的解决客户 沉  淀、私 域 客 户 经营、交 付 管 理、企 业 经 营 管 理、渠 道 获 客 等 多 方 面 痛 点。': array([1.], dtype=float32),\n",
       " '我们公司最开始入驻猪八戒平台的时候我也不知道怎么弄，只是注册了店铺开通了漫游，后来逐渐了解后，就开始加入了能力中心达成合作，对于企业获客引流帮助真的很大。': array([0.], dtype=float32),\n",
       " '猪八戒网对于像我这样的刚起步的小微企业来说帮助真的特别大，我刚创业的时候就是通过猪八戒网来开单的': array([0.], dtype=float32),\n",
       " '猪八戒网非常时候刚创业没有什么经验的一些小企业或者个体户，能帮助少走很多弯路，相较于网上大多数投放的渠道，猪八戒网成本更低、回报更高。': array([0.], dtype=float32),\n",
       " '还可以，之前在上面发布了一个做LOGO的任务，要卡通一点的，对接的设计师人还不错，半个月就定了': array([1.], dtype=float32),\n",
       " '挺不错的，我们公司和猪八戒网合作了3年左右了，现在已经叠加了猪八戒网的多款企服通产品，之前是我们去给别人打电话，加入猪八戒后现在都是客户主动联系我们。': array([0.], dtype=float32),\n",
       " '我是做生鲜市场的，一直想进军互联网，但是扳不过那些大手腕，前几年看着同行入驻互联网个个惨谈收场，但是不搞线上生意又愈来愈差，后来朋友介绍了猪八戒网，入驻猪八戒网仅3个月的时间，非常可观，真心挺不错的一家搞企服的平台。': array([0.], dtype=float32),\n",
       " '对 于 企 业 来 说 ， 好 的 办 公 环 境 可 以 提 高 员 工 的 认 同 感 和 归 属 感 ， 还 会 影 响 员 工 的 敬 业 度 。 而 员 工 对 企 业 的 认 同 感 和 敬 业 度 的 提 升 ， 更 是 直 接 关 系 着 员 工 的 工 作 效 率 。 我 之 所 以 会 选 择 入 驻 猪 八 戒 网 平 台 ， 首 当 其 冲 的 我 就 是 比 较 喜 欢 猪 八 戒 网 提 供 的 非 常 舒 适 的 平 台 环 境 。': array([0.], dtype=float32),\n",
       " '猪 八 戒 网 会 定 期 举 办 社 群 活 动 ， 里 面 有 很 多 行 业 大 佬 会 互 动 共 享 自 己 的 创 业 经 验 。 个 人 认 为 ， 猪 八 戒 网 能 真 正 做 到 助 力 企 业 发 展 与 赋 能 。': array([0.], dtype=float32),\n",
       " '从入驻平台到开办企业需要的各项手续，都有工作人员跟踪服务，真的是又贴心，又让人省心，像我这样刚毕业想要创业的小白，其实前期难免会栽很多跟头，但是有了猪八戒网的帮扶，可以说是帮我扫清了不少创业路上的绊脚石。': array([0.], dtype=float32),\n",
       " '入驻猪八戒网平台的有非常多的优质企业，我们公司就结识很多志同道合的公司及团队，我们在这里可以携手向前，一起探讨合作共赢的可能性。': array([0.], dtype=float32),\n",
       " '猪八戒网帮我们创建的一对一的运营群真的帮助非常大，在这里，专业的人士会有准对性地解决我们在运营方面的困扰。此外，当我们的店铺访问量陷入瓶颈之后，运营专家也对店铺做了全面的诊断优化，第一时间解决了我们发展过程中的痛点。': array([1.], dtype=float32),\n",
       " '作 为 行 业 知 名 的 企 业 服 务 平 台 ， 猪 八 戒 网 一 直 在 积 极 赋 能 人 才 工 作 方 式 和 企 业 经 营 方 式 的 数 字 化 变 革 ， 我 也 是 在 朋 友 的 介 绍 下 认 识 的 猪 八 戒 网 ， 当 时 团 队 陆 续 有 人 离 开 ， 连 我 们 最 早 的 创 始 人 团 队 也 走 了 两 个 ， 就 在 公 司 存 亡 的 为 难 之 际 ， 好 在 我 们 及 时 入 驻 了 猪 八 戒 网 平 台 ， 通 过 平 台 的 扶 持 及 耐 心 的 运 营 ， 才 让 公 司 得 以 顺 利 经 营 下 去 ！': array([0.], dtype=float32),\n",
       " '毕业后尝试过几次在线下创业，深知创业的艰辛，有段时间业务也不太好，后来合伙人拉着公司一起来到了猪八戒网，情况慢慢地好了起来，还是蛮感谢猪八戒网的。': array([1.], dtype=float32),\n",
       " '我是猪八戒网上的一个雇主企业，因为疫情等影响，我们公司转变了业务模式，成为了猪八戒网上运营相关的服务提供商。其实在猪八戒网，认真阅读规则，精心规划店铺，还是很容易走下去的。': array([0.], dtype=float32),\n",
       " '没什么固定的套路，想要多接单，一是注意口碑和服务，二是多总结经验，多学习别人的案例，三是多和官方工作人员多沟通交流，找到自身的短板和不足': array([1.], dtype=float32),\n",
       " '猪八戒网骗子平台': array([0.], dtype=float32),\n",
       " '在猪八戒上开了有几年了，分享一下自己的经验吧。一是运营好自己的店铺，发挥好自身的长处，比如你是做设计，在logo设计上最出色，那就应该多展示这方面吸引客源；二如果才加入猪八戒，可以多去任务大厅参加投标，门槛不高适合新手上手；三是最先开始可以接一些需求不高的订单，让自己慢慢熟悉起来；四的话，多看多听吧，看优秀服务商的案例分享会，听听工作人员的建议。': array([1.], dtype=float32),\n",
       " '从身边朋友了解到的，用了几次，发现了不少惊喜。': array([1.], dtype=float32),\n",
       " '猪八戒是行业内知名网站了吧，从大学用到现在，开店都开了好几年了。': array([1.], dtype=float32),\n",
       " '有了互联网，购买任何实物产品都变得简单，你可以查参数、比价格、看评价，甚至还能7天无理由退换货，总能让你的需求得到合理的满足。但购买服务却不同，每一次服务的过程，都是一次独立而又主观的体验，即便是同一个服务案例，不同的雇主也会有不同的评判，要想满意，可不简单。作为公司的设计需求外包管理者，我最头疼的事情永远是：“这个活儿交给谁来做？”常用的几个签约设计师，不见得啥都能做；拐八道湾求来人引荐的人，有时候还不如实习生靠谱。兜兜转转，就来到了猪八戒网。选择太多了，反而容易犯错其实一开始，在猪八戒网上外包设计需求，进展并不顺利，主要是选择太多了。有时候人生的很多困惑和麻烦，不在于没有选择，反而因为选择太多。初次打开猪八戒网，让我这个老手也有些震惊，设计店铺琳琅满目，看起来个个都是高手，感觉自己拥有了一座金矿，再也不用担心外包难题了。选了半天，找了家相对来说便宜的店铺，直接就下了单，后来效果图做出来还真不错，交易结果也是非常满意。我尝到了甜头，没多久有一个新的平面设计需求，又选了个报价不高的服务商，结果这次却让我栽了个大跟头。这个服务商做事也很积极，我付钱没多久，就拿出了好几版设计方案，不能说很差，但和我期待的相差甚远。和服务商沟通了几轮，终于发现他们擅长的是网站设计，和我平面设计需求南辕北辙。最后费了老大劲才结案，服务商也被我折腾的够呛。即便是在线下做外包，也会偶尔遇到不对口的外包对象，这事儿给我提了个醒，要在猪八戒网总结适合我的选择方法论。五年以来，我累计发布需求不下百例，经过不断实践和总结，我发布的服务需求完成地越来越顺畅，这得益我归纳了一份如何选择优质服务商的“挑选真经”。不要盲目追求排行榜，成交案例与口碑很重要在猪八戒网上，雇主能够看到很多人性化的功能。例如实时排行榜这个功能就挺有用的，能体现服务商的能力，但也有一点，排行榜越高的服务商，越不“缺活儿”，往往很难对我这种外包业务，付出足够的精力，而设计服务的最终品质，离不开灵感和经验，但更离不开足够的精力投入。所以说，我会综合成交排行榜的数据，选择那些单子没那么多，但成交案例很有品质、口碑比较好的服务商，至于说价格，一分钱一分货，不执着于最低价格，总能淘到具有极高性价比的服务商。慢慢的，用的服务商多了，我自然就拥有了多个品质靠谱，又可以随时顶上的外包团队。对比同类需求完成度，不盲目相信数据这个世界上，能做设计的团队有很多，但是设计与设计完全不一样，不同行业的客户对应的风格偏好也不同，由于我们公司本身就服务多种行业的客户，反向推动我在使用猪八戒网进行设计外包的时候，选择拥有行业设计经验的服务商。选择一个新服务商，考察店铺的时候，优先侧重于拥有同类型设计经验服务商，评估他能否完成同类订单？我的设计思路，服务商能不能快速理解？这个时候，不要盲目相信数据，我们得横向对比，多看几家的案例，多交流几次他的设计思路，优质服务商都是“聊”出来的。多翻翻以往的雇主评价，能侧面发现服务商的优秀品质猪八戒网上，完成服务的雇主都会给予评价，当我们有意挑选某一个服务商的时候，除了可以要求对方拿出案例供你来参考外，还能通过评价来评估服务商的真实口碑，特别是那些积极分享的雇主，他们对于服务过程的故事与细节，有详细的表达，能给我很好的参照。我曾经在一个雇主的评价中看到，这个服务商服务非常细致，会仔细询问雇主购买的字体资源，避免后期设计作品有字体侵权，这种细致入微、考虑雇主权益的服务商，太令人放心了，果断下单合作。这几年，我们看到猪八戒网也在积极创造健康环境的交易模式，各类不足之处的优化也是有目共睹的，还推出了诚信服务保障措施，对于新加入的用户给出了不少便利。这份指南当然不能说涵盖一切，也不能保证大家一定能找到称心如意的服务商，但好歹能提供一些我个人的经验，可以供你参考。毕竟，服务的优劣，本身带有很强的主观评判，你自身满意，才是真的下对了单。': array([1.], dtype=float32),\n",
       " '事实上买服务就是这样，主观色彩很多，评价和星级是依据，但不是全部，很多小店铺往往有物超所值的惊喜。': array([1.], dtype=float32),\n",
       " '双语直播，新东方甚至火过双减前近日，新东方旗下的直播带货平台“东方甄选”因主播双语直播带货人气大涨，仅仅10天时间，原来寂寂无名、粉丝不足百万的东方甄选直播间，成为拥有近1700万粉丝、一周带货3.4亿的热门直播间，以董宇辉为代表的老师们圈粉无数，登顶一百多个热搜。爆火之后，俞敏洪也来到直播间，和众多老师们一起直播带货。5月12日以来，新东方在线股价已然实现翻倍，期间累计涨超107%，6月15日当天股价涨幅一度突破50%，最近4天下来新东方股价已经从4港元多涨到现在的16港元，创造了4天4倍的新纪录。根据百度指数显示的“新东方”相关指数，近日的热度飙升，甚至超过了2021年“双减”政策落地期间。新东方双语直播带货火了，主播们输出英文知识、狂飙搞笑段子，网友们一边看直播买东西，一边听课学英语，网友表示：原来直播带货还可以这样玩！跟传统嘶吼式的带货方式完全不一样，简直是“直播界的清流”。图源|爱设计爆红之前，新东方成立6家分支机构启信宝平台显示，东方甄选（北京）科技有限公司成立于2021年12月7日，法定代表人为孙东旭，经营范围包括技术开发、技术咨询、技术交流、技术转让、技术推广、技术服务，由北京新东方迅程网络科技股份有限公司全资持股。目前，该公司已成立6家分支机构，包括文创分公司、图书分公司、电子产品分公司等。此外，新东方还与北京仰德电子商务合伙企业（有限合伙）投资成立东方甄选（北京）科技有限公司。东方甄选于2021年12月28日上线，定位于助农项目直播平台，俞敏洪曾在个人公众号透露，每天销售额“少得可怜”。据新抖数据显示，自去年12月28日首播以来，东方甄选两个月内合计开播的37场直播累计销售额为928.48万，场均销售额仅25.09万。6月以来，直播间却突然爆火，6月11日的一场直播，东方甄选创下2100万的销售总额，东方甄选抖音平台粉丝也已经升至672万，直播间多次登上平台带货小时榜的前五名，一扫半年以来暗淡的直播带货战绩。图源|抖音截图新赛道再出发，商标为品牌保驾护航东方甄选已经在直播带货赛道奋力开局杀出一条血路，商标布局情况如何呢？据商标局官网检索结果显示，2021年12月8日（此时“东方甄选”项目尚未开始运营），新东方教育科技（集团）有限公司旗下北京新东方迅程网络科技股份有限公司就已申请了多个“东方甄选”“DONGFANGZHENXUAN”商标，注册类别涵盖了45类全类别，目前这些商标均处于等待实质审查状态。图源|商标局官网截图东方优选公司则申请了多个“好物东方”“好物东方来”商标，大多数商标流程为“受理通知书发文”。图源|商标局官网截图此外， 2021年12月17日新东方教育科技（集团）有限公司还提交了多件“新东方农品优选”“新东方优选”商标注册申请,目前这些商标注册申请有的处于初审公告状态，有的处于等待实质审查状态，有的处于驳回复审中。图源|商标局官网截图据路标网查询数据显示，新东方教育科技（集团）有限公司已申请1200+个商标，注册类别几乎涵盖了45个国际分类，35类-广告销售、41类-教育娱乐、42类-网站服务等重要类别更是集中布局，申请个数均已超过百件。图源|路标网截图由此可见，新东方在知识产权保护方面是十分具有前瞻性和全面性的，提前进行商标布局不仅保障了新领域业务的顺利开展，也在一定程度上避免了他人抢注商标及侵权情况的出现，这样的品牌保护意识也值得所有企业学习，不管是中小企业还是大企业，无论是什么行业什么产品都应该提前布局，且需要围绕主品牌进行防御性注册，构建起品牌商标护城河。商标作为企业重要的无形资产，具有庞大的使用价值和商业价值，提前布局商标工作，如此才能发挥品牌保护的作用，不仅能为企业提供有力的法律保障，还能维护公司的利益，助力企业走得更远。': array([1.], dtype=float32),\n",
       " '“您好,我是猪八戒网上的服务商,刚刚投标了您的包装设计。”在猪八戒网上发布招标需求,仅仅半个小时后,刘先生就陆陆续续接到几个服务商的来电。打开订单需求详情页,这10多个服务商的资质等级、好评率、工期、报价等信息一目了然,等着刘先生选择。“用习惯了,省钱省心,挺好的。”刘先生是北京一家化妆品公司负责人,从2012年公司成立至今,作为猪八戒网的“铁杆”雇主,已经8年了。业务需求不均衡,自养团队不如服务外包公司成立初期,产品要上市,有包装、宣传等一系列设计工作要做,短时间内招不到合适的设计师。“为什么不试试外包呢?到猪八戒网去看看啊。”在朋友的介绍下,刘先生第一次知道了猪八戒这个服务平台。在猪八戒网上找设计服务,方式多样,可以通过发布招标、比稿需求,从中选优;也可以浏览相关服务商的店铺,直接咨询提交需求、购买服务。于是,在搜索分类的“设计店铺”页面,刘先生咨询了几家成交量、评价比较靠前的店铺,通过对比后,选中了一家服务商,将托管赏金提交到平台上,并与服务商签订了合同。“刘先生您好,我是猪八戒网的工作人员。”下单不到2分钟,就接到平台来电,如此速度让他颇感意外。原来,为了帮助雇主和服务商详细沟通,猪八戒针对每个项目都设立了1对1客服,并建立工作群,跟进服务、规范流程。在验收环节,平台客服会先验收一遍再提交给雇主,一直修改到满意为止。第一次合作,这次设计中简约天然的科技风格,很符合公司化妆产品的定位,刘先生很满意:“感觉跟淘宝购物一样,只不过在猪八戒网购买的是服务。支付的托管赏金在平台放着,满意确定后,才到达服务商账户上。”有了“第一次亲密接触”的良好体验,刘先生不再考虑招设计师,因为公司设计业务不均衡,只有在产品上新时才有密集的设计任务,闲的时候根本没事做,成本太高。再者,自己培养的设计师接触面有限,而猪八戒网上的第三方设计公司更专业,经常接触业务、参加展会,对市场潮流有更敏锐的把握。平台交易服务更规范,相互理解天地宽“跳单啊,以前的确也有过,但是成本太高,划不来。”刘先生坦言自己在这8年中,也曾出现过跳单行为,与平台上一些服务商合作久了,双方熟络后觉得走平台交易,流程麻烦,便私下交易。没想到,离开平台的资金托管、流程规范、单订评价等监管约束后,服务质量难以确保。“这不仅仅是单纯的金钱成本,关键是时间和精力成本。”刘先生说,所以,他很快就回归了猪八戒平台。另外,在他看来,通过猪八戒网找设计服务的另一个便利在于,平台基于行业大数据,可以对服务产品进行高中低档次的精准评估,帮雇主确定合理的预算,通常来说,设计成本要低于市场行情。尽管经过多年的发展,公司规模逐渐壮大,也拓展了自己的研发生产基地,但刘先生却一直没有组建自己的设计、市场推广策划团队,他也没找过线下服务外包公司。“线下资源太散,找起来麻烦。猪八戒网上集中了海量服务商可以挑选。”8年来,刘先生公司的设计、市场营销策划等工作,都在猪八戒网上外包完成,与10多家规模大的服务商建立了稳定的合作关系。近期,公司正在启动品牌宣传工作,每个月投在猪八戒上的服务费大约是1.5万到2万。“收益远远大于支出,不管怎么说,都比我自己养团队成本更低,服务质量更好。”对于有些雇主吐槽的平台乱扣费情况,刘先生说,自己八年来,还真没遭遇付费不愉快的事,“每个平台都有收费规则,像服务付费平台,因为服务的过程比较复杂,推进到某一个环节,或者雇主没有严格遵守约定,有时候收取一定的费用应该能理解,比如雇主在发布比稿需求时,就要先看清楚比稿交易流程和退费标准。如果需求通过审核发布,有服务商投稿,雇主在征集中途关闭,也会产生一定的费用。”人与人之间交往,都要换位思考、相互理解,与平台、服务商合作也是一样,在刘先生看来,这正是他与猪八戒网从“第一次亲密接触”,然后8年“浓情蜜意”一直走到今天的原因。': array([1.], dtype=float32),\n",
       " 'UI界面改版了，现在猪八戒网上的是“外包、兼职、比稿、职位大厅”，就在右上角的“筋斗云人才工作台”里，还蛮好找的。': array([1.], dtype=float32),\n",
       " '猪八戒网一直在进化！此次平台升级核心有三：一是进一步提升平台双边用户的匹配效率，切实提升用户使用体验；二是构建兼职、全职和外包的企业全场景云用工服务体系；三是为人才提供在线数字化经营完整解决方案。': array([1.], dtype=float32),\n",
       " '这几年猪八戒网的发展势头挺不错的，八戒科技服务的发展模式值得肯定。': array([1.], dtype=float32),\n",
       " '时间过得如夏天的温度上升一样快前几天大家还在讨论高考和满分作文如今很多考生志愿都已经填报完毕啦图片源自爱设计第一个没有作业的假期准大学生们也没能闲着有的在考驾照有的趁着行程码摘星游历名山大川还有的则希望通过两个月时间做做兼职提前刷一刷社会经验图片源自爱设计暑期兼职最劝退大家的是严酷的高温以及诈骗！诈骗！诈骗！多地警方发布预警谨防误入兼职骗局微博截图那到底有没有靠谱兼职渠道呢？看我！看我！看我！6月18日猪八戒网对平台进行了全面升级为个人兼职开设了特别专区个人用户可免费在平台获取兼职信息没错！免费！劳(bai)动(piao)使我快乐图片源自爱设计平面设计、设计师、前端开发、后端开发、3D&VR设计、室内设计、网络客服、网络推广……每天都有大量的兼职需求在此发布50元、500元、5000元……各种难度的兼职需求满足不同的兼职人群猪八戒网截图同时还可以上传你的技能信息等用人单位主动找你': array([1.], dtype=float32),\n",
       " '总共有5、6个服务商的故事，这是开头第一段。上次我们推送过一篇猪八戒网的文章《万众唾骂的猪八戒网》，引发了极端对立的评论。这种对立，恰恰是猪八戒网在互联网上的微观缩影：在基于行业视角的新闻报道中，大多是模式价值与运营思路等宏大叙事，鲜有负面描述；而在基于个人视角的社交表达中，充斥着不满与吐槽，其中又以服务商居多。这次我们把目光聚焦到了服务商，试图弄明白：社交网络中的吐槽，在猪八戒网服务商群体中是否代表了大多数？服务商对于猪八戒网又有怎样的爱恨情仇？这两个问题的答案，都需要从服务商的真实讲述中去寻找。花了一个月，我们访谈了数十位猪八戒网的服务商，他们从不同的维度，感受与讲述不同的猪八戒网。在猪八戒网的官方报道中，成功的服务商案例仿佛印证了一种“幸存者偏差”，平台肯定更愿意拿成功者讲故事；而社交平台上的吐槽中，更多体现了一种“不幸者偏差”，他们对于平台的不悦需要公开宣泄，比“幸存者”有更强的表达欲。我们通过主动联系、朋友推荐选取了几位具有代表性的服务商，有人坚守，有人逃离，也有人逃离后选择回归，通过他们的故事，来回答上面的两个问题。遗憾的是，这些故事本身也难以完全跳出“幸存者偏差”的陷阱——愿意与我们分享的服务商，要么有实力，要么有经历，要么有表达欲。而和大部分舞台一样，那些泯然于人海的大多数，未能进入有限的聚光灯区域。样本有限，不过还是可以通过这篇文章，尝试解读圈外人不太了解的服务商群体，找到他们坚守、逃离和回归的原因，也借此更立体地勾勒一下猪八戒网的轮廓。': array([1.], dtype=float32),\n",
       " '这是第一个故事一、“猪八戒网，没得搞”李晓离开猪八戒网，已经两年了。电话里传来浓浓的南方普通话，拖着很长的尾音，有两句话魔幻般地在我脑海中回旋：“没得搞”、“很难搞”。“没得搞”的李晓，从2012年就入驻了猪八戒网，当时有一个小团队，提供营销推广服务。入驻5年后，也就是2017年，李晓曾花费140多万购买流量，希望能做大自己的生意。然而，这更像是一种“最后的疯狂”，因为到2018年年底，李晓选择彻底退出了猪八戒网。问及缘由，他无奈地说：“人，都有疲惫的时候。”作为猪八戒网服务商中的一家六年老店，李晓的无奈颇具代表性——平台不停地变换模式、变化规则，让他觉得“服务商是没办法生存的”。比如，购买皇冠会员还没到一年，又推出一个新的会员体系，新会员体系可能比皇冠会员的权益还好，此时就需要调整店铺的运营方式，去符合新的会员体系的规则。而随着话匣子打开，李晓也透露，除了平台规则的频繁变化，选择离开，还有一笔算不清的账：“一名设计总监月薪两三万，好一点的设计师也要上万，一个月上24天班，平均下来一天多少钱？一个Logo不算修改，也要花两三天时间吧？几百块钱怎么搞？”结论自然是“没得搞”，猪八戒网上的客群与他公司不符。实际上，李晓离开时服务等级已经达到“猪三十七戒”，线上累积成交额已达1900多万，可以说正是通过在猪八戒网上接单，才完成了自己创业早期的关键起步和原始积累，猪八戒网上服务类目的普遍报价，他也非常清楚，怎么突然就客群不符了呢？离开的真正原因，有外在的，也有内在的。2018年，李晓的公司已经不再是初创的小微企业，超过50人的团队，其中不乏高薪聘请的人才，而不管业务的价格高低，他都坚持用自己团队消化，绝不外包，导致企业整体运营成本高企不下。经营策略上，李晓开始追求高价高质，打造品牌案例，想逐渐往能够实现高附加值的市场迈进。成本高企、迫切转型的企业内因，变换模式、规则多变的平台外因，两者交互刺激下，李晓终于选择告别猪八戒。聊到最后，李晓也坦言，2017年投入140多万购买流量，是有后续的，为他带去了“三四百万”的营收。打开猪八戒网上他的店铺主页，不难发现，即便是在2018年底李晓彻底退出之后，仅仅是线上交易，2019年至今仍然有176个交易评价，交易金额也在百万量级。': array([1.], dtype=float32),\n",
       " '上面几个服务商的故事，相信大家可以从中得到很多东西，关于如何运营，平台到底如何，入驻要有什么准备和心态。下面再复制两段，就会对猪八戒的网评和企业的情况，多些了解。': array([0.], dtype=float32),\n",
       " '“幸存者偏差”与“不幸者偏差”有人珍爱，有人痛恨，也有人到处吐槽。关于服务商吐槽猪八戒网的现象，在逃离者李晓和手艺人郭涛看来，说出了他们的心声，而程序员黎永和大学生张磊，则认为平台无罪，应该从自己身上找原因。张磊把这种现象总结为“不幸者偏差”。“幸存者偏差”一般是社会看待成功者的认知偏差，仿佛成功者经历的一切都是对的，而忽略了成功与否其实是一种概率；而“不幸者偏差”则刚好相反，仿佛失败者经历的一切都是错的，而忽略了造成失败的变量原因。我们经常被“幸存者偏差”和“不幸者偏差”迷蒙了双眼，因“幸存者偏差”而吹捧造神，因“不幸者偏差”而墙倒众人推，从根上看都是一种肤浅的结果导向。而在成败背后，那些属于每个个体的变量差异，常常在偏差中被忽略。在平台上获得良好服务的雇主和获得良好收益的服务商，不会专门发帖去夸奖猪八戒网，那些在平台有不愉快遭遇的人，会去网上吐槽他们的遭遇和对网站的看法。在处理负面消息上，张磊认为猪八戒网“没有做好公关”，“人家有一些问题，应该去沟通解决，它有点忽视”。在任何领域，创业成功都是小概率，而失败者才是大多数。据猪八戒官网数据，平台聚集了1400 万专业人才，为全球1000 余万家企业提供1000 余种企业服务，没有坚持下来的人自然不会是个小数字。网络口碑似乎局限于单一视角，还原立体的猪八戒网，就需要更多服务商的真实故事。“拥有海量的真实服务需求”是确定的，或许有服务商质疑它的质量，但从未有服务商否认它的存在。这些需求既来自山东某地开挖掘机的人，也来自北京顺义区开化妆品公司的人，还可能来自我们每天擦身而过的街边小吃店，我们身处拥有14亿人口的中国，足够多元，也足够复杂。在当下的中国，5万块钱，买不到上海的半个厕所，但买得到鹤岗的一套房子。如此复杂的世界，导致猪八戒网上存在着鱼龙混杂的需求和良莠不齐的服务。这让本来就已经最难的猪八戒网“服务交易”生意，更难了，也导致一千个服务商可能有一千种标准，一千个雇主可能有一千种评价。理解猪八戒网，也许就理解了复杂的中国。猪八戒网的未来，无法断言，但服务交易市场，永不会落幕。没有人永远年轻，但永远都有人年轻，同样，在这个广袤大地上，或许没有人永远创业，但永远都有人梦想不灭，对服务的需求也就永远不灭。': array([0.], dtype=float32),\n",
       " '我已经逃离': array([1.], dtype=float32),\n",
       " '猪八戒网垃圾，同意点赞': array([0.], dtype=float32),\n",
       " '现在超级垃圾': array([0.], dtype=float32),\n",
       " '带血的馒头能好吃？': array([1.], dtype=float32),\n",
       " '发布需求很简单，官网就有一键发布需求的功能，主要是里面的具体要求要写清楚。': array([1.], dtype=float32),\n",
       " '平台定位：中国领先的综合型数字化企业服务平台。企业使命：汇聚天下人才，服务全球企业。企业愿景：帮助亿万企业获得满意服务，帮助亿万人才找到工作机会。企业价值观：客户为先、同心同向、成人达己、坚持奋斗。': array([0.], dtype=float32),\n",
       " '猪八戒骗子公司！上边有个子非网络也是骗子，大家小心': array([0.], dtype=float32),\n",
       " '这死猪什么人都骗，不管是雇主还是服务商！': array([0.], dtype=float32),\n",
       " '上边有个子非网络也是骗子，大家小心': array([0.], dtype=float32),\n",
       " '是的 他们公司就是收了钱不给办事，到时候说注册不下来 不给退钱，客服都有固定话术。业务装无辜，推财务。我准备找媒体曝光他们，看到这条的朋友不要再上当': array([0.], dtype=float32),\n",
       " '他们有个八戒圈子，在上面会有很多学习资料，针对新手有一个新手指南，可以了解一下。': array([1.], dtype=float32),\n",
       " '猪八戒 一毛钱没挣着 ，一步一步引诱你缴费，无论你是商家还是 想兼职挣钱。找兼职，投标需要 88元/年，听着不多，这是第一步。但是。。。。投标的钱 ，保证金 什么的。还有 联系商家 都得用的QQ企业版 1800/年 等等 。接了一单 挣个一二百，提现需要交保证金5000 。': array([1.], dtype=float32),\n",
       " '赞同楼上说的部分内容，猪八戒网的交易模式有很多，如果是新手服务商不如从投标和比稿开始，多了解下流程和积攒些经验。提个醒，无论哪个平台，都一定要擦亮眼睛。不过，只要你有真本事，就不愁没单接。保证金这个，就仁者见仁，智者见智了。保证金算是交易平台的基本准则吧，如果没有保证金，那岂不是骗子都可以无成本诈骗了？保证金是可以退的，个人觉得没什么问题': array([0.], dtype=float32),\n",
       " '为新人还是先去猪八戒网各个板块溜达下吧，也可以熟悉下版规。想接活可以看看猪八戒网首页右上角的【服务商中心】。': array([1.], dtype=float32),\n",
       " '适合我们这些无业游民': array([1.], dtype=float32),\n",
       " '算得上老用户了，这一次回归期待更多的惊喜。': array([1.], dtype=float32),\n",
       " '感觉不错                                \\n                \\n                    \\n                        天蝎座\\n                            \\n                               \\n                            \\n                        \\n                    \\n                    \\n                        参与贴吧T豆娱乐城七夕活动\\n                    \\n                    \\n                        活动截止:2016-12-31\\n                    \\n                    去徽章馆》\\n\\n                    \\n                \\n                        \\n                \\n                    \\n                        星座王\\n                            \\n                               \\n                            \\n                        \\n                    \\n                    \\n                        点亮12星座印记,去领取\\n                    \\n                    \\n                        活动截止:2100-01-01\\n                    \\n                    去徽章馆》': array([0.], dtype=float32),\n",
       " '机会多、平台大，感觉值得打拼很久……': array([1.], dtype=float32),\n",
       " '不错的平台！                                \\n                \\n                    \\n                        应用达人\\n                            \\n                               \\n                            \\n                        \\n                    \\n                    \\n                        应用吧活动,去领取\\n                    \\n                    \\n                        活动截止:2100-01-01\\n                    \\n                    去徽章馆》': array([0.], dtype=float32),\n",
       " '我也在玩猪八戒，新手，学设计的，从没中过标，很无奈。。。': array([0.], dtype=float32),\n",
       " '操作非常简单，每一步都有详细的教程，不用担心不会做，申明一下，这个项目不是淘宝类的！而且需要你每天有1到2小时的空闲时间！如果没有就不要做！': array([0.], dtype=float32),\n",
       " '都是新手过来的，还是要自己多摸索，先把基础功能搞清楚再说，公众号、贴吧也有很多老手在分享经历，可以多看看。': array([1.], dtype=float32),\n",
       " '你这让我想起了大学时在猪八戒网上接单的日子，青春真是一去不复返啊。': array([1.], dtype=float32),\n",
       " '我当时挺幸运的，注册好账号后，随手投了一个标，没想到就中了，被别人肯定也挺满足的。': array([1.], dtype=float32),\n",
       " '平台不错，做了很多年，累计了一批不错的服务者。由于服务者数量多，甄选的时候需要擦亮眼睛，毕竟服务水平各有差异，选择最适合你的才是最好的。': array([1.], dtype=float32),\n",
       " '对于像我这样的学 生 党 来说，猪八戒网还是非常nice的，真的是，我在这个平台赚 了 不 少零 花，像我室友也都会在闲暇的时候逛逛猪八戒网接些 私  活  赚  赚  小  钱，我一个室友比  稿  中 标 还  赚  了 3000  呢。': array([0.], dtype=float32),\n",
       " '猪八戒对于我们这些想赚 点 零 花 钱 的  学  生 来说算是一个比较不错的平台在里面有非常多的任务可以让我们去接单，这一些任务都是雇主去发出来的，我们去上面接订单即可。': array([1.], dtype=float32),\n",
       " '算是互联网界的一股清流了吧，平台拥有 一 千 万 以 上 有 着 专 业 技 能 的 人 才，而且随着互联网浪潮来势汹汹，很多专业的设计开发机构，也开始逐渐入驻到猪八戒网，实力也是够硬的。': array([1.], dtype=float32),\n",
       " '我认为今天的猪八戒和淘  宝相比，体量还不在一个量级，但是猪八戒未来作为平台的社会价值一定比淘   宝这样的平台的社会价值要大得多，会成为现象级的巨人存在。': array([0.], dtype=float32),\n",
       " '对于中小企业的帮扶很大，我之前开公司的时候，一个小小的商标弄不下来，得亏是通过猪八戒网上提供的商标注册      服 务，很快就搞定了。': array([0.], dtype=float32),\n",
       " '猪八戒网在产业互联网领域已经默默耕耘了10年，算是一家很有底蕴、很有实力的企业了，无论是想开公司创业的、想赚点零花的，猪八戒网都能提供很大的帮助。': array([1.], dtype=float32),\n",
       " '平台很大，服务商很多，费用也比较合理，上次遇到的设计师很有耐心。': array([0.], dtype=float32),\n",
       " '——猪八戒网联合中新社重庆分社火热征集中6月14日，“数字化时代，寻找‘灵活就业新36行’”活动启幕发布会在猪八戒网总部路演大厅举行。本次活动由猪八戒网、中国新闻社重庆分社主办，重庆市就业创业促进会协办，旨在挖掘灵活就业新赛道，拓宽灵活就业渠道、降低就业压力的同时激发市场灵活就业新活力。通过线上线下深度走访调研系列新职业技能培训活动，挖掘一批灵活就业新行业，树立一批灵活就业新典型，掀起一股灵活就业的新风潮，帮助一批有意愿、有技能的求职者实现灵活就业。▲ “数字化时代 灵活就业新36行”全网征集活动启幕我国灵活就业群体突破2亿人灵活就业人员主要指以非全日制、临时性和弹性工作等灵活形式就业的人员，包括在各级档案寄存机构寄存档案的与用人单位解除或终止劳动关系的失业人员、辞职人员、自谋职业人员。重庆市就业服务管理局相关负责人称，近年来，互联网等数字技术快速迭代，灵活就业应运而生，对传统劳动力市场和就业关系产生深远影响。据今年1月国家统计局数据显示，全国灵活就业人员已达2亿人左右。外卖骑手、网约车司机、网络主播等灵活就业发展方兴未艾。“灵活就业不仅让就业市场蓄水池扩容，使劳动者就业选择更为多样，而且让低收入者和特殊人群获得更多就业机会。”该负责人说，重庆将灵活就业人员纳入公共就业服务范围，落实社保补贴等灵活就业扶持政策措施，培育双更基地、零工市场、就业驿站，构建“15+5”就业便民服务圈，为劳动者提供灵活多样的就业机会。▲ 收纳空间设计师吴波分享收纳师行业发展情况数字化平台已成灵活就业的主战场“面向全网征集数字化时代灵活就业新36行，可以帮助社会大众提升灵活就业的认知程度，帮助供需两端搭建灵活就业的对接渠道，帮助政府部门洞察灵活就业的发展趋势，具有特别的现实意义。”重庆市就业服务管理局相关负责人称，该局将与活动发起单位等密切合作，强化政策落实和服务供给，促进灵活就业更加规范、健康发展，让更多劳动者拥有人生出彩机会，全力以赴稳定就业局势。当前疫情反复多变，不确定性、不稳定性因素较多，史上最多的高校毕业生将集中进入就业市场，作为“六稳”之首和民生之本的稳就业也不断加码。在国务院办公厅印发《关于支持多渠道灵活就业的意见》要求各地因地制宜、因城施策，清理取消对灵活就业的不合理限制，鼓励自谋职业、自主创业，全力以赴稳定就业大局。数据显示，我国灵活就业人群不断扩大，2022届高校毕业生中有18.6%选择了自由职业。大部分灵活就业人员分布在外卖平台、网约车平台和猪八戒网等灵活用工平台，互联网+、数字化、平台型企业正在让灵活就业成为批量解决就业的重要方式。中新网重庆（重庆新闻网）副总编辑张燕表示，伴随着数字时代的发展，科技对经济发展的推动作用，创造了更多更高质量的灵活就业岗位，成为了数字化时代下灵活就业新职业的风向标。▲智慧乡墅规划师王东分享灵活就业经历推荐新职业线索，可获多项福利启幕发布会现场，智慧乡墅规划师王东、收纳空间设计师吴波两位灵活就业翘楚代表，分别从各自灵活就业的经历出发分享了对于灵活就业话题的理解和困惑。猪八戒网联合创始人、董事刘川郁指出，本次活动就是要征集36个如智慧乡墅规划师、收纳空间设计师等灵活就业新职业，为灵活就业求职者指明就业方向。据介绍，本次“数字化时代，寻找‘灵活就业新36行’”征集活动由征集、评选、发布、培训等几个环节组成。即日起至6月25日为活动征集期，网友可通过活动官方专题页推荐灵活就业新职业的线索。7月15日，活动主办方还将举行灵活就业新职36行报告发布盛典。网友可以通过访问猪八戒网活动专题页、中新网重庆（重庆新闻网）媒体专题页参与活动。参与线索推荐的网友将免费获得任一上榜新行业的就业秘籍、培训课程，并获得“灵活就业新36行”首席推荐官荣誉奖牌。刘川郁表示，凡是依托于数字化平台，进行非全日制、临时性、阶段性和弹性工作时间等多种灵活的就业形式的人员均属于此次活动征集对象。只要符合上述定义的合法合规新职业，并且有案例、过往经验、数据等体现这份职业的可执行性，均算作是有效的新闻线索。扫描文末二维码或点击阅读原文，即可提交新职业线索。▲猪八戒网联合创始人、董事刘川郁介绍活动内容将为灵活就业群体提供多项赋能灵活就业呈现出就业渠道平台化、就业过程数字化、就业行业新奇化、人员分布离散化、人员岗位地点分离等突出特点。此次猪八戒网和中国新闻社重庆分社，希望发挥灵活用工平台、权威媒体平台，以及重庆市就业创业促进会各成员的资源优势，“聚众智、汇众力”帮助数字化时代下致力于从事灵活就业的求职者群体。今年上半年，猪八戒网将公司愿景更新为“帮助亿万企业获得满意服务，帮助亿万人才找到工作机会”。为助力人才解决就业问题，猪八戒网加强了对于灵活用工、兼职等服务类型的扶持力度，平台交易大厅内上线了大量的灵活用工、兼职类服务需求。在本次灵活就业新职36行报告发布盛典之后，猪八戒网还将联合新36行上下游翘楚企业，举行一系列的新职业人才培训活动。希望通过邀约猪八戒网上优秀灵活就业代表、新职业行业大咖等，为灵活就业求职人员提供职业规划、专业技能、就业渠道等方面的培训课程，助力求职业通过灵活就业解决就业问题。': array([1.], dtype=float32),\n",
       " '猪八戒的行业真经很多': array([0.], dtype=float32),\n",
       " '我怎么感觉，购买猪八戒服务的不论八戒通还是会员，基本在众包，投稿会优先获赏啊。观察好几个任务都是这样。': array([0.], dtype=float32),\n",
       " '被骗了': array([0.], dtype=float32),\n",
       " '买这个就是浪费钱': array([0.], dtype=float32),\n",
       " '最近，留意投稿的十个任务，基本都是金银服务商中赏，获赏的。所以如今看来没有悬赏。参与众包还是入会员的好。只要是猪八戒的金银，会员不论你稿件多么垃圾和不对任务顾客的需要。都能拿到赏金。所以，建议，大家还是考虑参与购买金银高级等服务。不然以后连众包都没法参与投稿了。俺这两天也在考虑是不是也加个银服务商呢。虽然感觉基本不会赚到钱，除非有客户购买版权，不然基本肯定会亏，会坑。付出的劳力如流水。不然就，只能转到别的威客平台了。至少俺是，已经在一品和时间两个威客注册。要从头开始了。毕竟普通服务商在众包如今也难拿到赏金了。任务的都给金银等服务商整包了。': array([0.], dtype=float32),\n",
       " '现在是八戒通最后几天了，就是有一个一直联系我的说是最后几天问我考虑的怎么样了，说是加入会员有各种好处，最慢2个月就回本了，所以我在思考要不要加入八戒通？楼主给个意见吧': array([0.], dtype=float32),\n",
       " '作为一个老服务商，我只能说这是一个让人心寒的平台，与原先的初衷完全背道而驰，因为政府关系，服务商投诉无门，我投诉过，举报过，换来的只是你要求退多少这种处理办法。目前平台问题不是一点点，然后八戒给我问题反馈打电话的是他们广告部~甚至我都怀疑中间协调声称政府部门的人与猪八戒狼狈为奸，或者就是移交猪八戒法务了，装作政府部门给我打电话！这就是你们的处理态度！就这样发展吧！希望大家不要上当！也祝猪八戒早日得报应！': array([0.], dtype=float32),\n",
       " '赵玉印总是向身边人夸起猪八戒网,猪八戒网平台真正地以客户需求为本,态度极好,服务也是极为专业,总是能给人惊喜。“到猪八戒网看看吧”也成为了赵玉印的一句口头禅。从当初的0元起步到如今年收入500万,这是河南青云餐饮管理有限公司创始人赵玉印在通过猪八戒网创业的真实经历。赵玉印2016年开始经营小吃生意,从选定公司名称之时,他就与猪八戒网结下了不解之缘。当时就是想一个商标名字,没想到想了数十个无一通过。沮丧之余,有朋友建议他去猪八戒网看一看,结果当天就有两个名称通过,便是如今的公司名称。     不单单提供策划服务,猪八戒网的线下设计服务更是到位。在赵玉印开第二家分店时,类比了许多设计够公司,比来比去还是猪八戒网的态度最好,服务也最周到。从风格,图案,价格等一站式服务,帮助赵玉印省了许多物力与财力。通过这两次经历,赵玉印公司之后但凡有文案推广,宣传海报都是找的猪八戒网。“到猪八戒网看看吧。”这也成了赵玉印的口头禅。    之后,赵玉印还采取了短视频推广的方式,大力宣传自己的公司,并且取得了良好的效果。在猪八戒网的帮助下,赵玉印公司发展越来越好,每年营收额轻松四五百万。在赵玉印公司崛起的背后,是猪八戒网一直给予着支持和帮扶。让我们一起了解这个神奇的平台。    猪八戒网是个怎样的平台?猪八戒网是中国领先的企业服务平台,简单来说,就是围绕企业全生命周期,提供商标设计、工商注册、财税代账等各种服务的交易平台。随着网络信息的发展,猪八戒网不局限于品牌设计等传统众包服务,业务范畴越来越广,服务项目也涵盖电商,法律,产业服务等各个方面。现服务项目主要包括品牌设计,科技服务,财税代账,IT行业,知识产权等。    猪八戒网口碑怎么样?经过长时间的市场探索,猪八戒网已成为国内提供一站式服务的企业服务品牌,以高效率为特色,以客户满意度为准。用户不仅可以自己挑选程序员、设计师、会计师等,还可以根据实际情况进行针对性的服务。猪八戒网发展到现在,好评率极高,许多客户在平台上均有很好的体验,毕竟平台运行多年靠的便是过硬的服务和可信的声誉。    商家如何入驻猪八戒网?猪八戒网不仅提供各项生活与工作服务,还可以入驻平台,成为猪八戒网服务商。首先必须注册个人的猪八戒账号,拥有平台用户体验资格,然后根据提示填写信息进行店铺激活,激活后就成功入驻猪八戒网,便可以进行投标赚钱。详见猪八戒官网服务商指南入驻流程,上面有更详细的操作流程。   入驻猪八戒网的优势有哪些?对于成功入驻猪八戒网的服务商,有巨大的优势接单赚钱。首先,经过长期的发展,猪八戒网已经拥有了海量客户。因此,每天数万个订单,完全不用担心接不到单的问题。并且,猪八戒网市场还开发了海外市场,入驻猪八戒网,还可以服务于其它国家的用户。最后,即使商家缺少服务技能,这里也会提供线上课程培训,手把手教你如何做好项目并提升赚钱技能。还有线下交流会,不仅可以提升见识,更可以拓宽人脉资源,提高成功机会。   如果你选择猪八戒网,相当于成功了一半,这里有专业的技能培训,有丰富的用户资源,有良好的市场口碑,快来入驻一起赚大钱!': array([1.], dtype=float32),\n",
       " '我从当初的默默无闻到现在小有成就，这一路是痛并快乐着把！     我是从事PHP开发的， 主要做些网站开发（php+mysql/asp+sqlserver access）、网站美工（div+css 兼容各种主流浏览器）、仿站、ecshop2次开发之类的工作 。     最近闲来无事，有空就会和大家分享一下我的成长历程吧！     ': array([1.], dtype=float32),\n",
       " '我加入猪八戒网的时候还是个学生，赶上了威客的末班车，现在的我都老婆孩子热炕头了，也有了自己的团队，背靠平台肯定是比单独打拼来的快得多。': array([0.], dtype=float32),\n",
       " '厉害了，从成立到疫情受挫再到重新步入正轨，一直与猪八戒网保持合作，如战友如兄弟，猪八戒网这样的平台，对企业还是很友好的。': array([0.], dtype=float32),\n",
       " '因为相信所以选择，找对一家企服平台很重要，选择猪八戒网，不仅仅是选择了这家平台，还选择了他们的资源以及专业度。': array([0.], dtype=float32),\n",
       " '可以关注下猪八戒网上的优秀设计师们哟': array([1.], dtype=float32),\n",
       " '2014年，互联网行业风起云涌，形形色色的软件开发公司破土而出。做财务软件代理的张明娟也敏锐地意识到了这一点，“传统企业即将互联网化，软件开发需求一定很大！”基于这样的判断，张明娟决定进军开发行业，成立了慧族网络。▲ 慧族网络创始人张明娟01  五年坚持，年营收突破3000万订单永远是初创公司最大的软肋。为了接触到更多客户，张明娟带着团队不断跑客户、同时进行线上投放引流。“在我们刚开始引流的时候，经常投了钱却看不到效果。后来我们才知道投放也是有技巧的，掌握这些技巧后，投放也就变得更精准了……”虽四处碰壁，好在张明娟坚持了下来。创业的前五年，公司就实现了业务量的稳定增长，公司发展迈入新阶段。如何提升利润成为了张明娟的新难题，成本问题一直让她苦恼不已。“现有威客平台的投放成本太高，效果却不好，不是长久之计。”2019年，慧族网络在机缘巧合下了解到了猪八戒网，“当猪八戒向我们投出橄榄枝，我们立马抓住了这个机会！”张明娟回忆。也就是这一年，慧族网络的全年营收创下了3000万元的新高。▲ 慧族网络办公室一角02 疫情之中，逆风翻盘业绩再创新高2020年，突如其来的疫情打破了这场宁静。公司全体员工只能居家办公，办公室空无一人。无法线下交流、业务难以进行，公司陷入资金流困难。张明娟在焦头烂额下，想要找到一条紧急出路。她转念一想，“线下业务无法进行，说不定很多客户会转型线上。”就带着这种想法，张明娟全身心投入到公司的猪八戒网店铺的运营。不仅提高了店铺产品的性价比，也进一步提升了服务品质。没想到效果立竿见影，2021年慧族网络实现了6000万的突破！受业绩提升的正面影响，公司员工也增长到150多人。▲ 慧族网络部分奖项03  开店几个月，才接到第一个订单“这一路有太多的不易，但没有猪八戒就没有现在的慧族网络！”张明娟感叹。直到现在，张明娟依旧清晰地记得慧族网络在猪八戒网上接到的的第一个订单——一款留学小程序开发。经过实地交流对接，慧族网络顺利和客户签下了合同，张明娟第一次体验到了猪八戒的交易闭环。尽管是第一个订单，但此时的慧族网络已入驻猪八戒网有好几个月。在店铺没开张的这几个月里，慧族网络一直沉住气在练内功——装修店铺、封装产品、摸索平台运营之道。“在猪八戒网开店是我们公司做出的最正确选择之一，这个平台帮了我们太多！”张明娟印象最深的是，猪八戒网员工的帮助。慧族网络店铺开张初期，张明娟对平台运营不熟悉，很长时间都没有咨询、没有订单，在杨阳等运营人员的交流指导下，张明娟才真正摸清猪八戒平台玩法，慢慢实现订单增长……如今的张明娟，对于公司未来发展充满信心，“慧族网络将继续扩增，升级组织架构和办公环境，呈现更强的公司实力！”': array([1.], dtype=float32),\n",
       " '这个服务商挺有定力的，也获得了应有的回报。': array([0.], dtype=float32),\n",
       " '希望有更多像猪八戒网这样的做企业服务的数字化平台，让更多企业明白知识产权的重要性，只有品牌树立起来了，才能接着“走出去”。': array([0.], dtype=float32),\n",
       " '现在文字、画面、视频、专利都逐渐数字化了，一不小心就被人趁虚而入，盗用冒名，还是要找猪八戒网这样专业、正规的代理机构，做好知识产权的保护。': array([0.], dtype=float32),\n",
       " '新京报专访猪八戒网联合创始人刘川郁：未来灵活用工或将成为一种主流观念“总样本中稳定或扩大灵活用工使用规模的企业比例从2020年的29.32%上升至2021年的51.80%，缩减灵活用工使用规模的企业仅占9.34%。”《中国灵活用工发展报告（2022）》蓝皮书中显示，2021年，我国有61.14%的企业使用灵活用工，企业更倾向扩大而非缩减灵活用工规模。国家统计局相关负责人日前表示，目前我国灵活就业人员已经达到了2亿人左右。成立于2006年的猪八戒网十余年来为超过100万人实现灵活就业。其联合创始人刘川郁近日接受了新京报记者的采访。在他看来，互联网让灵活用工有了更广泛的发展。企业通过灵活用工，可以在节省开支的同时解决人才需求问题，此外也刺激了新职业的产生。不过，灵活用工也面临一些问题，包括灵活就业者的税收缴纳和技能提升诉求，以及纠纷权益保障等。在当前疫情大环境下，灵活用工也呈现出了多种不同的面向。▲ 猪八戒网联合创始人刘川郁 / 受访者供图01 互联网的发展使灵活用工逐步壮大新京报国家统计局数据显示，中国灵活就业人员已经达到2亿人。猪八戒网最早以帮企业雇主寻找外包服务起家，且已经持续了十余年，在您看来，中国的灵活就业市场经历了怎样的发展？刘川郁灵活用工一直都有，最早的农民工外出打散工，按天结算，这些零工主要在线下进行。随着互联网的发展，灵活用工逐步壮大。最开始是在论坛上发广告，不过大量的还是本地化进行，和线下散工差别不大。到了2006年猪八戒网成立，同时期也有一批威客网站，那个时代非常火爆，进入了一种平台化的阶段。现在它也又进入了视频时代，比如抖音衍生出来很多直播和更多就业机会。总的来说，互联网的发展让灵活用工有了更广泛的发展，变成一个跨越时空的非本地化的状态，就业的领域越来越渗透到我们生活的方方面面。新京报哪些工种雇主比较倾向于使用灵活用工？选择灵活用工的原因有哪些？刘川郁雇主选择灵活用工主要是解决人才问题。第一种是初创公司，没钱招很多人才，就要把很多订单外包。第二种是很多公司在遇到核心业务之外的一些专业性问题时，也需要使用灵活用工。大厂也有这方面的外包。第三种是季节性的非长期性的项目，一段时间内做完就行了。还有一种是跨区域的需求服务，比如logo设计。总的来说，公司通过灵活用工可以节省一些开支，选择面也广。反过来说，灵活用工也刺激了一些新职业的产生。02 灵活就业的认可度还不是很高新京报从2020年《政府工作报告》到2021年7月人力资源社会保障部等八部门联合印发《关于维护新就业形态劳动者劳动保障权益的指导意见》，初步统计至少有八个文件、报告、意见等都分别明确对灵活就业的支持。在您看来，目前灵活就业市场还有哪些痛点尚待解决？尤其是疫情下哪些影响比较严重，猪八戒网有哪些针对性措施？刘川郁疫情主要有两方面影响，一是整体的活力在下降，我们的买家都是企业，所以我们会受到一些负面影响。但从另一个角度，疫情让很多交易转移到线上，所以很多企业也又回归到猪八戒网站。还有一个存在的问题，就是个人自由职业者的税收问题。他们本身挣不了太多的钱，如何让他们的纳税保持在一个合法状态，同时又不要太高，是一个值得研究和解决的课题。新京报截至2021年底，猪八戒网帮助178万人实现灵活就业，这些灵活就业的人期望的核心保障有哪些？猪八戒网作为平台方，能提供的保障有哪些？刘川郁灵活就业人群有几方面的需求，首先是他有技能提升的需求。比如高校学生虽然学了设计、软件开发或者营销策划，但是很多学校没有教他们怎么拿这些东西去线上灵活就业。这背后是观念问题，大家对灵活用工灵活就业的认可度还不是很高。另外一个就是刚才提到的税收问题。感觉这些个人自由职业者的税收有点高，能不能参照个体户去纳税呢？当然这个动作就比较大，需要去研究。我们平台也是螺旋式的上升，最初平台上面全是创业者和灵活就业人才，那时候人数非常多，中间有段时间我们过分强调个体人才要变成公司，变成B2B形式，现在意识到这样其实会限制我们的发展，因为有的自由职业者在平台上挣不到钱就离开了。我们现在也在做调整，希望使更多有才的个体在平台上能够生存。新京报根据你们之前的公告，平台上其实也经常有雇主和服务商之间的纠纷。你们观察到的两方的纠纷类型主要有哪些？怎样才能有效缓解？刘川郁争议比较多的，一个是服务态度问题，第二个是服务时间，另外一个是服务的交付标准问题，就是买家认为我说的是这个需求，结果服务商把它理解成另外一个。在解决方案上，第一我们有数据化的手段去记载，避免发生恶意行为。如果是两方认识上的差距，我们可以去查看线上的对话记录留痕，结合他们的协议做出一定判断，再去撮合他们，撮合不了就只有去上法院。买家能评价卖家的服务，所以卖家也会珍惜在平台上的记录。平台上都是实名制，也有保证金制度，所以反而是线上对于双方的管控更加严格一些。新京报在灵活用工灵活就业当前的发展态势下，能否对未来社会公司组织的运转形态做一个预判？刘川郁这个就有一种算命的性质了。我认为未来灵活用工会成为一种主流观念。全球化不可阻挡，数字化也不可阻挡。社会科技的进步，客观上为灵活用工带来了更多的空间和机会。我觉得未来会诞生一大批一个人的公司。借助灵活用工平台和灵活就业人才，一个人可以给客户交付不同的业务，最终一个人对外就可以做一个公司的事。本文转载自新京报，点击「阅读原文」获取原报道新京报贝壳财经记者：孙文轩 白金蕾编辑：陈莉校对：陈荻雁': array([1.], dtype=float32),\n",
       " '说的很对，我也认为灵活用工和灵活就业是未来发展的趋势，给了企业和就业者更多的选择。': array([1.], dtype=float32),\n",
       " '在这个经济环境下，灵活就业确实不失为一种选择，对稳就业帮助很大，感觉我身边不少朋友就处于灵活就业状态。': array([1.], dtype=float32),\n",
       " '很多呀，提到猪八戒都知道': array([0.], dtype=float32),\n",
       " '我一直坚持在上面接单赚点外快，我身边的同事也都有在做，猪八戒网做服务众包平台十年了，在交易体系和流程上还是很完善的，比较让人放心，对于我们这些做设计的来说，能在闲暇之余赚得外快还是比较好的。': array([1.], dtype=float32),\n",
       " '我身边挺多人在上面接  活的，算是当下互联网环境中比较值得信任的一个”莆 田”了，我前不久就在上面接了个产品详情设计图的活儿，算是第一个任务吧，赚了人生第一桶金，之后会继续努力在上面好好赚 钱的，哈哈。': array([1.], dtype=float32),\n",
       " '我身边的好多同学都在用，我当然也在用，这个平  台不错的，它会把定 单 散布给更多的接  单人，人人都有机会，选择方向也更多。': array([1.], dtype=float32),\n",
       " '我们公司在入驻猪八戒网平台之后，可以说是风生水起！猪八戒网对新手服务商的扶持力度还是非常给力的。': array([0.], dtype=float32),\n",
       " '我们公司是在前年入驻的猪八戒网平台，经过在平台里两年的运营，我们的营收提高了一个大阶梯，这一年可以说，我们通过猪八戒网做得越来越好了。': array([0.], dtype=float32),\n",
       " '最近在猪八戒网购买了一个商标注册服务，服务态度和专业性还是很不错，很快就办理下来了，费用也合理': array([1.], dtype=float32),\n",
       " '我曾经在猪八戒网下过几次设计的需求，当时公司刚成立不久，没有招聘设计师，还不错，对接的服务商很耐心，改到满意为止。': array([1.], dtype=float32),\n",
       " '毕业那会儿接触过一段时间，在上面接单做过兼职，因为雇主要选择合适的服务商，竞争还是挺激烈的，真是应了那句“没有金刚钻别揽瓷器活”。': array([1.], dtype=float32),\n",
       " '贤达，我刚刚来到猪八戒，话说想开店的，不知道哪里实名认证，里面有个人，企业，学校等等都要进行认证吗？只选择个人身份认证可以吗': array([0.], dtype=float32),\n",
       " '猪八戒网上三个月收入真实吗？有的三个月就收入好几百万，这种服务网扣掉员工工资那不都纯赚，真有这么赚钱吗？': array([0.], dtype=float32),\n",
       " '当然是假的，都是店铺自己在八戒销售人员的授意下刷出来的，这你也信？为的就是吸引更多的白菜入驻': array([1.], dtype=float32),\n",
       " '这个平台会把你当“猪”一样一步一步来坑，一年交几千的会员，还有这个那个的费用，还要买关键词、刷新什么的，我开了一年会员，买了好几千广告费，结果不到三个咨询的，成交一笔都没有，白白浪费两万元，退店时还要扣押保证金，够黑的吧....！！！！！希望这么黑的平台，媒体能多曝光！': array([0.], dtype=float32),\n",
       " '挣多挣少要看自己的能力，平台上一年营收超过1亿的都有，也有不挣钱的。楼上那些说猪八戒要收费也是正常的，别个又不是做公益的，平台也要挣钱呀。所以要在平台上挣钱首先要了解平台规则，还有就是要看自己的能力了。': array([0.], dtype=float32),\n",
       " '求兼职，找副业，欢迎到猪八戒网上看看哟~': array([1.], dtype=float32),\n",
       " '“多亏了‘八戒筋斗云’，现在，我们公司客户单日增加量超过了50个，客户运营转化率也从原来的4%提升到了9%。”近日，重庆一家处于创业初期的小微企业向猪八戒股份有限公司发来了感谢短信。“八戒筋斗云”是什么？为何能让处于初创期间的中小企业迅速打开市场？带着这些问题，重庆日报记者近日采访了猪八戒股份有限公司相关负责人。“我们通过调研发现，目前，受疫情影响，传统单一的推广获客方式已经无法满足企业的发展需求。”猪八戒网企服平台事业部总经理周昱均说，中小企业普遍面临获客难，获客成本高，获客后续转化路径无法跟踪等问题。为此，猪八戒网通过一系列技术创新，于2021年开发并发布了一款数字化管理运营解决方案SaaS(软件即服务)产品——“八戒筋斗云”，赋能服务型企业数字化转型。“简单说，‘八戒筋斗云’能帮中小企业快速建立一个平台型网站——‘线上微店’。”“八戒筋斗云”产品负责人陈红解释，“这个‘微店’与一般的网店不同，它由企业自己搭建运营，不与某一特定平台独家绑定，无论是哪个平台的客户，都可以通过链接找到这个‘微店’。”该负责人解释，“八戒筋斗云”打通了流量平台之间的诸多限制，实现了一套系统全平台管理。同时，通过九种拓宽工具，降低获客难度，可帮助企业构建起专属服务数字化经营平台，进而在猪八戒网、微信、抖音、微博等流量平台同步开展经营活动。▲八戒筋斗云签约活动现场比如，“八戒筋斗云”中的SCRM管理系统，可智能化设置客户分类、来源标签，将线上线下的客户统一在SCRM系统内管理，实现企业对线上线下客户的精准分析、跟进、交付全链路精细化管理。“八戒筋斗云”还整合了百度、360、腾讯、阿里云等合作伙伴资源，帮助中小企业进行广告投放，在全域平台进行流量挖掘，进而节省企业投放成本。“‘八戒筋斗云’帮助企业实现降本增效成效显著。”陈红表示，“仅‘一套系统，全平台管理’这一件事，就可以帮企业每年节省至少40%的运营成本。”该负责人表示，下一步，“八戒筋斗云”将对服务型企业的生产、经营等企业全生命周期的需求进行深入挖掘，整合设计、软件、知产、财税等行业SaaS(软件即服务)功能痛点，从企业获客、经营、管理、安全保障等方面为不同行业打造细化解决方案。本文转载自重庆科技报作者：重庆日报记者张凌漪': array([1.], dtype=float32),\n",
       " '最近三四天了，猪八戒网站个人主页啊，站内信息啊、任务投标网页都打不开。老现实IE问题。可提交任务作品页面却能打开，也能上传。请问，这个谁有类似的情况的。麻烦告诉一下怎么弄啊！好多信留言啥的都无法给雇主回。钱也无法提取了……( ⊙ o ⊙ )啊！': array([0.], dtype=float32),\n",
       " '平台有各种各样的任务，简单的任务如给公司取名字等服务，可以多看看，选择一个适合自己的任务开始上手哟': array([0.], dtype=float32),\n",
       " '足不出户就能赚外快，程序员朋友们速来了解一下！作为中国领先的综合型数字化企业服务平台，猪八戒网上每天有大量企业发布服务需求，除了外包和全职需求外，还有很多兼职需求。今天，我们精选了近期一些软件开发的兼职需求，有意者赶紧接单赚钱吧！更多企业服务需求信息，请登录猪八戒网官网了解。1.开发APP2.Python开发人员3.海外APP开发4.海外安卓APP开发5.Java或C#编程人员6.网站维护（若上述链接打开后提示“没有权限”，说明这个需求根据精准推送的原则，没有推送给你~可以登陆兼职大厅查看更多兼职需求哦！）想要查看更多兼职机会？赶快点击阅读原文完善个人主页后去兼职需求大厅，开始接单吧~第一时间 get 兼职机会可添加客服回复“进群”即可加入官方兼职信息群~': array([1.], dtype=float32),\n",
       " '我们公司公众号的代运营就是在猪八戒网上找的，对接运营的小姐姐很专业的，品牌运营的效果很*，点赞。': array([0.], dtype=float32),\n",
       " '还行吧，十几年的老品牌了，一个中立的交易平台，上面有买家和卖家，跟其他交易平台一样，购买企业服务可以到上面去买，创业也可以在上面接单赚钱': array([1.], dtype=float32),\n",
       " '我在猪八戒网上找过设计类的服务，当时预算是3000元左右，就先来猪八戒网了解下设计价格的行情，对比了上面好几家店铺，最后我们选择了一家口碑比较好，设计风格也比较符合的店铺，最后拿到效果图的时候还是都比较满意的，预算也没有用满3000。所以我个人觉得我那次在猪八戒网上购买服务的体验还不错。当你有一个非标需求的时候，线上线下可能都有些参差不齐，这时候只能好好挑选服务商，用心去跟进进度，一定会得到一个令自己满意的结果的。': array([1.], dtype=float32),\n",
       " '中国领先的综合型数字化企业服务平台': array([0.], dtype=float32),\n",
       " '我是猪八戒网的老用户了，作为平台的雇主我觉得这个平台能满足我不同的服务需求，而且猪八戒网的服务商效率和质量确实蛮高': array([0.], dtype=float32),\n",
       " '有产品，无品牌，只会让你陷入到低水平的劳力竞争中，唯有积极打造具有客户认可度的品牌，使品牌产生溢价能力，才能获取更多资金进行自主创新，从而进入良性循环。4月26日是第22个世界知识产权日，八戒知识产权联合平台创新强企客户在微信视频号『八戒知识产权』举办首期品牌打造专题直播活动。4月26日14:00-17:00 ，TFBOYS导师、璨音文化创始人许科，重庆瀚乐思总经理曹呈辉，十七门品牌联合创始人马超，字源奇说品牌创始人颜希，四桌火锅老板老刘，5位不同领域的创业实战大咖将做客直播间，分享自己的实操经验的同时，还将与创业者和企业主共话“知识产权与品牌打造”，揭秘如何提升品牌“含金量”，帮助企业快速打造自己的品牌。直播亮点TFBOYS音乐导师许科在线演奏热门原创歌曲，分享如何才华变现。创业刷爆10张信用卡后，瀚乐思总经理曹呈辉究竟做了些什么？一口气进行全品类商标注册保护后，十七门为何又推出商标共享模式。字源奇说品牌创始人颜希：企业功能性价值已高度同质化，情感性价值正帮助消费者做出新选择。在火锅之都重庆打造一个火锅品牌有多难，老刘靠这“四桌火锅”站稳脚跟。扫码预约直播本次直播将设置7轮抽奖机会：奖品1：抽\"0元商标注册”，拥有自己的品牌；奖品2：抽“0元版权登记”，快速保护创意；奖品3：抽\"华为平板电脑”，办公快人一步；奖品4：抽“百元现金红包”，夏季财运不断。分享直播，领取更多福利：扫码上方海报预约直播，并分享该海报至朋友圈，可凭朋友圈截图领取【400电话免费使用1年+2400元话费】添加八戒小助手发送朋友圈截图兑奖分享活动：4月19日-4月25日有效据悉，八戒知识产权“4·26创新保护季”活动火热开展中，商标、专利、版权爆款服务最高直降4800元，多样知识产权维权服务限时8.8折立抢……，进一步帮助企业降本增效，走创新发展之路。有需要的老板一定不要错过。': array([1.], dtype=float32),\n",
       " '竞然，还有水军，咋洗也洗不白了': array([0.], dtype=float32),\n",
       " '别来 太垃圾': array([0.], dtype=float32),\n",
       " '可以去咨询猪八戒网客服和业务顾问，他们网站上也要服务商指南，很多教程': array([0.], dtype=float32),\n",
       " '中国企服行业，正在成为一个新的蓝海市场。相关研究机构预估，未来3-5年内，这一市场有望达到25-100万亿规模。广阔的市场前景吸引了众多玩家进场“掘金”，从分类来看，有能满足协同办公、人力资源、财税、CRM等需求的“通用型”选手，也有从各个细分市场切入试图抢夺更多企业用户的“垂直型”选手。然而入局者众，“出众”者却甚少。以垂直型企业服务商为例，即使企业用户在某个业务上定位了确定的服务商，解决了某一项需求，但对于其它业务需求，企业用户同样需要花费时间去寻找合适的服务商与其对接。这是由于大部分垂直型服务商（诸如记账、算账类企服）只能提供单一服务所致。而这种情况反馈到企业服务领域，也代表着赛道玩家的普遍形态——企服平台需要花费大量时间，去不间断寻找新客户，并且从0开始重新建立客户对企业自身的认同感。在通用型玩家领域，新近入场者类似商业查询平台衍生而来的企业服务平台，也在加速发力扩围生态版图，尽管有着数据流量支撑，却也引来了业内对其交易能力的质疑；还有一些中小型企服平台，因不健全的生态系统和有限的服务类型，导致其能聚焦的企业用户也相对有限，以致渐渐步入到经营下行的恶性循环中。反过来，在企服领域用户端，中小企业用户决策难，付费意愿低，正是由于门槛原因，大部分头部企服平台直接将中小企业用户挡在了门外。一个真实的现象是，大部分中小企业用户能够真正触达到的企服服务商，多数是代理外包公司，而这当中相当一部分存在胡乱定价、业务能力不达标的情况。猪八戒网创始人朱明跃分析，中国有上亿的市场主体，超过90%都是中小微企业，面对碎片化、离散性、低频生产性的服务时，自养或外包成本都很高。它们需要一个可靠的平台形成撮合，帮助其连接人才与服务。当然，相较于匆匆入场，企服领域更应该被解答的一个问题是——怎样在发展赛道里，为企业用户赋能恒定的成长密码，即一站式解决企业用户发展过程中需要的所有服务，因为最好的企业服务，一定是当好企业用户全生命周期“陪跑员”。猪八戒网从2006年成立至今，15年来一直在不断进化精进，从企业服务平台的角度，其集纳了2800多万个中小微企业，可提供包括营销、知识产权、财税、政治、科技、咨询等版块超过1000种企业服务，遍布企业服务全链条，为企业用户构建起从初创期、到成长期、再到成熟期的全生命周期服务平台。凭借多年来建立的平台数据能力，猪八戒网非常了解用户当下和潜在的需求，而在基础设施建设方面，猪八戒网推出了电子合同、电子发票等服务，而且投资并购了一些外部公司，包括收购了知识产权交流平台、商标监测平台、印刷公司，还投资了社保代理平台、互联网学习平台等。“通过一系列数据分析、预测和判断，我们可能比用户自己更早知道他什么时候要注册商标、登记版权、报税、做资产负债表。”朱明跃表示。满足全生命周期服务的陪伴，是一个企服平台对企业用户最长情的告白。现如今，猪八戒网这个以知识工作者（拥有各种专业技能的人才和机构）为核心的人才共享平台，已经成为重庆为数不多拿得出手的互联网名片，而未来，其势必在企服市场书写更多可能。': array([1.], dtype=float32),\n",
       " '小公司入驻猪八戒网平台我觉得真得是个非常好的选择，因为猪八戒网平台能够提供更加专业的品牌设计、技术开发、视频制作、财税等企业全生命周 期 服 务，让小公司更加省心、省力的做好运营。': array([0.], dtype=float32),\n",
       " '还挺适合初创企业和知识工作者的，使他们通过这个平台可以连接起来': array([1.], dtype=float32),\n",
       " '猪八戒网算是企服平台中数一数二的了，好几个眼熟的“网红”品牌营销推广活动其实都是找猪八戒网做的呢。': array([0.], dtype=float32),\n",
       " '我 应 该 算 是 最 早 一 批 大 学 生 自 主 创 业 入 驻 猪 八 戒 网 平 台 的 ， 其 实 在 入 驻 平 台 之 前 ， 我 也 是 做 个 人 互 联 网 创 业 的 ， 但 是 “ 收 成 ” 并 不 理 想 。 后 来 入 驻 猪 八 戒 网 ， 给 我 最 直 观 的 感 受 是 不 愁 无 单 可 接 。 同 时 猪 八 戒 网 给 了 我 们 创 业 者 非 常 多 的 支 持 ， 也 给 了 我 们 继 续 前 进 的 自 信 。': array([0.], dtype=float32),\n",
       " '我算是最早的一批通过互联网自主创业的大学生，入驻猪八戒网给我最直观的感受就是不愁无单可接。同时猪八戒网给了我们创业者非常多的支持，也给了我们继续前进的自信。': array([1.], dtype=float32),\n",
       " '奉劝各位准备入坑的小白们，不要入坑，猪八戒现在做不了了，各种费用我认了，***全是虚假标，都不审核的吗？一堆打不通电话的 ， 一堆服务商发的标。投标的钱你还不退。这也就算了，妈的一百块的标，你投标费就要收20？你把服务商都当智障了？': array([0.], dtype=float32),\n",
       " '真的恶心到了！': array([0.], dtype=float32),\n",
       " '并且投标的价格也提高了，贵的要命，现在好的订单不多了': array([0.], dtype=float32),\n",
       " '假标多。': array([1.], dtype=float32),\n",
       " '狮想堂品牌设计我们广州几个08年在猪八戒就玩威客的朋友，都聊到猪八戒。就一个相同印象：只有钱味，没人情味，老会员也好，新会员也好，给不了钱买会员，滚！买了玩不起，也滚。没有给迂回生存路走。虽生存淘汰正常，但猪八戒就是个活葬场，生着进去，跪着躺着岀来，白干几年多着去。讲多是泪，以怨报怨，就是对猪八戒最好的处理方式！没别ViviStar亮星星 2018/10/29 17:59:42嗯 太过分了 现在狮想堂品牌设 2018/10/29 18:00:30设计线下大家都有个圈的。不是猪圈，是朋友圈狮想堂品牌设 2018/10/29 18:01:08猪八戒不是一条好选的路，建议各位另辟好路ViviStar亮星星 2018/10/29 18:02:00他们急着上市圈钱 不顾一切疯狂抢钱   在账目上提高利润率   点绛 2018/10/29 18:02:33已经弃猪了狮想堂品牌设 2018/10/29 18:02:58猪八戒现在就是把双眼与良心都遮了，一个字：骗': array([1.], dtype=float32),\n",
       " '这是一个近400个服务商的维权联合群里面的服务商说的你说猪八戒网是什么样？猪八戒本来就是西游记取经团队里面的反面角色，他们取了这个名字正好就是符合了他们的特点:': array([1.], dtype=float32),\n",
       " '好好的平台让这帮酒囊饭袋搞成这样。网上就没人说猪网好的。去脉脉看看也是，才知道这个公司是从根烂的！坑完服务商坑雇主！': array([0.], dtype=float32),\n",
       " '本人刚刚结束第一笔也是最后一笔猪八戒订单，朋友要走这交易，顺便开发票，首先注册好以后不让你开店，需要交5000保证金，不交也行，申请一个什么保障金1000元，店开起来了，订单流程走完，钱90天后才能到账，想立即到账？可以，交5000保证金，保证金是能退的，只是有条件，最后一笔交易完90天后，我去年买了块表，忍了，90天等就等吧，一看服务费20%，我去年又买了块表，单子走完不但没拿到当时谈好的钱，反而还赔了好几百，猪八戒的团队真是牛啊，既能拿保证金去挣钱，又能赚雇主跟服务商的钱，是个挣大钱的主，惹不起惹不起，拜拜了您呐！去年又㕛叒叕买了块表！！！': array([0.], dtype=float32),\n",
       " '我也算常用，自己在上面找了很多服务，结婚的时候在上面找了一个服务商做方案，还比较满意，感觉还是很方便': array([1.], dtype=float32),\n",
       " '我觉得还行啊，可能我没遇到纠纷什么的吧，他们提供的服务还是杠杠的': array([0.], dtype=float32),\n",
       " '我们联合一起去消协告猪八戒怎么样': array([0.], dtype=float32),\n",
       " '猪八戒网，无比黑心的一个网站。到了关键时刻（比如说作品不满意的时候），猪八戒网会毫不犹豫的代表商家的利益和他们自己的利益，不是买家的利益。不信自己去百度慢慢 搜一搜。你就会知道猪八戒网是怎么代表商家利益和他们自己利益，而不代表买家利益的。先是会将买家的钱，强行支付给卖家。或者无期限的拖延这笔钱。如果买家要走法律程序告卖家或者告猪八戒网，猪八戒网为了快速消灭证据，就会封这个买家的注册号，或者删除这个买家的注册号。': array([0.], dtype=float32),\n",
       " '别在信猪八戒了': array([0.], dtype=float32),\n",
       " '我也彻底的不再相信它了，一个字黑。看到需求，你投标后（投标是要钱的），就联系不到。': array([0.], dtype=float32),\n",
       " '你要在猪八戒赚钱，你就先给他钱，这就是猪八戒网的规矩，投标时没中标你的钱也不会还给你，参加任务要交钱，那么服务商像雇主的报价就会高一些，所以不管你是服务商还是雇主都不要在这个平台做好些': array([0.], dtype=float32),\n",
       " '骗子还不倒闭啊，有钱烧，旁氏骗局，根本挣不到，猪八戒到处融资来维持，不知骗我们的钱，还骗政府的钱，骗投资人的钱。参考假药亭。': array([0.], dtype=float32),\n",
       " '投标需要5块钱上午冲了10块，投了一个，我看没有其他人投，然后下午打电话，人家说有人做了不需要了，于是我去找猪八戒客服，人家说钱不退，我就想爆粗口了，凭什么不退啊，这个任务又没做成，那你平白无故就捞5块钱。。。。我一个人5块，那么多任务那么多人加起来钱就不少了，这不明摆骗钱吗。。。剩下那5块我想提出来还提不出来！！！！幸亏冲的不多就当喂狗了！！！生气呀！！！猪八戒一生黑！！！': array([0.], dtype=float32),\n",
       " '刚在猪八戒签了一个霸王合同。是我自己傻不看合同。申诉完全没用 立场完全根据合同 言下之意 你签的你傻呗。建议网站审核合同 不要允许霸王条款的存在。人家一副官方的态度 哎 来这看到是这样的公司。也难怪 不可能有好的服务': array([0.], dtype=float32),\n",
       " '公道地说，猪八戒网在初创时确实提供了一个很好的平台，无论是雇主还是服务商都感觉是个很棒的！但这些年来，它逐渐偏离了它的服务本质，疯狂地逐利。功能越来越复杂有必要吗？针对服务商重复收费（服务费我是认可的），其它费用变法儿的重复收取。': array([0.], dtype=float32),\n",
       " '开始做的时候还有点搞头，那时是完成后直接扣 拥金，做不成的单也不会产生费用，好了，后来搞个3600的年费也照交了，能接单做几千元不算什么。。每月下来也有个5-6000左右收入再后来费用越来越多，成交率不高，网站操控很多定单，那时我做到猪七戒，不想做了': array([1.], dtype=float32),\n",
       " '猪八戒网员工一枚，以前觉得很好，现在越来越坑，坑客户，坑服务商，坑员工': array([0.], dtype=float32),\n",
       " '点我主页有店铺运营的经验分享，有用可以私信Q讨论': array([1.], dtype=float32),\n",
       " '入驻猪八戒7年的老服务商说句交心话，猪八戒16年之前是挺良心的，那时候年费  金牌钻石根据自己需要上，流量也大，客户成交率也高，现在猪八戒改革地区化就不好做了，基本等于自营了，即使入驻了工厂会员流量也很低，买小城市根本没用，买一二线城市中小型的服务商根本顶不住这种每个月几千的漫游费。形成不了良性发展。说实话有点失望了。有能力没单子的苦恼！': array([0.], dtype=float32),\n",
       " '希望有人在犹豫的时候能看到吧，慎入！黑心到家，流氓到家，不专业到家，霸道霸道，别再用钱与精力来作恶了！': array([0.], dtype=float32),\n",
       " '接触了一段时间，这个平台10个标里9个假，很多都是花钱投标后，雇主联系不到然后取消你的资格，联系客服，偶尔会补偿你一次限时的投标机会，注意是限时 只有一天时间，但是平台里的单并没有那么多可以让你投，因为一堆假的，就等于你花75人民币买了个假信息，这个投标的钱全被平台吃了。恶心至极，不可能再去了。': array([0.], dtype=float32),\n",
       " '骗子公司，不靠谱。': array([0.], dtype=float32),\n",
       " '今天想入得 看完头大': array([1.], dtype=float32),\n",
       " '今天刚去，上来就说要入会员才能接这个单': array([1.], dtype=float32),\n",
       " '你砸钱就有单，之前想接点单，让我交5000，一气之下自己弄了个平台，我发布的帖子就有平台地址。': array([0.], dtype=float32),\n",
       " '猪八戒网就是熟悉了政府部门的办事风格然后利用这点耍无赖骗钱': array([0.], dtype=float32),\n",
       " '猪八戒恶贯满盈只要证据充分兄弟们上中国政府网中央人民政府门户网站互动栏反映': array([1.], dtype=float32),\n",
       " '9天工期 半年没给我产品，合同签了管什么用？猪八戒包庇骗子服务商，就为了部分平台费，吃相太难看了之前不懂  前后被猪八戒套路了7-8万，老板是过去《重庆晚报》的记者，被曝光多次，平台还在运营。': array([0.], dtype=float32),\n",
       " '作为服务商，用了猪八戒一个月，花了一些钱，感觉没什么效果就来贴吧看一下，情况大致和上面说的差不多，反正就是一步一步的收费，先不给你说有哪些费用，等你先买了取经卡之后就是什么企业QQ，店铺装修，直通车，投标，城市漫游就都来了，不开可以，那没效果就不要来找我。关键是花了钱也没看到效果。销售天天给你推荐产品，客服天天爱答不理，还拽得不行，钱当喂狗了，只是保证金还要90天才能退出来，想起都头大': array([1.], dtype=float32),\n",
       " '只有使用过才有真正体会，不用不知道，一用才知道这网站服务真坑，从客服到跟进的业务，差得不得了， 注册了一个商标贵很多不说，服务差的不得，最后还要你充钱买什么会员，眼里只有钱， 我就看看这样的企业文化能撑多久的。': array([0.], dtype=float32),\n",
       " '以前入驻过，交了5000保证金，各种理由给你扣了， 主要是我店铺装修的时候不小心留了个电话，发布时包括扣得时候不提醒你，扣完了给你发个短信，我真的挺无语的，对这个垃圾网站': array([0.], dtype=float32),\n",
       " '这平台就是纯**平台  我都怀疑是他们自己发布的需求来骗投标金': array([0.], dtype=float32),\n",
       " '说多了都是泪~~我们是专业定制开发工作室，有需要可以找我们报价对比下噢，业务：微信公众号/微信游戏/界面设计/动画设计/微官网/微信小程序/移动端APP/全方位定制服务。': array([1.], dtype=float32),\n",
       " '我个人认为猪八戒网大势已去.': array([0.], dtype=float32),\n",
       " '被猪八戒网坑1800，黑！！！': array([0.], dtype=float32),\n",
       " '投标后，给雇主发短信，没人回复，打电话过去也没有人接。很坑呀': array([0.], dtype=float32),\n",
       " '猪八戒员工和客服比你爹都牛逼，还有一个客服说是他们部门领导然后口气牛逼哄哄，我说让他说出我们为啥违约，他说不出来，还让我们说爱自己上法院去上法院啊': array([0.], dtype=float32),\n",
       " '自从入驻了猪八戒网，整个人像换了人似的。以前的我是混日子，整日浑浑噩噩还是一点钱都挣不下，现在入驻了猪八戒网，每天虽然都很忙，但自己反而越来越有精神了，口袋越有钱了也越有干劲了。来自于一位入驻猪八戒网的经历分享。  以前自己也没文化，不知道啥工作适合自己，所以都是听别人说什么挣钱就干什么。三年来，钱倒是没挣下多少，工作已经换了几十个。这样的日子越过越没劲，直到有一天，听朋友说在猪八戒网上开店可以挣钱。当时已经对这样的挣钱方式不再感冒，感觉还会像以前那样碌碌无为。但朋友信誓旦旦地保证这个绝对能挣钱，看着他那有信心的样子，便抱着试一试的态度和他合伙入驻了猪八戒网。': array([1.], dtype=float32),\n",
       " '作为已经入驻了猪八戒网的店主，我在此分享自己的一些经验。当年我就业就瞄准了电商行业这块，这块必定是当下的风口，但由于刚刚接触没有任何的经验，这在竞争激烈的电商行业几乎是致命的。果不其然以失败告终，后来做了大量的市场调研与分析后，经过综合考虑选定入驻猪八戒网，入驻猪八戒网最主要的理由就是这里有客户，这里赚得到钱，很快，入驻第一个月就赚得人生的第一桶金。所以，猪八戒网对于想要进入电商市场的创业者来说绝对是一个正确的选择。': array([1.], dtype=float32),\n",
       " '现在比稿都要收费， 我直呼好家伙啊': array([0.], dtype=float32),\n",
       " '实实在在的评价，感觉稍微有用的标，2秒空，其他都是假标，投上去，雇主要么说没需求，要么说小孩子按错了，你觉得小孩子会懂这么多吗？': array([0.], dtype=float32),\n",
       " '我本人也是通过猪八戒网这个平台，结识了很多同好和各行业的尖端企业，大家互相切磋、互相学习，进步的也非常快，公司成长的也十分迅速。': array([1.], dtype=float32),\n",
       " '前 年 这 个 时 候 ， 我 们 团 队 还 在 做 区 块 链 的 相 关 技 术 开 发 。 随 着 客 户 越 来 越 多 ， 大 量 订 单 让 我 们 原 本 的 小 团 队 有 些 应 接 不 暇 ， 为 了 规 模 化 消 化 订 单 ， 于 是 着 手 创 办 了 公 司 ， 但 是 我 们 这 群 人 都 是 做 技 术 的 ， 没 什 么 开 公 司 的 经 验 ， 后 来 一 个 经 常 合 作 的 客 户 就 推 荐 我 们 入 驻 猪 八 戒 网 平 台 。 这 的 确 是 个 非 常 良 心 的 平 台 ， 提 供 的 扶 持 不 仅 能 把 我 们 的 公 司 打 理 的 井 井 有 条 ， 还 能 让 我 们 的 业 绩 继 续 翻 上 一 番 ！': array([0.], dtype=float32),\n",
       " '猪八戒网同一品威客、时间财富网、汇图网等现在比起来在比稿任务排列优化方面可以说是最差的了，汇图网比稿任务排列有个截止时间选项，时间财富网则是快结束选项，一品威客比稿任务排列则有个投稿到期选项，基本上都是让参加任务威客可以优先做快结束的任务，最高效节省安排自己的时间，而猪八戒在比稿任务排列则根本看不到这个类似选项，确实是很奇葩，不知道网页设计人员心里是怎么在想事情，根本不从参加任务威客的角度思考问题。更奇怪的事，有些比稿任务打开时已经选出了中标任务，这样的任务还放在任务列表中是准备浪费参加任务威客时间用的吗？相比而言一品威客、时间财富网在这方面做的人性化多了，已参加了的任务都会显示出已参与。这样不走心的猪八戒网，在威客网站中还能领先多久？…………': array([1.], dtype=float32),\n",
       " '大学在校生，本想在猪八戒找单子写写项目赚钱 ，投标要钱就算了，今早上刚投一个需求，花了33块钱，打电话过去问雇主，雇主直接说有人已经做了，但是他又不选标。紧接着就把订单关闭了，33块钱直接扔给平台了，不能补偿。今早上就亏了33，是不是平台的托我也不知道': array([0.], dtype=float32),\n",
       " '今年改版之后，在大厅投标变得很难，投十个标最少八个无效。包间不好用，流量也不多，已经在考虑退出八戒平台了': array([0.], dtype=float32),\n",
       " '有其它平台吗？比稿都要交钱了，网站通吃。': array([0.], dtype=float32),\n",
       " '花了20元投了一个标，给对方打电话，拒接，而且发短息也不回复，': array([0.], dtype=float32),\n",
       " '八戒做了半年，和平台内部运营沟通交流比较多，对各方面都研究比较透彻了，欢迎想做好八戒的商家一起分享交流。根据用户心理，增加真实下单主要有五个需要优化的大项。1.让雇主看到店铺2.看到后有成交量3.有咨询意愿4.客服沟通（话术、专业度等）5.雇主下单八戒平台大店的交易总额动辄几千万，单个的服务项动辄2000+，有做动作是肯定的，这样好处就是：1,雇主搜索时，看到的详情页成交量不是十位数甚至个位数（爆款单项起码500+,其他看情况即可）2.优化产能模型，这样平台才会有更多流量奖励、刷新次数等多种奖励我店铺也有做成交量、交易额、评价等各方面的优化，不做不行，做了就能解决五点中的前两点，但是也不知道有没有效果、有多大效果。各位有没有同样想法的？': array([1.], dtype=float32),\n",
       " '都是假的，我是一个资深服务商，猪八戒干的都是坑蒙拐骗，偷**狗的事儿，除了会坑服务商无止境的要钱就是会以公谋私，从上到下都是一派偷**狗，男盗女娼的事儿，从领导到员工干的就是那溜须拍马，欺软怕硬的事儿，对于服务商除了要钱就是往死了欺负服务商，大家都叫苦不迭，千万不要被骗': array([0.], dtype=float32),\n",
       " '前几年还可以，投几个标还能接点单，自今年以来，短短三个月，一个建站的投标价格从2.5站到23，接近了涨了十倍，猪八戒公司啊，你是缺钱缺疯了吧，而且很多标都烂七八糟的，我都怀疑是你自己放的假标，这就是一家独大的结果，价格垄断，霸王条款，这么作下去，服务商没活路，你们也迟早得完蛋': array([0.], dtype=float32),\n",
       " '猪八戒在作死，投标价格那么贵，你妈哟了，当年的创业初心呢，就知道吸钱。无良商家': array([0.], dtype=float32),\n",
       " '真TM奇怪了，没有政府部门管的了，当地政府也是为了地方财政吧，对这种网络平台缺乏监管': array([0.], dtype=float32),\n",
       " '2021年10月8日，八戒科技服务与内蒙古阿拉善高新技术产业开发区管理委员会签约确立升级国家高新区“以升促建”合作项目。为推动阿拉善高新技术产业开发区“以升促建”，八戒科技连同阿拉善高新区协力构建“互联网平台+专业化孵化载体”线上线下融合的创新服务体系，全力推进阿拉善国家高新区创建。1月14日下午，阿拉善盟副盟长刘德一行莅临阿拉善高新区双创孵化中心调研指导。阿拉善高新技术产业开发区党工委书记张存光，阿拉善盟科技局党组书记、局长王柱芳，八戒科技副总经理许阳等热情接待了领导一行。许阳向刘德副盟长一行详细汇报了八戒科技服务阿拉善高新区“以升促建”工作成效。他表示，八戒科技通过线下建设运营阿拉善高新区双创孵化中心，线上开发建设阿拉善高新区创新资源服务平台，围绕高新区产业亮点及特色，着力为企业提供全流程、精细化、联动式服务，构建企业梯队培育精准服务生态链。目前双创孵化中心已引进6个全国性创新机构及3个科技服务机构，为区域营造了良好的创新生态和产业生态，招商引智已取得初步成效。听完介绍后，刘德副盟长对阿拉善高新区“以升促建”工作的稳步推进给予肯定，对八戒科技平台及运营模式表示认可。他指出，希望高新区继续发展园区产业特色，深入挖掘企业需求，更好地发挥八戒科技平台作用，加快推进阿拉善高新区国家级高新创建工作，为阿拉善区域创新发展助力加码。未来，八戒科技将围绕“线上+线下”双载体运营，升级阿拉善高新区创新服务体系，做好“服务政府、服务企业、服务产业”三大服务工作，加快推进国家高新区创建短板培育与考察对接，助力阿拉善高新区创建国家级孵化平台，并打造自治区和国家级成果转移转化示范区，推动区域高质量发展。': array([1.], dtype=float32),\n",
       " '10月15日，来自天津、山东、广东、安徽、四川、重庆等地的多家猪八戒网优秀服务商应猪八戒网企服平台事业部邀请，齐聚猪八戒网总部共话平台发展，猪八戒网企服平台事业部总经理周昱均、副总经理丁然、副总经理朱万莉，以及各产品、运营等负责人出席活动，充分听取了到访服务商的多个发展建议，并与到访服务商进行深入交流。在活动现场，光荣网络创始人陈天、千界科技创始人司兵兵、百荣科技创始人尹红岩、咪狐文化创始人王海平、千问网络创始人兰显波等多位服务商代表，就今年以来在平台经营的情况，坦诚分享了自己的感受并提出多项发展建议。针对服务商所关心的问题，周昱均从平台发展、渠道合作等层面进行了充分沟通，并详细介绍了企服平台在今年第四季度和明年的最新发展规划。周昱均表示，接下来猪八戒网多措并举解决服务商所关心的问题，她邀请平台服务商积极与平台互动，携手服务好客户、做好新媒体营销宣传，以打造网络效应，共同促进平台实现更大发展。活动现场，丁然从市场投放、市场活动等层面分享了最近工作安排和规划。朱万莉则针对服务商最关注的快车、刷新、八戒企业微信等方面的问题解答了疑问。多位负责人针对服务商提出的具体问题给出解决思路，并明确工作排期。对于服务商提出的各种建议，以及在平台店铺经营过程中发现的各种问题，周昱均现场安排了相关负责人进行收集统计，并安排各业务负责人进行跟进处理，给出解决方案。现场无论是企业平台各业务负责人，还是服务商伙伴都秉承实事求是的态度充分发表了自己的意见。此次共话发展沟通会，进一步增进了企服平台和服务商之间的了解，增强了服务商对于平台发展的信心。': array([1.], dtype=float32),\n",
       " '知道呀，猪八戒王就是一个企业服务平台，企业可以通过他们解决专业服务需求的。': array([0.], dtype=float32),\n",
       " '知道啊，之前还在上面结果单，还挺不错的，最近又被种草了一个跟它类似的平台，好像叫天眼企服还是啥的，都还行。': array([0.], dtype=float32),\n",
       " '猪八戒网跟天眼企服这种平台都差不多，都是做企业服务的': array([0.], dtype=float32),\n",
       " '现在全国规模最大、做得最久的企业服务平台，上面囊括所有企业需要的服务，怎么可能不知道': array([0.], dtype=float32),\n",
       " '我有在猪八戒网找过企服业务，虽然工商现在已经开放了企业的工商资料，但是还是需要花费大量人力、时间去拼凑这些企业信息，拿到的工商数据也真的就只是数据而已，没办法进一步整合，而猪八戒网的企服业务可以帮忙解决一切问题，还是很靠谱的。': array([0.], dtype=float32),\n",
       " '我平时会在猪八戒网上发布设计的任务多一点，一般我都是直接在手机上操作的，直接根据需求选择任意分类，比如你想找人做海报就选择做设计，你想要人做文案就选文案策划，然后按照系统一步一步来，最后系统会为你自动推荐商家，你可以联系或雇佣他们。': array([1.], dtype=float32),\n",
       " '刚好碰到他们搞八八节，0元工商注册，一个月免费代账，还1块钱抢了张500的代金券，还是挺靠谱的，没有网上讲得这么黑嘛': array([0.], dtype=float32),\n",
       " '还是冲一个 会 员吧，反正也不是很贵，成为会 员后 接  活 找   外  包都非常便利的，猪八戒网算是我接触过的比较靠谱的平台了，特别棒，能够积极主动的为用户提供方便。': array([0.], dtype=float32),\n",
       " '经过本人进坑加泡吧 了解到比稿很多也是真的比稿 很多也是假的比稿 假的就不说了 挣不到钱的  真稿里面还分为雇主是真心要比稿和假心要比稿，真新要比稿的分为你中稿和不中稿 中稿分为你有没有交保证金  交了就有钱了 没交就提不出来 假心比稿指的就是雇主确实想要服务但是不想拿钱 那么他就会申请一个小号 选择自己中稿 然后把投的稿浏览一遍  又得到了好的作品 又没有花钱': array([0.], dtype=float32),\n",
       " '我大四上学期比较闲然后就开始在猪八戒网上做兼职了，当时注册了猪八戒网的账号，仅仅一个星期，就在猪八戒网接到了三个订单。第一单就是比稿出的，当时是参加猪八戒网比稿大厅的投稿，很荣幸在上传稿件的当天就得到了这位雇主的主动联系，不仅得到了客户的好评，还收到了2K元的酬劳，高兴的一晚上没睡着觉。': array([1.], dtype=float32),\n",
       " '猪八戒网全是托，大家小心': array([0.], dtype=float32),\n",
       " '托太多了': array([1.], dtype=float32),\n",
       " '好的 收到': array([1.], dtype=float32),\n",
       " '我被坑了很多钱了，都不敢投标': array([0.], dtype=float32),\n",
       " '我是觉得很多单子是假单，刷的': array([0.], dtype=float32),\n",
       " '非常多非常多，你的感觉是对的，': array([1.], dtype=float32),\n",
       " '今天出来基本假标，前几年不会，也不知怎么了，全是无效标，现在投标还要钱': array([0.], dtype=float32),\n",
       " '平台也该管管了，这样下去可不好，毕竟这个网十几年了，这样一弄，外面口碑也不好了': array([0.], dtype=float32),\n",
       " '刚开始摸索这个网 我每天只能投6个标 意向客户几乎没有 哭啊': array([0.], dtype=float32),\n",
       " '真心垃圾 早放弃': array([0.], dtype=float32),\n",
       " '我最近投了10个标，9个雇主不需要，压根没发布过，不需要为啥要发布，': array([0.], dtype=float32),\n",
       " '完全赞同！认证完才发现！这个要交钱那个要交钱你就是一个垃圾app！': array([0.], dtype=float32),\n",
       " '行业领头羊，不至于吧': array([1.], dtype=float32),\n",
       " '假标特别多是真的。': array([1.], dtype=float32),\n",
       " '几年前上当买了猪八戒网的19800的会员，被坑得死死的，各种条款都是以八戒有利来写的，今年的猪八戒越来越厉害了，群里在讨论猪八戒现在现在雇主和服务商联系，只能买180/月的八戒QQ，还有60/月的八戒呼呼，才能很快的联系到雇主，雇主那边也是经常不能及时的联系到服务商（第一次使用猪八戒的人八戒QQ网页入口，APP入口都很难才能找到），猪八戒上面的领导班子真是雁过拔毛，两边都想赚，我也是第一次听到有服务平台要联系费的，好比如淘宝你买个包包，下单了，客服给你发消息淘宝平台要收钱，你给客服发消息，找不到发消息的地方。太恶心了。': array([0.], dtype=float32),\n",
       " '和楼主一样一样的，每一个环节都要先给钱，这样算下来兼职的辛辛苦苦一整年很大可能连本都回不了，猪八戒这个平台真的让我呵呵了': array([0.], dtype=float32),\n",
       " '别说猪八戒了，2013年后，连淘宝也退出了——虚拟服务平台，大部分服务就是中间商两头吃的平台。': array([0.], dtype=float32),\n",
       " '那么缺德吗': array([0.], dtype=float32),\n",
       " '我真的服了  直接打电话过去很尴尬  就保留之前免费的交流平台类似淘宝那样的不行吗  连联系都要收费  真的绝了  无****说': array([0.], dtype=float32),\n",
       " '平台的商家对猪八戒平台的评价有好有坏，关键是在平台的运营好与不好，半年的时间已经是八戒精通运营的招商运营的负责人，运营的商家无一不是八戒优秀的服务商，欢迎各位一起来探讨如何经营（玩转）猪八戒！！！': array([0.], dtype=float32),\n",
       " '现在离职了吧 哈哈在八戒你真的没前途，没钱途': array([1.], dtype=float32),\n",
       " '入驻猪八戒网，我最大的感受是第一有钱赚、第二公平、第三有盼头。简单说来，就是站着把钱挣了，并且在将来能挣更多钱！“从游戏爱好者到软件创业者“我们这一代人通过游戏了解了计算机，我从小就对计算机的软硬件特别着迷。”作为一位标准的“90后”，郎奇凡从电脑游戏启蒙入行IT行业，并于2015年在深圳成立了一个软件开发工作室，通过学校老师以及家庭关系等资源的介绍，承接一些软件开发的业务。没想到这条路被郎奇凡越走越顺，团队的规模也越做越大，最终成立了重庆新光互动科技有限公司。“疫情，让公司命悬一线谁曾想，2020年初爆发的新冠疫情，让郎奇凡原本顺风顺水的创业之路陷入了困境。“那段时间，公司已是命悬一线！”至今回想起当时的情景，郎奇凡还有些后怕。原来过去这些年，新光互动一直在重点经营线下业务以及各地政府的业务。“疫情爆发后，我们的线下业务受到了重大冲击，同时政府也因为财政等方面的压力削减了部分订单。”多重因素的影响下，公司业绩骤降。“6年前的无心插柳派上大用场关键时刻，郎奇凡多年前无意种下的一颗种子开始萌芽，“我想到了自己在猪八戒网上还有一个店铺。”郎奇凡口中的这个店铺注册于2015年，一直基本处于放养状态，没有进行任何经营。疫情期间线下商业活动难以进行，郎奇凡计划全面转型线上发展，而这个6年前注册的店铺，则成为此次行动的重要突破口。为此，郎奇凡花了长达半年时间的了解猪八戒网平台。直到2020年7月1日，新光互动才决定正式启用猪八戒网的店铺，迈出了转型线上第一步。“最开始其实没抱太大希望，毕竟猪八戒上经营竞争大、线索有限，尤其是现在猪八戒已经是一个成熟的平台了。”不止是郎奇凡，整个团队都在担心像新光互动这样新加入的服务商没有数据、没有名气，是不是很难在平台上生存下去，更何况近几年市场经济都很萎靡。在这个过程中，猪八戒网的招商服务人员蒲文晋，给了这支团队很大信心。“加入猪八戒后，由于对很多规则不了解，新光互动也犯过错，甚至还曾受到平台的处罚，但文晋一直对我们不离不弃。”据郎奇凡介绍，蒲文晋经常主动帮助新光互动解决难题，比如帮助他们进行商务培训，指导店铺运营等。2020年，为了响应“六稳”“六保”号召，猪八戒网推出了一系列新服务商扶持帮扶政策，在蒲文晋等猪八戒工作人员的耐心辅导之下，新光互动凭借自身过硬的实力，斩获了让人惊喜的成绩——从开店至今已经完成了1500余万的销售额，团队也从最初的10来个人扩充到了30人，后期很快将突破40人，公司发展蒸蒸日上。“站着把钱挣了”至今，郎奇凡还清楚记得公司在猪八戒网上的第一个订单，“那是重庆沙坪坝区的一家汽修门店，客户做一个汽修会员管理小程序。”他告诉我们，这个客户至今都还在使用新光互动开发的软件。谈到这一年的逆风翻盘的经历，郎奇凡很是感慨：“非常感谢猪八戒网给与我们公司一个良好的生态环境。”他表示，入驻猪八戒网，自己最大的感受就是第一有钱赚、第二公平、第三有盼头。“简单的说，就是站着把钱挣了，并且在将来能挣更多钱。”通过猪八戒网这个平台，郎奇凡还结识了很多同好和各行业的尖端企业。在2022年，郎奇凡计划让公司在猪八戒平台继续深耕，已经准备全面接入猪八戒公采业务，为政府提供专业的服务。': array([1.], dtype=float32),\n",
       " '猪八戒的吃相确实越来越难看，对服务商层层搜刮老牌会员注册10年以上，全靠比稿到这个级别。投标模式   雇主没托管一分钱，投标就要交这些钱，且不退，你说狠不狠。比稿模式  现在只要交稿就扣钱，这样搞你觉得服务商不会跑？': array([0.], dtype=float32),\n",
       " '今天刚看到比稿付费  我也是惊了    真是不想活了吧？': array([0.], dtype=float32),\n",
       " '我曾经是个服务商，接了近20单，一单钱都没赚到，投入产出比奇低。付出和回报完全不对等。有这个经历和时间，干点什么都比搞猪八戒好。': array([0.], dtype=float32),\n",
       " '这个就是一个企业服务平台，他们这个平台自成立以来，就给全国大中小型企业提供了非常优质的服务，口碑特别好。': array([0.], dtype=float32),\n",
       " '猪八戒网值得信赖吗，靠谱不': array([0.], dtype=float32),\n",
       " '这么大一家公司 不能不靠谱吧': array([0.], dtype=float32),\n",
       " '听说不靠谱': array([0.], dtype=float32),\n",
       " '我找的八戒财税，简直无语，多交了五千多的税': array([0.], dtype=float32),\n",
       " '怎么说呢，靠百分之八十的谱吧。但是好像他们负面特别多，但是我自己遇到的服务商还是挺好的': array([0.], dtype=float32),\n",
       " '比其他的靠谱': array([0.], dtype=float32),\n",
       " '相对于而言还可以': array([1.], dtype=float32),\n",
       " '靠谱个鸟蛋，两边吃！！！': array([0.], dtype=float32),\n",
       " '我运气好？遇到的服务商挺好的啊，很负责': array([1.], dtype=float32),\n",
       " '表示非常认同，她们平台个人服务商因为猪八戒收取20%的中介费，然后重庆水务局又收取17%的税费，20000多的合作，要收走40%的费用.......结果人家服务商不愿意开票，猪八戒还不退款！！！ 流氓啊': array([0.], dtype=float32),\n",
       " '我觉得还可以': array([1.], dtype=float32),\n",
       " '没用过的人会问这样的问题，用过的人就不会再用，夸它的全是托，不管是雇主还是服务商，它都要宰，贪得无厌的pig。倒闭只是时间问题': array([0.], dtype=float32),\n",
       " '不靠谱': array([0.], dtype=float32),\n",
       " '我猪六戒，不想做了，规则太多，交易流程太复杂，用过一次的客户都不用了。平台收取费用三天两头变，简直无语。': array([0.], dtype=float32),\n",
       " '不靠谱，我在猪八戒网': array([0.], dtype=float32),\n",
       " '真的不靠谱，我的一个专利评价报告一个多月了还没递交，而且客服猪脑子一样。': array([0.], dtype=float32),\n",
       " '旁氏骗局，别TM上当了，比1040西部大开发传销，只不过多了一个平台，你交了钱，是难以赚到钱的合法传销平台。': array([0.], dtype=float32),\n",
       " '感觉严重的不靠谱': array([0.], dtype=float32),\n",
       " '打电话问客服“雇主说不需要，发订单就是发着玩呢，这种问题怎么解决”客服说“你提供下订单号，我们这边查一下”我说“查了之后怎么解决，”客服说“没有了呀，就是查一下是不是假的”我花了几十块钱换了所谓的雇主一句话发着玩呢，客服说，仅仅验证一下订单是不是假的，呵呵呵了，没睡了，上哪说理去': array([0.], dtype=float32),\n",
       " '八戒没去西天，坠入魔道了！名如其形，天下第一“🐷”': array([0.], dtype=float32),\n",
       " '入驻猪八戒7年的老服务商说句交心话，猪八戒16年之前是挺良心的，那时候年费 金牌钻石根据自己需要上，流量也大，客户成交率也高，现在猪八戒改革地区化就不好做了，基本等于自营了，即使入驻了工厂会员流量也很低，买小城市根本没用，买一二线城市中小型的服务商根本顶不住这种每个月几千的漫游费。形成不了良性发展。说实话有点失望了。有能力没单子的苦恼！': array([0.], dtype=float32),\n",
       " '别的不说，之前赚了100，到现在我都没收到钱，需要交5000保证金才能收到钱，就问你怕不怕': array([0.], dtype=float32),\n",
       " '最不靠谱': array([0.], dtype=float32),\n",
       " '很多人被骗的，千万别走这个平台': array([0.], dtype=float32),\n",
       " '早就不是以前的猪八戒了，想钱想疯了，还有乱七八糟的界面没见过这么差的。你要投标先交钱，想不交钱也行，开通888元的会员。我钱没赚到，倒要先给你们送钱。吃了原告吃被告。还到处打着互联网创新的名义到处招摇。想要我交1分钱，做梦去吧。': array([0.], dtype=float32),\n",
       " '几个月前下了一个任务，7000元钱，还没有解决好纠纷问题。服务商的好评满满的，这是怎么来的？我真是无语了，水平差的不能理解！ 我以后再也不在这上面下单 了！': array([0.], dtype=float32),\n",
       " '不靠谱。说猪八戒靠谱的都是上面的商家。我在上面找过人开发软件，结果被骗了钱，所以证据都能证明对方欺诈，结果猪八戒就是不给赔偿，坑人呐': array([0.], dtype=float32),\n",
       " '还行': array([1.], dtype=float32),\n",
       " '辣鸡的一批，比稿模式都要交钱的了才能投，两头坑': array([1.], dtype=float32),\n",
       " '现在比稿都要交钱了劝退小服务商': array([0.], dtype=float32),\n",
       " '几年前，猪八戒网刚上线的时候，我就已经是首批用户！其实猪八戒网的模式是原K68的威客模式，一个任务平台！对接需求方和供应方的平台。对需求者来说，只需要设置好预算，就有若干个设计师提供多种设计方案，需求者再从众多方案中选出自己心仪的方案即可！这样的一个流程，对需求者来说，只需要付1份设计费，却可以得到多种思路和风格的稿件，这是单纯找一家设计公司所不能提供的。自然而然，哪个平台拥有够多的设计师，哪个平台就能得到更多的任务。因为早期的K68平台阿男的执着而没有及时转向导致了没落，所以大量的设计师、程序员转战猪八戒。所以猪八戒很快就站稳了脚跟，我也陆续在上面获得了足够的稿件。随着猪八戒获得了融资，似乎认为收取平台入驻费比收取任务佣金要来钱更快，居然逐步弱化了任务功能，甚至一度我也找不到发布悬赏任务的入口。当时我就觉得，猪八戒网可能不行了，因为他已经将获取利润的砝码偏向了设计公司，导致大量的设计公司入驻，但是却基本上没有需求者发布任务。平台AB角色出现了巨大的失衡，慢慢的就会被需求者所遗忘——至少我已经有1年多没去关注猪八戒网，而是转战一品威客平台发布任务。今天再回头去看了下猪八戒网，虽然主导航条增加了任务大厅的入口，表示运营方应该看到了任务模块的重要性了。但是如果依然弱化任务功能，停留在收取平台入驻费，相信猪八戒网不久矣。人才共享模式并非只是加入我的园区，进入我的平台，交各种会员费和入驻费。': array([1.], dtype=float32),\n",
       " '现在有没有什么新的众包平台？不要一来就交钱的那种，我都实名了搞不懂还交钱干嘛': array([0.], dtype=float32),\n",
       " '哎，不砸钱没有流量，砸钱了也不一定有单。难啊~~': array([0.], dtype=float32),\n",
       " '老铁有心了。平台是口塘，用户是水，服务商是船。  收船主钱的前提是：这船还能在水里划！！！': array([0.], dtype=float32),\n",
       " '本来就是垃圾，坑人的': array([0.], dtype=float32),\n",
       " '这话 说了好几年了  他却越来越好  你说气人不': array([1.], dtype=float32),\n",
       " '这个平台遇见供求争议只会推卸责任': array([0.], dtype=float32),\n",
       " '越来越不行了': array([0.], dtype=float32),\n",
       " '开始两头收费了': array([1.], dtype=float32),\n",
       " '自己办太麻烦了，还是找专业的靠谱': array([0.], dtype=float32),\n",
       " '八戒能做到那么大，还是有他自己的优势的': array([1.], dtype=float32),\n",
       " '投标后 钱不退。': array([0.], dtype=float32),\n",
       " '第一次使用这个，然后就投标了，打电话过去是个女人接的，说是她晚上的时候随便弄的，根本不需要服务，她也不清楚那个东西是什么，然后客服电话打不通，人工客服让我申请补偿，结果申请了之后不给补偿，非常坑。                                \\n                \\n                    \\n                        星座王\\n                            \\n                               \\n                            \\n                        \\n                    \\n                    \\n                        点亮12星座印记,去领取\\n                    \\n                    \\n                        活动截止:2100-01-01\\n                    \\n                    去徽章馆》': array([0.], dtype=float32),\n",
       " '确实是坑啊，充了钱，投标聊天还得开企鹅mm，一年1800，不然不让和客户聊天，无语': array([0.], dtype=float32),\n",
       " '一个三五百的标，投标金额几块钱，未中标的投标金退不了，钱全部被平台赚了，设计师赚个毛线，而且中标还要抽成，一堆虚假标就不说了，还要各种这个费那个费。': array([0.], dtype=float32),\n",
       " '只有冲钱给他割，想退钱没门': array([0.], dtype=float32),\n",
       " '看完各位的评论，我觉得我还是不要搞这些了，安心做我的淘宝估计都比这靠谱。': array([0.], dtype=float32),\n",
       " '以前是扣掉交易总数的20%，但那也是交易成功之后扣的，还能理解，现在这是先给钱，还不一定能成交': array([0.], dtype=float32),\n",
       " '这次猪八戒网八八节除了有特惠加超低价格秒杀外，还有许多创业福利赠送，例如超值套餐，很多平日里单买的服务做了打包，价格便宜了一半多。还有免费的企业问诊，官网介绍由行业专家和金牌创始人组成的102位问诊嘉宾帮助创业者免费规划公司发展，这种福利肯定是不能错过的，另外还有直播课和线下峰会可以参加。但我们小工作室反而注意到了那88套免费赠送的创业工具，一开始还以为没啥用，因为领取过程太简单了，只要关注了公众号就行。可当我打开的时候，没想到如此良心！福利包里面有各个行业的前沿研究报告以及各类信息汇总，比如我们公司正好缺少很多企业的法律材料和协议，没想到福利包竟也送了好多。还有很多的合同模板以及总结计划之类的材料，基本上满足了从创业开始到走上正轨的发展刚需，对刚刚创立的企业绝对是一份不能错过的福利。还没领取的朋友，赶快冲一波，非常具有价值哦！': array([1.], dtype=float32),\n",
       " '猪八戒从上到下，从员工到高管，一派乌烟瘴气，干的都是坑服务商坑客户些事儿，有啥问题了，客服那态度叫一个强硬，反正就是话里话外就是自己很牛逼，说自己是部门主管，****，让我们不服上法院去，从来不懂得尊重客户，一字不和就要扣你保证金，我们说要换人去调节，告诉我不可能，我们问哪里违约了，说无可奉告，客服的态度让我们觉得猪八戒就是天王老子，这地方没法说理，你交了保证金交了会员费，会想办法给你抠光，那领导不知道是啥领导了，我们也是服了，大家不要上当受骗': array([0.], dtype=float32),\n",
       " '以前八戒通、钉耙卡都存在不超过一年，那个888超级会员才出现几天就不见了': array([0.], dtype=float32),\n",
       " '猪八戒三十六变你难道是不知道？目前会变的趋势已经超过孙悟空了。': array([0.], dtype=float32),\n",
       " '威客网站有排名的也就那么几个，现在的威客网是越来越多，很多人都想在威客平台上找兼职坐任务来满足自己的需求。但现在的威客网站这么多，要怎么取选择呢？这是现在很多人想入驻威客平台的一个疑问。一个威客平台的发展，有好的平台，也有些平台可能发展的要稍微差一些。不过不用担心该怎么去选择威客平台。四海方城威客网也是现在新型的威客平台，他在威客平台中的排名是在逐渐上升阶段，不管是商家免费入驻，还是商家该怎么找兼职做任务，这个平台都能有效的帮大家解决。': array([0.], dtype=float32),\n",
       " '吃相越来越难看了，小心被骗！！！': array([0.], dtype=float32),\n",
       " '我就想问问app. 上面的那些需求有几个是真的？？我投了几个标，到现在都还是待选标嘚，打电话问别个，别个说是假的，我靠，，，这玩意儿靠谱？？？？点击展开，查看完整图片': array([0.], dtype=float32),\n",
       " '都是骗子，猪八戒离倒闭不远了': array([0.], dtype=float32),\n",
       " '为什么现在都是无效标，平台也不管的。和前几年没法比，那时候投标免费，一天投十几标都可以，而且都是有效标。对于我们老服务商来说，真的有点失望，本来还想一路追随…': array([0.], dtype=float32),\n",
       " '真的是太难了': array([0.], dtype=float32),\n",
       " '猪八戒这种垃圾平台，基本上是资金一托管，就掉坑里了。本人被骗3000元。猪八戒网纵容服务商诈骗客户！': array([0.], dtype=float32),\n",
       " '传统生意转战线上成王者,猪八戒网创业者的王牌人生!\\u3000\\u3000在没有入驻猪八戒平台之前,九界公司是一家一直平稳发展的传统广告公司,他们成立多年,一直有着固定的客户,但是随着广告公司的竞争激烈,尤其是时间到了2017年,传统品牌设计公司受地域和经济大环境的影响,企业发展需要更多的商机,业务转型迫在眉睫。\\u3000\\u3000自己就是做营销出身的,却在市场的大环境下被冲击得不得不再想出路,这是九界品牌创始人刘炜东没有想到的,在这种情况下,刘炜东不得不去寻找一个更适合公司发展的出路。\\u3000\\u3000一次偶然的机会,九界品牌创始人刘炜东了解到了猪八戒网。“我在猪八戒服务全世界”的共享经济模式,可让企业足不出户极大扩宽服务半径,这让正在寻求转型良方的刘炜东产生了极大兴趣。\\u3000\\u3000十年的创业经验,早就练就了刘炜东做事事无巨细的风格,要做就要做到为,为了让公司在猪八戒网的形象一下子树立起来,东久广告线上品牌“九界品牌设计”正式成立,迈开了公司“互联网+”的转型升级。入驻猪八戒网以后,刘炜东也跟着平台的节奏一起,开始为公司创建起现代化的服务体系和标准。\\u3000\\u3000于是,多年积累,一朝爆发,入驻猪八戒网以来,九界设计服务了诸多品牌,国民品牌稻香村便是其中之一。通过品牌诊断与市场调研从营销端为稻香村策划出一套完整的品牌升级方案,从品牌定位与消费群体定位5步走:从提出“中国人的中国糕点”超级广告语,将稻香村作为中国传统品牌与200多年悠久历史的信息融入到广告语中,引起国人的自豪感和认同感,让国货回潮,到卖场新升级,引用苏州园林的设计风格,结合现代灯光排布与货品陈列设计,将历史与现代完美结合,从把产品重新分类,满足不同年龄段的消费需求,到新的VI形象,将花好月圆融入其中,传达出幸福美满的品牌新形象。\\u3000\\u3000通过与猪八戒网携手,加上新的营销思路与平台推广,九界对稻香村的营销方案支持,让稻香村销售额增长了2倍。也因此,稻香村的品牌升级荣获了有全球创意设计奥斯卡之称的2019 IAI国际广告奖—铜奖。\\u3000\\u3000互联网迅速发展的今天,九界品牌紧跟时代,积极拥抱互联网,入驻猪八戒平台,凭借多年积累的服务经验与系统化的服务标准快速发展壮大,为更多企业战略发展保驾护航,真正做到了“服务全中国”。\\u3000\\u3000“先把事情做对,再把事情做好”也是我们的经营理念,猪八戒网的品牌愿景就是这样,也因此一直保持着极高的专业度,满怀热爱去服务企业、服务品牌、服务未来。': array([1.], dtype=float32),\n",
       " '做兼职还可以': array([1.], dtype=float32),\n",
       " '拉倒吧  真的垃圾 我做了三个月 除了叫交钱就是交钱  根本没有流量 交了钱也没有 一天就两三个浏览': array([0.], dtype=float32),\n",
       " '心好累啊，咨询的还要不知道是拖还是什么的': array([0.], dtype=float32),\n",
       " '企业客户，有这么多咨询还是很不错了。想想去百度获得一个客户要花多少钱？线下获得一个客户要花多少钱？知足吧少年': array([0.], dtype=float32),\n",
       " '这网站是骗人的，千万别去  亲身经历   巨后悔': array([0.], dtype=float32),\n",
       " '别发布了，坑人的网站。我发布了一个LOGO设计，托管1100元，交稿了114篇，猪八戒官方最终通过审核的仅为4篇且质量惨不忍睹，结果找网站110，400电话、重庆官方电话，电话打了十几个，后台个个柔声软语就是不解决问题，只会谈流程……钱还在他们手上没退，网上很多差评。': array([0.], dtype=float32),\n",
       " '说一个我看到的，比较有意思的案例，重庆一家叫“汉国软件”的公司，通过开发面向县镇下沉地区的智慧水务系统实现了商业模式的升级。对于县镇市场的中小企业而言，规模较小、技术缺乏，依靠自身实现数字化转型实在太过艰难，但同时，随着移动互联网的普及，“小镇青年”也期望更好、更便捷的服务，这些地方中小企业往往感觉自己落后一大截。一些在大中城市从事技术服务的中小企业又何尝不想转型，在大中型城市，软件开发已经是非常成熟的市场，互联网巨头的技术和服务能力输出更是带来一波又一波的降维打击，竞争激烈，也在渴求寻找全新的蓝海市场。于是在某区的这家水厂就通过猪八戒网找到了汉  国软   件公司，希望开发一套水量监测软件，用于提升节水效率。凭借多年在线提供技术服务积累的经验和团队实力，汉  国软  件轻轻松松就完成了项目。同时还举一反三，将项目成果进行复制和串联，想成了一整套专门针对县镇中小水厂的智慧水务系统，实现了从技术服务到商业模式打造的完美跃迁。这个案例给中小企业提出了一个不错的思路，拥有数字化解决方案（技术）的中小企业和团队可以通过类似猪八戒网这样的服务交易平台链接更广泛的市场，特别是下沉市场的中小企业，基数足够大，需求广泛，痛点明确，可复制性极强，是非常值得探索和发展的蓝海市场。': array([1.], dtype=float32),\n",
       " '贴吧ID：mgymmh 骗纸，拿了碇金不做事点击展开，查看完整图片': array([0.], dtype=float32),\n",
       " '骗子小人行径，没有那个金刚钻别揽瓷器活，接了不说还收了定金，只做了个开头，完不成你说一声，到了期限，信息不回，语音不接，还直接把我拉黑！此人人品有问题，大家谨慎，把自己的事情交给这样的人很耽误事啊！': array([0.], dtype=float32),\n",
       " '敢做不敢当，截了两张图就断章取义的自我安慰，是心理不健全，还是不敢面对啊？取之不当用之不顺，懂吗？你的人格也就值250元？！': array([0.], dtype=float32),\n",
       " '建议走正规平台': array([0.], dtype=float32),\n",
       " '骗子都有客户 我们正规公司饿肚子': array([0.], dtype=float32),\n",
       " '还是走平台交易比较靠谱，比如小鱼儿网。': array([0.], dtype=float32),\n",
       " '投诉他去': array([0.], dtype=float32),\n",
       " '我也遇到无赖的雇主， 项目做好了，雇主找理由耍赖。 准备资料明天申诉': array([0.], dtype=float32),\n",
       " '不可能,都是先托管在开工的,猪八戒规则不管雇主满意不满意至少50%跑不了': array([0.], dtype=float32),\n",
       " '是猪八戒没给你钱': array([0.], dtype=float32),\n",
       " '所有的付出都会有回报，三个月的坚持换来月五萬的结果，带徒': array([0.], dtype=float32),\n",
       " '服务真的差，这里有官方的领导的话可以看看，你们的下属是这么干的，还是是领导指示这么服务雇主的呢': array([0.], dtype=float32),\n",
       " '现在聊天也限制，让你用腾讯企点，不交钱用不成的。哎。我现在只想把我的保证金退出来。但难度不小。有几个订单，雇主根本联系不上，已经中标了，网页却找不到申请付款的功能，这样你这个订单就始终不能完成。好阴暗啊。': array([0.], dtype=float32),\n",
       " '是倒闭了赖账了?': array([0.], dtype=float32),\n",
       " '学生还是不要在这上面接兼职了   要你交5000保证金  而且每次投标没中也不会退钱  与雇主联系还要买180/月的企业qq  给雇主直接打电话都是说不需要了或者说已经取消了订单了  我觉得这个平台太坑了': array([0.], dtype=float32),\n",
       " '投标基本不怎么靠谱，还要给投标费，点了投标别人还不一定用你，烂费了钱': array([0.], dtype=float32),\n",
       " '个人想接点活儿干，猪八戒不行，大家有没有好的渠道啊，大佬们': array([0.], dtype=float32),\n",
       " '个人还是要慎重，很容易掉坑里。我们是专业定制开发工作室，有需要可以找我们报价对比下噢，业务：微信公众号/微信游戏/界面设计/动画设计/微官网/微信小程序/移动端APP/全方位定制服务。专业H5互动定制开发，5年资深开发设计，满意为止': array([1.], dtype=float32),\n",
       " '我劝你卸载吧，这个平台不可靠，你会被榨干的': array([0.], dtype=float32),\n",
       " '感觉这个就是个骗子。点击展开，查看完整图片点击展开，查看完整图片': array([1.], dtype=float32),\n",
       " '客服都没有': array([0.], dtype=float32),\n",
       " '厉害啊！一个2500的项目，投标需要50，客户那边确认要做了，过两天客户说点错取消了，然后又叫我重新投标（因为确认我们做了），投标后（50块），客户拖了几天，现在连回复都不回了，去搜索订单号也搜索不到，一直在任务里面，来来回回用了100块，时间差不多半个月，这就是猪八戒？？': array([0.], dtype=float32),\n",
       " '你自己联系的雇主不甩你了  你就怪猪八戒？？': array([0.], dtype=float32),\n",
       " '注销了，再也不用这类的东西了，搞不懂': array([0.], dtype=float32),\n",
       " '起码80%多少假的': array([0.], dtype=float32),\n",
       " '只能说优质的单很少很少，而且一般拿不到我们是专业定制开发工作室，有需要可以找我们报价对比下噢，业务：微信公众号/微信游戏/界面设计/动画设计/微官网/微信小程序/移动端APP/全方位定制服务。专业H5互动定制开发，5年资深开发设计，满意为止': array([1.], dtype=float32),\n",
       " '平台废了': array([0.], dtype=float32),\n",
       " '真的这个平台很坑，可以跟P2P比肩了吧，我是新手，一开始不知道怎么点了需求，我以为是赚外块的，后来有电话打过来问我是不是要图片处理，我说不是，然后我看了一下，我确实招标了，我马上取消掉，几天后再看，***还在给我招标，这他妈就是平台在忽悠大家的钱，真不明白这样的APP怎么审核得过去，居然能上架，***了。': array([0.], dtype=float32),\n",
       " '各种坑钱': array([1.], dtype=float32),\n",
       " '所有的免费都不是免费 都是有条件的  平台总是说虚的  客服就这**态度': array([0.], dtype=float32),\n",
       " '名义上是保障客户利益，实际上交了保证金，很难再取出来。猪八戒会以各种理由给扣掉，投诉都不管用的，重庆的龙头企业，后台很硬。': array([0.], dtype=float32),\n",
       " '看来自打融资以后猪八戒坑服务商这招是越来越严重 还好2年前就不做了 苦海无涯尽早脱离猪八戒': array([0.], dtype=float32),\n",
       " '今天又收到猪八戒坑钱短信，我直接回复4个字：': array([0.], dtype=float32),\n",
       " '这种网站没大前途,想海外上市人家调查下来不要,国内上市也不可能,威客网的机制是病态的': array([0.], dtype=float32),\n",
       " '我也是过来人，真的坑': array([0.], dtype=float32),\n",
       " '别缴费，感觉现在到处都是坑了                                \\n                \\n                    \\n                        星座王\\n                            \\n                               \\n                            \\n                        \\n                    \\n                    \\n                        点亮12星座印记,去领取\\n                    \\n                    \\n                        活动截止:2100-01-01\\n                    \\n                    去徽章馆》': array([0.], dtype=float32),\n",
       " '神州处处都是坑': array([0.], dtype=float32),\n",
       " '一大片全是这样的，完全不知道是个啥，这是不是就是猪八戒的拖来骗投标费的': array([0.], dtype=float32),\n",
       " '贴吧这么冷清，这平台是不是落寞了，网站需求也是翻个两三页就是2016年的单子了': array([0.], dtype=float32),\n",
       " '很多骗标的，我投了200元，真实客户很少，还有狠人各种套话，浪费时间，浪费钱。这两个标刚刚发布的就电话停机，昨天看到他发布一个三川科技的logo，50元，各种理由托，电话客服，让猪八戒110投诉，点击投诉需要用户名，贼坑。上市了，不坑服务商的钱，没办法做报表。': array([0.], dtype=float32),\n",
       " '这么大的项目，放到平台上来接来谈妥吗？还不如找个中间人让人家抽1%。。。。': array([0.], dtype=float32),\n",
       " '这些死中介，阿里，滴滴，美团，做个平台大吸实业血液': array([0.], dtype=float32),\n",
       " '僧多粥少啊，这样发需求会补被挤爆的功能定制型的找我，他们做不了的请找我，他们做了没售后的请找我。只求展示和只看设计图的别找我，太感性的没标准沟通太累': array([0.], dtype=float32),\n",
       " '猪八戒企业客服推荐的服务商，修一张图要一周。。。效果还达不到。。。要改变修图方法，就要加钱！！要取消服务，钱退不了。。（这个是我傻了，太相信猪八戒，合同里竟然有不退款这一项，而我却没看合同就签了）。。        修出的图片效果，简直了，PS初级水平不如，美图秀秀处理的都比这服务商修的好。。。        最后，客服告诉我通过他们不懈努力，最后服务商要求退90%。。。        给我的感觉是什么呢？就是这个服务商，随随便便处理下图片，逼我取消合同，付违约金。。。        失望，太失望，恶心！！没下次了！！': array([0.], dtype=float32),\n",
       " '最后还是扣了一百。。。恶心': array([0.], dtype=float32),\n",
       " '想问楼主，为什么猪八戒比稿模式那么多烂尾的，也就是雇主交了钱最后钱也不要了也不来选稿，最后系统选稿的。我投稿的有一半烂尾了。还有系统排名是按什么规则排的？有的连基本要求都不符合的竟然也能被系统选稿选中，感觉猫腻甚多。': array([0.], dtype=float32),\n",
       " '猪八戒什么时候申请破产清算啊，八戒资金转到什么行业里去了,八戒能混过2020年嘛': array([0.], dtype=float32),\n",
       " '感觉猪八戒网变了好多。。。': array([0.], dtype=float32),\n",
       " '没交保证金的话中标的赏金就不能提现吗？为什么我在比稿大厅里看到有些做到八戒、九戒、十戒的也没交保证金？他们不提现的吗？': array([0.], dtype=float32),\n",
       " '我想做推广，都找不到人接单了，真是，都发布不了任务！': array([0.], dtype=float32),\n",
       " '啥时候可以变回最初的猪八戒啥时候回去，那时候猪八戒也不少挣吧，百分之二十呢，投标的不管是新手还是老牌公司都也都能赚到些钱，现在.........': array([0.], dtype=float32),\n",
       " '起名的容易被骗稿，遇到过几次了': array([0.], dtype=float32),\n",
       " '资深服务商变黑粉，眼看他起高楼，眼看他楼快塌了，猪八戒撑不到2020年的。': array([1.], dtype=float32),\n",
       " '保证金能退就退吧，别犹豫': array([0.], dtype=float32),\n",
       " '我冲过；基本上都被套走了；以前投标猪B不成功的还可以申请退款；现在连退都不退了；直接送一次机会；现在是个什么情况吧；无论你投标花费多少成于不成无论是何原因；这个钱永远不会退你的 ；就是这么坑  我冲了好多了 ；不会再玩了  扼杀廉价的设计': array([0.], dtype=float32),\n",
       " '别入坑，骗子公司。': array([0.], dtype=float32),\n",
       " '好福利': array([1.], dtype=float32),\n",
       " '还有，怎么扣了那么多钱啊！！！！好坑啊！！！还要上传身份证照片各种不情愿啊！！百度了一下更不放心了啊！！！！有没有取现成功的，来讲讲，顺不顺利，安不安全啊！': array([0.], dtype=float32),\n",
       " '我也关心这个，不知道是不是可靠的': array([1.], dtype=float32),\n",
       " '安全 ，已提现过好多次，是要扣一部分，不过之后会返回来': array([0.], dtype=float32),\n",
       " '速度好慢……一天半了已经~': array([0.], dtype=float32),\n",
       " '我是一楼！！！一品威客VIP和猪八戒VIP哪个好？这就是个引战话题，一品骂猪八戒黑，猪八戒骂一品黑，这两家是竞争对手，肯定掐的厉害啊。有些人在一品威客接到的单子多，自然觉得一品威客好一点，有些人在猪八戒接到的单子多，就会觉得猪八戒好一点。': array([0.], dtype=float32),\n",
       " '我说一品好，肯定有人要说我是猪黑，我说猪好，也会有人说我是一品黑，无论说什么，楼主你最终也不会信的。想做威客不是一个VIP就能解决的事情，楼主你说你专攻剪辑，那你就先试水一下，如果确实要买VIP的话，先试试小价格的，购买一下市场优先权。前提，你技术够硬。': array([1.], dtype=float32),\n",
       " '其它都差不多， 如果你有精力而且不太差钱的话两个一起维护。': array([0.], dtype=float32),\n",
       " '猪八戒是公认的骗人，还经常去黑别人。威客网站不存在真真假假，只要有实力，哪里都可以。': array([0.], dtype=float32),\n",
       " '这个东西得自己分析 你觉得哪个平台大 更有空间 就选哪个': array([0.], dtype=float32),\n",
       " '你要看清楚才行。如果光听是没用。哪个平台空间大，份额大你就选谁。做电商你会选淘宝天猫，肯定不会优先选拍拍': array([0.], dtype=float32),\n",
       " '建议不要选猪八戒。': array([0.], dtype=float32),\n",
       " '猪八戒不论是服务商，还是客户建议都不要选择': array([0.], dtype=float32),\n",
       " '感觉都差不多，搂起钱来，谁会比谁傻？猪头是明目张胆，一品是羞羞答答。目的都是一样的。': array([0.], dtype=float32),\n",
       " '在一品威客接过单子我来现身说法。我刚开始注册这个网站的时候没有成为他们的VIP会员。那个时候也是可以接到单子的。但是单子比较少，有时候两三天才能接到一单，不过那个时候我还在上学，对单子数量没有什么要求。 后面毕业工作后反而空闲时间比较多了，生活压力也比较大了。索性我咬咬呀就买了VIP。VIP所获得单子的确之前多了很多，基本上每天都有单子。而且他们的售后也算是尽职尽责。我有什么问题问售后基本上能够马上解决掉。所以个人是蛮推荐的。': array([1.], dtype=float32),\n",
       " '我看了大家的评论，我是在猪八戒上面做服务商的，几个月下来投入了近1万了，到目前为止，收入也才一千多，几个月下来，连成本都收不回来，有点心灰意冷，所以想看看一品威客如何？不知道有没有更多的朋友提提意见？参考一下。我们是广告公司http://www.chbhqd.com，实体公司已经开了十年了，生意不好做，所以希望在电商平台能够接单。': array([0.], dtype=float32),\n",
       " '免费的去威客，花钱的要去八戒': array([1.], dtype=float32),\n",
       " '我在猪八戒上发布需求，但是那边打电话过来的和我沟通，在这个过程中问了我很多，但我都感觉不专业啊，谁能说下那种打电话的是什么角色': array([0.], dtype=float32),\n",
       " '一品不知道。但是猪八戒很多年以前有个五毛钱的余额。近来想起来了又重新登陆余额变成0 了。': array([0.], dtype=float32),\n",
       " '无良商家，这就是他们的服务态度，网络客户都不搭理人的， 网站一直在用，现在出现问题，找他们反馈， 不解决问题， 都不告诉你问题点在哪？直接就要钱，这样的商家不要再合作了。': array([0.], dtype=float32),\n",
       " '这事楼主你不再理呀。举个例子，比如你买了一台电视机，保修一年，过了保修期坏了，你找厂家上门查故障也要给上门服务费啊': array([0.], dtype=float32),\n",
       " '如图，我们是猪八戒的钻石会员，当然签约的时候告诉你有各种派单了，这个是实际的情况，十天一个派单没有，反应了，也只回复一个正常，那些考虑签约会员指着派单赚钱的各位，劝你们慎重。': array([0.], dtype=float32),\n",
       " '派单，不是你赚钱的根本，靠派单赚钱的服务商是最低级的': array([0.], dtype=float32),\n",
       " '倒闭之前疯狂敛财，都没有几个雇主了，哪来的单可派': array([0.], dtype=float32),\n",
       " '不单单要开卡投标还要猪币，投一次四五十块，然后你联系客户只能用虚拟号码': array([0.], dtype=float32),\n",
       " '很坑人的 交了猪币还不一定中标  中标后完工 客户验收后要等三个月才能拿到钱 如果要马上拿到钱 必须交5000元保证金 随便找你点小错 就把你的5000元保证金给你扣光了 到处都是坑。': array([0.], dtype=float32),\n",
       " '现在的八戒不是以前的八戒了，资本进来之后现在要吸血回去了，麻烦，而且吸血多。': array([0.], dtype=float32),\n",
       " '无底洞，无尽，唔进，乌金，重要的话，说三遍': array([0.], dtype=float32),\n",
       " '至:   猪八戒雇主一份信,   雇主的各种抱怨和牢骚，作为服务商也无奈，为啥这么说呢，    1.雇主需求不明确，直接导致各服务商投标需要花更多猪币(估计有些雇主还没听过猪币)或者望而不投。    2.说服务商不专业，综合原因，报价低于市场，工期短，平台中间费贵，有心无力啊。    3.雇主发布需求没人接，作为服务商要过五关斩六将（会遇到机器人，假需求，假雇主，充会员），奈何服务商没有一双火眼金金。      个人总结，要想得一标，可所为要经历九九八十一难啊，果然很猪八戒呀。     雇主对不起，我先撤了，还想留条狗命研究那几行代码，不想被八戒完死。': array([0.], dtype=float32),\n",
       " '雇主一名，前天发到猪八戒的一个平面设计任务，等了两天，一个投标的都没有，这八戒众包比以前的更慢，这还众包屁啊，请问各位威客，还有那些靠谱的平台效率高的': array([0.], dtype=float32),\n",
       " '猪八戒现在不像刚开始那么多草根投稿了，都是工作室的，挺挑肥拣瘦的。': array([0.], dtype=float32),\n",
       " '相比其他平台成熟，规模大。': array([0.], dtype=float32),\n",
       " '老平台还是值得信赖': array([1.], dtype=float32),\n",
       " '八戒工场可以解决办公问题八戒企业管家可解决少养人的问题': array([1.], dtype=float32),\n",
       " '优质最关键': array([1.], dtype=float32),\n",
       " '做法简单，好上手点击展开，查看完整图片': array([1.], dtype=float32),\n",
       " '猪八戒牛皮啊': array([0.], dtype=float32),\n",
       " '八戒牛啊': array([0.], dtype=float32),\n",
       " '厉害': array([0.], dtype=float32),\n",
       " '不错': array([1.], dtype=float32),\n",
       " '这么厉害的消息，怎么没人顶帖？？？': array([0.], dtype=float32),\n",
       " '厉害了我的猪': array([1.], dtype=float32),\n",
       " '八戒上还有很多牛的': array([1.], dtype=float32),\n",
       " '这是真的厉害了。': array([1.], dtype=float32),\n",
       " '千万不要去，做了任务，还没任何结果，暗箱多，剽窃知识': array([0.], dtype=float32),\n",
       " '为什么我搜到的百度显示威客吧点进来确实猪八戒网吧？感觉到了深深地恶意。': array([0.], dtype=float32),\n",
       " '是大的平台大得不得了，最后小企业的发展最终成就都走向了被大平台兼并收购的归路。衣食住行依赖各大平台的便捷服务，但就实体经济而言，还是需要民营经济有好的发展，不然为啥经济学都说民营经济的好坏是一个国家的经济晴雨表。': array([1.], dtype=float32),\n",
       " '因为平台可以改变我们的生活、工作方式，更加有效率': array([0.], dtype=float32),\n",
       " '平台可以改变，为何不依赖？': array([0.], dtype=float32),\n",
       " '挺好的，只要平台促进自身发展，没有什么不可依赖的': array([0.], dtype=float32),\n",
       " '是啊，哪一样都离不开': array([1.], dtype=float32),\n",
       " '依赖得狠': array([0.], dtype=float32),\n",
       " '我觉得挺难的，不过我觉得ZBJ做得还不错': array([1.], dtype=float32),\n",
       " '相比做贸易的平台是要难得多吧，不然天猫、狗东、苏宁。。。全是卖东西的，服务平台确实难做。': array([1.], dtype=float32),\n",
       " '服务没有标准，事无巨细，挺难的。': array([1.], dtype=float32),\n",
       " '有可靠的平台做支撑很重要，就同站在巨人的肩膀上一个道理': array([0.], dtype=float32),\n",
       " '确实难，八戒还是很难': array([0.], dtype=float32),\n",
       " '平台哪有那么好做': array([1.], dtype=float32),\n",
       " '猪八戒网有很多视频需求，还认识专门拍婚纱摄影的服务商，你也可以试试': array([1.], dtype=float32),\n",
       " '都看过来，最火爆兼职在这里': array([0.], dtype=float32),\n",
       " '去猪八戒网这些网接单撒': array([0.], dtype=float32),\n",
       " '去八戒，很多': array([1.], dtype=float32),\n",
       " '管家式服务就是贴心': array([1.], dtype=float32),\n",
       " '有管理机制，有秩序规则，有公平正义，也有商业、社会价值': array([0.], dtype=float32),\n",
       " '服务态度好，售后有保障': array([1.], dtype=float32),\n",
       " '厉害了': array([0.], dtype=float32),\n",
       " '厉害啊': array([0.], dtype=float32),\n",
       " '未来的路更加坚定': array([1.], dtype=float32),\n",
       " '感觉营销手段很强势，突然好多都在关注': array([0.], dtype=float32),\n",
       " '以往成功案例重要，按规矩办事重要，急客户之所急重要，擦亮眼睛好好选择！': array([1.], dtype=float32),\n",
       " '业务线更广了': array([0.], dtype=float32),\n",
       " '“其实对于入驻猪八戒网，起初我们并没有报很大希望，但没想到‘共享人才’的效果太明显了，才三天我们就接到了单子。” 邓詹说到，“虽然单子小，但对我来说堪称莫大的鼓励！” 邓詹对这一单非常重视，加上客户也要得比较急，他带领公司上下熬了3个通宵才顺利完成客户的要求，客户也对他表示了高度认可。 “这一单对我的影响很大。虽然钱不多，只有几千块。但让我更坚定了把这条创业走下去的决心！” 本着“蚊子再小也是肉”的原则，在接下来的时间里，只要能赚钱的单邓詹都接。令他惊讶的是，短短一个月时间，居然接到了近20万的业务！仅一年的时间，就从一个无名小公司成长为猪八戒网成都地区APP开发第一名，年交易额达到750万。': array([1.], dtype=float32),\n",
       " '互联网公司都节奏快、压力大。得抗压、耐操的人才比较适合互联网公司，不过在重庆，猪八戒应该算是最不错的互联网公司了吧，还是可以去看看': array([1.], dtype=float32),\n",
       " '听说公司挺大的，其实都要去了解才知道': array([0.], dtype=float32),\n",
       " '曾经的公司 还不错': array([1.], dtype=float32),\n",
       " '创业痛点太多，想创业，可没有勇气': array([0.], dtype=float32),\n",
       " '在诸多行业中存在着为了经济利益而损害顾客的乱象，现在很多产品销售都是如此，虽然很多有情怀、有节操的商家奉行着职业操守，但现在这个时代，消费者宁愿相信这世上有鬼，也不愿相信商家的嘴。想把情怀说的让人相信，难度可想而知。消费者更多的是看重结果是否让自己满意，那如何保障双方的利益也是国家及相关机构的难题': array([1.], dtype=float32),\n",
       " '买卖双方利益的保障，一直都是个难题吧…消费者老觉得无商不奸，商家也确实有口难辩。所以才更加期待社会制度、相关机构的监督，包括每年的315，还有最近才出台的《电商法》，都是在一步步改变的路上。': array([1.], dtype=float32),\n",
       " '被长期拖欠款，这是最容易碰到的。记得去年友商跟我说：他们卖了600多万了；我问他：回款了么？他说：去年的都还没回，前年的回来了一部分我说：你真有钱！他说：我身上就剩200了，等回款我就有钱了！今天又碰见他，他说：今年卖了800多万了我又问他：款回来了么？他说：去年的回了一部分，今年的明年会回吧！我还是说：你真有钱……他说：身上就100块钱了……不回款的业务都是耍流氓……': array([1.], dtype=float32),\n",
       " '总的来说，网购更有保障了吧！尤其是对于购买非标服务来说，用户更有信心了点。': array([1.], dtype=float32),\n",
       " '平台背负的责任越来越大': array([1.], dtype=float32),\n",
       " '总体来说，电商法还是解决了不少问题，电商平台也会更注重用户的心声，对于平台发展还是很有利的促进作用，更大的获益者是用户，用户的合法利益得到了进一步的保障。': array([1.], dtype=float32),\n",
       " '期待不断健全': array([1.], dtype=float32),\n",
       " '还需不断健全吧，很多问题还是没有解决': array([0.], dtype=float32),\n",
       " '为啥猪八戒网的贴吧里全是其他平台的广告啊？？？': array([0.], dtype=float32),\n",
       " '单少 价低 人多 活贱': array([0.], dtype=float32),\n",
       " '辣鸡': array([1.], dtype=float32),\n",
       " '俺发垃圾帖子了吗？？昨天给禁言一天。还删帖！不过是截个猪八戒任务图。难道吧主是猪八戒的托？？？要跟猪八戒论坛一样，不能说猪不好？？？太过分了。': array([0.], dtype=float32),\n",
       " '还行吧': array([1.], dtype=float32),\n",
       " '今天我们猪八戒网的喜事超级多啊北有猪八戒网河南总部园区开园南有猪八戒网亮相乌镇世界互联网大会 作为中国领先的人才共享平台猪八戒网首次参加世界互联网大会究竟会带来哪些惊喜？展台有什么亮点呢？': array([1.], dtype=float32),\n",
       " '厉害了我的八戒': array([1.], dtype=float32),\n",
       " '名气更大吧，占有率要高一些，订单应该也多一点': array([0.], dtype=float32),\n",
       " '几年前接触猪八戒，那时觉得还好，现在的猪八戒网就是一个坑。为了圈钱什么都做的出，越来越烂，傻的客户才去那里。': array([0.], dtype=float32),\n",
       " '相对另外几个威客网来说，猪八戒的名气是相对大些': array([1.], dtype=float32),\n",
       " '优势？？单子多机会多': array([1.], dtype=float32),\n",
       " '模式上，客源质量和数量上，但是劣势也很明显': array([1.], dtype=float32),\n",
       " '+1，流量流量流量....流量第一！': array([0.], dtype=float32),\n",
       " '线上+线下吧，线下布局了那么多城市': array([1.], dtype=float32),\n",
       " '优质服务商更多': array([0.], dtype=float32),\n",
       " '今年6月，猪八戒网成为山东省企业上云指定云服务平台及战略合作伙伴。在八戒上云管家的帮助下，山东30多家企业已实现上云，八戒企业管家帮助企业申领补贴近60万元。如今，猪八戒网又成为河北省、重庆市、株洲市指定云服务平台，三地企业将享受八戒上云管家所提供的便捷、高效的上云服务。': array([0.], dtype=float32),\n",
       " '蛮厉害的': array([0.], dtype=float32),\n",
       " '猪八戒现在想钱想疯了··': array([0.], dtype=float32),\n",
       " '这么牛': array([0.], dtype=float32),\n",
       " '确实牛': array([1.], dtype=float32),\n",
       " '到今天，你会发现，吃穿住行都离不开这个平台的时代，购物有了淘宝、买服务有了猪八戒、打车有了滴滴，这是共享经济的时代，也是平台的时代，平台的发展与用户的体验息息相关。平台的热门度，取决于用户的满意度，我们更加期待各平台带来越来越多的惊喜。': array([1.], dtype=float32),\n",
       " '大家不要找这家公司  本人老公去年在这家公司做软件没出来，一直不退款，后来发了贴吧来自：tieba.baidu.com/p/5908297966': array([0.], dtype=float32),\n",
       " '不要脸': array([0.], dtype=float32),\n",
       " '以后做软件尽量去他们公司看一下，了解一下公司的实力。': array([0.], dtype=float32),\n",
       " '近期猪八戒针对服务商的一系列苛刻行为， 只是尽可能套现，能套多少是多少，总有新手会加入，总有看不明白的会交钱，总有贪心的会等待猪八戒改革这些苛刻的制度，总有`~~~~反正猪八戒不会在乎服务商的反对，也不会在乎客户的不满，他只要保证平台能进钱就好，只要事情不闹大。想想一年只要有1万个新手入驻猪八戒光叫保证金5000加上 银卡6000元  总共就是11000千元    那么保守估计就这一块至少能白白直接轻松容纳资金1亿多。这个钱完全是网络平台就能吸取的资金，不关其他分公司的事。 大家想想为什么他们明知道后面的制度会遭到众多服务商的不满， 还是要制订出一系列苛刻的制度。就是因为光靠拿服务商与商家的交易服务费远不及交保证金跟办理银卡、金卡、砖石卡钱来的那么容易。为什么猪八戒要这么做，原因很简单，因为他有流量，流量为王，正是因为他积累了大量的流量，以及知名度所以他敢这么做。  即使名声下滑他依然要这么做，  仔细想想如果两年内有忽悠10万人    加入猪八戒，（）以猪八戒现在的流量10万真的不算多。）。然后交保证金跟办理会员卡 ，那算下来是多少   ：光这块那就是10几亿。     反正我是对猪八戒失望  希望他以后能走好': array([0.], dtype=float32),\n",
       " '为了圈钱不择手段。': array([0.], dtype=float32),\n",
       " '为了圈钱没办法': array([1.], dtype=float32),\n",
       " '上个月工资到手1万，可是5号发的，今天自己卡里就剩下2千多点！！唉，还是乖乖的约束自己吧！自己出来是赚钱的！不是来潇洒的！': array([0.], dtype=float32),\n",
       " '他现在要上市，想钱想疯了': array([0.], dtype=float32),\n",
       " '手里有钱的傻子多了，只要不违反法律，不坑白不坑！': array([1.], dtype=float32),\n",
       " '网络上当键盘侠就可以随意口嗨吗？不负责任的诽谤污蔑。猪八戒网紧跟国家政策，大力支持大众创业万众创新，鼓励大学生创业，提供大学生创业平台，这怎么就变成你口中的“忽悠大学生创业+变相校园贷”的套路敛大学生父母的血汗钱？猪八戒网兼顾社会价值和经济价值，为社会发展献力献策。': array([0.], dtype=float32),\n",
       " '猪八戒霸王条款防不胜防，且一改再改，你都不知道怎么就违规被扣保证金。服务商没这么大的时间和精力去跟他们一个专业的团队去耗，何况这群初出茅庐的学生，还不是任人宰割？！': array([0.], dtype=float32),\n",
       " '八戒你设置的最低门槛，银卡6000一年，保证金10000，已经完全限制了小服务商的活力。再说了，我们擅长的类目交易中心的单寥寥无几。就算交了钱，交了保证金，这些都能回本吗？？周围同级别的服务商都退了。。跟你说声古德拜，你们可以自己玩。。': array([0.], dtype=float32),\n",
       " '调研了一圈，觉得还是不要买了。真心不靠谱，强迫式消费。': array([0.], dtype=float32),\n",
       " '这几天草草的浏览了吧里的帖子，确实发现了很多阴暗面，想来想去，还是打算把一些事情都披露出来，让更多的人能够知道，这平台到底是怎么回事。': array([0.], dtype=float32),\n",
       " '我是猪网的服务商，这点不怕你们知道。在猪八戒网做了6年了，眼睁睁看着平台一点一点被某些“大服务商”搅得乱七八糟，心里也是说不出的难受。以前我们接触客户，客户第一反应向来都是：这平台还不错，服务商差不了，好好谈谈。现在接触客户基本上只剩下一种：先试稿，满意再说。明显已经失去了对平台的信任。相信很多服务商也经历过：投标莫名被淘汰、派单莫名被关闭、派单客户永远联系不上等等问题我就不一一例举了，而最近平台的质量水准又下降了一大截：订单不外放、客服没人理、仅有的几个订单客户基本联系不上，比稿的大部分都是骗稿。都不需要我们来猜测什么，大家心中明镜一样：平台吸着我们的血来供养“大服务商”。': array([0.], dtype=float32),\n",
       " '每一次和客户沟通，听客户谈到他们”大服务商“还怎么怎么滴的时候，心中除了苦笑，就是戏谑了，一般我都会直接告诉客户：那您去联系他们把，祝您能得到理想的设计。以下内容均为转述，本人不承担任何责任：（去北京旅游碰到的一位平台前辈，了解的内幕特别多）”他们都是这样子嘛“”你平台流量养我，我给你造势宣传，让你吸引用户“”什么高大上的设计？都是扯淡，最新的模板库一套，多简单。“”还XX大奖得主？真有这本事会在这平台吗？代言费而已“”就你抱怨单子少？你不给它钱，谁给你单子？”': array([1.], dtype=float32),\n",
       " '上述这是对服务商的不公平待遇，与所谓上层的权钱交易。': array([0.], dtype=float32),\n",
       " '对于雇主来说，平台这种运作方式导致绝大部分服务商均处于负盈利的状态，因此你们所受的欺骗就解释通了：我们还亏本呢，先拿钱再说，管你设计不设计的。': array([0.], dtype=float32),\n",
       " '正是因为平台的造星计划，让大多数雇主盲目的去追寻所谓的大服务商，结果导致各种问题。大众点评网上，投诉这些大服务商的数量我初期统计了一下，总共约有1000左右，全是差评。但是平台上你可以看到，这几家服务商的档案中，加起来的投诉不超过100，十倍的差距，相信你们都能明白到底是什么猫腻。作为服务商的我也不想去评论这些大服务商，毕竟能撑起来实力还是有那么一点的，但是态度实在恶劣至极，完全就是：做不做？不做拉倒，我们给你做那是你的荣幸。': array([0.], dtype=float32),\n",
       " '我先拿品牌设计这个最火，客户最多的类别来举例：私下里我都和类目排名前100的服务商网上沟通过，也可耻的套过他们的案例，对比来对比去真是发现了很多差别。我简单的例举如下：（个人感觉，非正式评论，不具有任何法律及商业效益）服务态度最好的：琨睿、企艺、甲骨、兰灵、黑丑就案例来看，设计水平最好的：空蝉、甲骨、兰灵、琨睿、千树真实有效的评论最好的：甲骨、黑丑、万城、琳琅、企艺、弓与笔价格与服务水平更相符的：黑丑、琨睿、琳琅、兰灵、黑腰蚂蚁整理了一下，我也是发现真正水平好，服务好的服务商并不全是所谓的大服务商，很多营业额百十万的，十几万的都不差，显而易见这些真正服务客户的服务商全都被黑幕坑了。': array([1.], dtype=float32),\n",
       " '我想说现在猪八戒的价格可真搞笑，看看价格后已经不像去认证为服务商了，比现实里接单收费还便宜，便宜的太多了，便宜的只能赚个辛苦钱而已了，不接猪八戒的单也觉得没什么可惜的': array([0.], dtype=float32),\n",
       " '猪八戒的“心悦会员”嘛，你充钱你就NB啊 ， 真是像玩网游一样，真是搞笑，': array([0.], dtype=float32),\n",
       " '真的很坑爹，我是八戒通会员，现在悔青肠子了...........': array([0.], dtype=float32),\n",
       " '就是垃圾': array([0.], dtype=float32),\n",
       " '我的天，太可怕了，我现在在小鱼儿上面找的，要不楼主你试试。': array([0.], dtype=float32),\n",
       " '各种花样坑钱，花样剥削，真心觉得这个网站离倒闭不远了，服务商和雇主都慢慢看出它的真面目了。': array([1.], dtype=float32),\n",
       " '自从众包出现后就没怎么投稿了，没给八戒交会员费，稿件基本就是白忙活，雇主看不到，现在不打算做了': array([0.], dtype=float32),\n",
       " '再也不见，腊鸡公司也能上市，我吃一万坨屎': array([0.], dtype=float32),\n",
       " '提现，说好的提现呢都一个星期了！！！！我都怀疑有没有人成功提现过了，支付宝这么多人用是因为方便快捷，易极付用过一次就不想再用！！！！': array([0.], dtype=float32),\n",
       " '就是骗子，那大家怎么在猪八戒玩的额': array([0.], dtype=float32),\n",
       " '我有一群朋友在猪网做兼职啊，挺好的': array([1.], dtype=float32),\n",
       " '我之前提现了5次都没有成功。 后来换个银行卡就成功了。 总规来说，使用起来不是太方便的。': array([0.], dtype=float32),\n",
       " '现在猪八戒投标居然要什么机会豆，太恶心了，有没有人或团队 要我这种人才的 做的h5 炫的飞起542006055 可以看案例 经验丰富，做过上百个项目': array([0.], dtype=float32),\n",
       " '做人事一个多月了，碰到很多很多奇葩，也和很多很多所谓的见多识广的人去争辩过。最后才发现自己很有意思，跟一群没有拼搏的心，没有冒险的精神，天天却喊着上天不公平的人，去讨论着怎么去赚钱，怎么明白自己身上的责任是多么的可笑。为了隐藏自己可悲的懦弱，天天去宣传着，来的人最后怎么怎么样。是的！是有很多掉入坑里，他们的遭遇的确是这个行业的错，但是，这个世界有哪一个赚钱的机会是不与风险共存的？强者都会陌陌的把时间花在积累自己的财富上，只有弱者才会把时间花在抱怨上。': array([1.], dtype=float32),\n",
       " '一个月一万多，根本不够花好不好': array([0.], dtype=float32),\n",
       " '现在的社会！钱是人的力量，是血液！！只有不断的增加自己的力量，你才可以更好的生存！如果你天天去献血，我觉得你也活不了多久了。想要一份，好的工作！就赶紧去找吧': array([1.], dtype=float32),\n",
       " '看起来有点高大上呢': array([0.], dtype=float32),\n",
       " '这样不就可以不用猪八戒了': array([0.], dtype=float32),\n",
       " '之前在猪八戒平台上找服务商做公众号，问了客服是各种担保各种保护消费者，签了合同2个月做完的事，拖拖拉拉做了1年多还没做完，现在爱理不理基本上就是晾在那里了，期间也找个猪八戒平台咨询过，要我们找服务商商议解决，解决不了他们再出面，现在说超过1年不管了，没有诚信的平台造就没有诚信的服务商。': array([0.], dtype=float32),\n",
       " '不简单': array([1.], dtype=float32),\n",
       " '不用加入了，猪八戒快凉了~~': array([1.], dtype=float32),\n",
       " '以前算是个中介，现在自己可能也经手服务运营，好单它自己先接了，或者拆分功能低价转包给普通服务商去做，还能收百分之二十手续费，呵呵哒自从投标收费以后，开始还能打通客户电话，后来百来块钱投标出去，就没一个接电话的，打十次九次长声无人接听，偶尔一次提前挂断': array([0.], dtype=float32),\n",
       " '感觉好象是太贪了，然后效益不好了，裁人，然后好多应该有的服务没有了，应该及时做的事拖拉了。话说猪八戒的改版总是越改越差，人越改越少，于是到了现在，感觉有点凉凉了。': array([0.], dtype=float32),\n",
       " '赶快看看最新改版的。让你惊喜让你意外！': array([1.], dtype=float32),\n",
       " '典型的哪个啥……就不明说了': array([0.], dtype=float32),\n",
       " '看了大家的评论，觉得好可怕，为什么都没有有关部门去整治一下呢？前段时间某段子和某音那些平台都只是因为传播不好的东西的原因被整改了，那么这种真切地伤害到大家利益的网站为什么还继续存在着？后台这么硬吗？': array([0.], dtype=float32),\n",
       " '都去管平台了，当然没法管贴吧啦。猪八戒做了10多年了，它能存活下来自然有存活下来的道理，如果真的是伤害到大部分人的利益，按照市场规律是一定会让它死翘翘的，又不是“国字号”“央字号”“地字号”的企业，还没那么硬的后台。至于为什么争议那么多，那要回归到服务本身，服务交易不同于商品交易，商品是好是坏，是不是缺斤少两，有质量问题，是有明确的规范的和客观依据的，而服务没有，一个图片，你说好看，我说不好看，那是主观判断，没有客观依据，也就会有很多的纠纷，就会有很多的不满意和负面舆论。然后再说商家为什么那么大抱怨，我觉得可以分成两部分来看，一部分赚了钱的商家希望继续享受免费或者低成本的平台红利，另一部分觉得交钱=订单，相当于买了猪八戒网这个大销售，而不是买的平台的使用权等互联网产品，在认知上有些偏差（当然跟猪八戒网没有有效销售管理有很大关系，存在一些销售乱承诺的现象），总体来说，整个平台还是在一个相对好的方向发展，但在内部管理以及平台、雇主、商家三方利益分配上还要再做优化。': array([1.], dtype=float32),\n",
       " '首先先给单独工作的朋友一个告诫：最好不要去接单平台上私自“开店”接单。除非你具备以下几点要求：   1：有足够好的专业能力（接到任务后能在规定工期内完成，并且是高质量的完成哦）。   2：很多发单房有较为严格的要求，如：需要接单方有很多案例提供选择 / 店铺信誉要足够好 / 有的甚至需要当面谈 等等等等各种严格的要求。   3：个人有足够的流动资金去维持店铺的正常运转（其中含了各种说不上来的费用）。   4：有足够的耐心自己去联系下单方，谈单 / 交易 / 开发 / 交付 / 后期等等的问题。   5：保证自己的接单频率在一周2单以上（每单的成交价格在1-3万左右哦）。   6：一定要有钱。   7：一定要有钱。   8：一定要有钱。   9：重要的事情说三遍': array([0.], dtype=float32),\n",
       " '以为做个软件很简单，所以描述需求的时候及其模糊。': array([0.], dtype=float32),\n",
       " '急着想要报价，在自己对需求不确定的时候就要报价。然后就按这个报价开始做。': array([1.], dtype=float32),\n",
       " '以为所有软件都有模板，而且模板都很便宜。': array([0.], dtype=float32),\n",
       " '自己不知道要做的东西的具体功能，要靠开发商来猜。而且还这时候就要报价。': array([0.], dtype=float32),\n",
       " '1：因为项目失控/失败而被迫离职/降职/开除。2：项目上线的时候漏洞百出，反复修修补补解决不了问题。后面必须重做。3：误把自己都不确定需求时得到的不靠谱报价当做真实报价去开始做预算，导致后期资金预算跟不上继而导致项目失控/破产。': array([1.], dtype=float32),\n",
       " '我见过最常见的例子。很多人上来就问开发app多少钱？或者问做一个简单的app多少钱？或者.........跟她一样多少钱？？？': array([0.], dtype=float32),\n",
       " '第一种：问做一个APP多少钱？其实你问这个问题就好像你到4S店问，一辆车要多少钱？车有10万的家用轿车也有1000万的超跑。车根据用途（轿车，越野，跑车，赛车，公交也是车），配置，引擎，装置不一样，价格和成本是天差地别。同理，你来问APP也是一样的。必须表达清楚自己要的是什么样的APP，用于什么场景，APP解决什么问题，怎么解决（具体需要哪些功能）。就来问价格，不亚于你去问汽车4S店，我就是要一辆车，你告诉我价格就行了。别人肯定会拿你当傻子。因为***没告诉人家你到底要什么车啊！！！所以不能抱着这种态度！': array([0.], dtype=float32),\n",
       " '如果你只问我做一个APP多少钱？ 我只能告诉你，几百块到几个亿，都有可能。': array([0.], dtype=float32),\n",
       " '第二种：我要做一个简单的APP，多少钱？每个人对简单的定义是不一样的。你说的简单具体是简单到什么程度，你又具体是要做什么东西的，很多人觉得微信也挺简单的。。。建议你每次问的时候都说清楚具体功能。': array([1.], dtype=float32),\n",
       " '第三种：我要做个类似美团/淘宝/京东/滴滴打车。。。一样的APP多少钱？一般这么问的创业者都有个这样的共同点，很多说不清楚自己要的是什么。可能只是看中了比如滴滴打车的地图功能，但是描述的时候说的是跟滴滴打车类似。而滴滴打车的地图功能本身实际只占了滴滴整个软件系统功能的百分之一都不到。同理，有的是看中了美团的团购部分，说自己要做的是美团。有的看到京东有在线支付，就说自己要的是京东。如果你直接这么问，我其实完全不明白你想要的是你举得例子里面的具体什么功能。因为不可能完全仿一个美团/淘宝/京东/滴滴打车。。。需要双方有共同的耐心去整理开发需求。': array([1.], dtype=float32),\n",
       " '大公司不仅仅是因为他是大公司才做得细，是因为他做得细才能成为大公司。所以人家有钱。同样的这也是大部分人赚不到钱的根本原因。': array([0.], dtype=float32),\n",
       " '找个人，团队还是公司来开发？': array([0.], dtype=float32),\n",
       " '个人开发者：优点是开发成本最低，一般一天的开发薪酬为300-700不等（由于项目的大部分的工作量在开发上面，所以通常是找开发人员接手）。缺点是项目质量差，开发周期长，沟通和后期维护都比较麻烦。由于找个人开发大都是兼职，所以开发周期通常会比较长，进度上相对难掌握。另外还有就是除了开发外，项目设计，UI设计，测试，沟通，服务器部署，上线，后期维护等方面缺乏相应的经验，毕竟个人的能力一般都比较局限，只能擅长其中的一两方面，所以很难在项目各个方面都做好。': array([1.], dtype=float32),\n",
       " '每个阶段都有相应的质量控制任务，特别是安全任务。': array([1.], dtype=float32),\n",
       " '留一手。很多情况下你根本拿不到尾款，留点自己知道的漏洞和接口说话至少有点底气，实在谈崩了也不亏嘛。': array([0.], dtype=float32),\n",
       " '先收定金。毕竟开发是需要时间和精力的，别人一句话就开干很多时候会让自己处于被动的状态。': array([0.], dtype=float32),\n",
       " '少接政府项目。做过一次你就懂。': array([0.], dtype=float32),\n",
       " '要是你能全做，那在下就佩服了，不是佩服你的能力和技术，而且佩服你小子活的够累的啊': array([1.], dtype=float32),\n",
       " '报价真是一门坑爹的艺术，报多了，稍不留神就溜走了，报少了，累的苦的是自己。': array([0.], dtype=float32),\n",
       " '.必须文本化，对方不愿意出文本，你也自己做一份给对方，必须文字上的同意。': array([0.], dtype=float32),\n",
       " '改动要谈好，对方提出的小改动都有可能让你增加成倍增加工作量': array([0.], dtype=float32),\n",
       " '外观或者后台。一般是改动就加钱或者只允许改动几次。': array([0.], dtype=float32),\n",
       " '那种不付定金只会说各种好话的就拉黑吧，诚意不是体现在嘴上的。': array([0.], dtype=float32),\n",
       " '签合同的时候一定要明确需求，搞不清楚自己想要什么的客户真不是一个两个，合同里没写清楚就意味着被免费加班。': array([0.], dtype=float32),\n",
       " '尽量以本地为先，以有产品经理的项目为先。': array([0.], dtype=float32),\n",
       " '期要预留一些空余，承担项目是由风险的，过程也难以预测，留一些空余工期应对意外。': array([0.], dtype=float32),\n",
       " '钱是赚不完的，别光顾着消耗自己，也要持续充电学习，才能成为更有价值的程序员。': array([0.], dtype=float32),\n",
       " '我们要判断项目真实性': array([0.], dtype=float32),\n",
       " '在我们找到一个或者客户找到你的时候，就要判定这个客户是否真的有设计需求；而不是一些个人或者公司自己想不出创意，或者不愿意出钱，所以想骗取一些设计的，所以我们需要一定的技巧来判定这些项目,通过电话沟通，QQ沟通，需求判定，单位名称等来进行判断一下（当然你觉得没必要，可有略过）。': array([1.], dtype=float32),\n",
       " '猪八戒网不错哦，新手可以考虑在上面做任务': array([1.], dtype=float32),\n",
       " '火钻越多每天分红越多，和宝石星球一样。获取火钻邀请人或是发布视频别人点赞你可以获得。加入我们一起互相给对方点赞获取火钻。一起发财！': array([1.], dtype=float32),\n",
       " '做了悬赏半年，后来加了众包，众包火的那几个月，还是有钱赚的，就是没有开会员一天挣个三四十也不成问题，现在众包基本没有什么任务了，按理说众包这块不出任务招标这块任务会变多，然鹅招标这块也还是半死不活，订单都被猪家自己吃下去了么！！！至于大家说的保证金，开了众包会员就不用交了，虽然说平台缴纳保证金也有道理，不过好几千块呢，我也是不会交的，最近想去一品威客看看': array([0.], dtype=float32),\n",
       " '然后就是大家纠结的一品威客和猪八戒哪个好，一品威客不重视悬赏这块，开会员也都是招标发需求给你，猪八戒由于项目划分的比较清楚，平台流量确实是比一品威客多，而且一开始猪八戒不需要任何成本就可以在平台做，只要每单收2成，这对新人来说非常非常好，毕竟谁也不想一来就开个几千块的会员，现在猪八戒弄的也非常尴尬，不知道接下来要出什么新的产品了': array([0.], dtype=float32),\n",
       " '非常明显、太明显不过猪网是缺钱了！不然不会一时间出这么多么蛾子。这平台除了流量，其他作用基本上就叫无，尤其是对小服务商来说。以前是有用的，对小服务商，现在越来越没用了，万事靠自己吧亲': array([0.], dtype=float32),\n",
       " '这个平台已经不适合小老百姓创业了，不像淘宝网，大爷大妈们都能在上面开店赚个零钱花花！': array([0.], dtype=float32),\n",
       " '在猪八戒发布众包任务感觉效率很差，楼主有没有好的LOGO网站推介': array([0.], dtype=float32),\n",
       " '总体来说，没以前好了。以前做仿站还能赚点零花钱。现在不行了哦。': array([1.], dtype=float32),\n",
       " '只是变化有点快，也是为了适应发展': array([0.], dtype=float32),\n",
       " '很明显，改版后，各种缴纳费用，小服务商已经躺了一片。感觉平台难长久': array([0.], dtype=float32),\n",
       " '什么人定什么政策，这保证金制度除了猪脑子，任何人都不会想出这种办法来。猪一戒和猪八戒交一样的保证金，猪一戒的新手能赚多少钱？猪八戒的老手能赚多少钱？猪九戒和猪二十七戒交一样的保证金，收入上差几百倍、几千倍甚至几百万倍，保证金却交的一样多？！这是多么奇葩的思维模式？圈钱也不这么个圈法啊？大服务赚得多不能多交、更不肯多交，小服务商想赚点钱交上，一大堆烂政策又不允许小服务商赚钱甚至生存！': array([1.], dtype=float32),\n",
       " '人一旦成功了就会变得异常自信，觉得自己无所不能、不管说什么、做什么都是对的，甚至连个意见都不让提，如果死不了的话，最好马上、飞速上市，一旦上市，就再也不是你一个人说了算了的，千千万万的人都在等待着，用脚给你们投票！': array([1.], dtype=float32),\n",
       " '我打个比喻，如果把猪八戒网比喻成一个饭店，正常的生意都是如何费劲心思提高服务，提升菜品，赚客户的钱，而猪八戒赚钱的路数比较诡异，成天打厨师的主意，老想赚厨师的钱，猪八戒倒闭是早晚的事': array([0.], dtype=float32),\n",
       " '情况就是头疼': array([0.], dtype=float32),\n",
       " '天上不会掉馅饼，保持清醒不上当！！！': array([0.], dtype=float32),\n",
       " '依照目前的情况来看，你说的还是有道理的': array([1.], dtype=float32),\n",
       " '雇主保障！怎么感觉是幌子！说收取别人的20%的服务费！拿出10%做赔付，要想得到保障！还得叫钱！每个月10元！这不是逗逼吗！': array([0.], dtype=float32),\n",
       " '一点都不照顾新人啊！好坑！': array([0.], dtype=float32),\n",
       " '想问下在猪八戒网，对于一个新手怎么挣钱': array([0.], dtype=float32),\n",
       " '确实太坑，佣金应该有上限。': array([1.], dtype=float32),\n",
       " '猪八戒网给我的感觉就是贪，跟猪八戒一样。不管在服务商排位、作品显示管理上，都是能坑就坑，隐藏作品需要交钱，完全不把知识产权放在眼里，位置要交钱，等级又摆在那里。真差劲。': array([0.], dtype=float32),\n",
       " '猪八戒  参与数  虚标  中标虚标  这个怎么解释！': array([0.], dtype=float32),\n",
       " '去其他项目交易网都有保障，且便宜': array([1.], dtype=float32),\n",
       " '我只想说我花了好几百买了任务置顶，也不见得有很大效果，有些人都是自己刷的任务数量，照样很火，所以置顶是个坑，而且收雇佣者20%，加大雇主和雇佣方的成本，太不要脸了！': array([0.], dtype=float32),\n",
       " '这个垃圾网站应该早点倒闭，到处贪钱': array([0.], dtype=float32),\n",
       " '你们猪八戒最近在抢钱吗我的服务费从2% 涨到10%了不是在抢钱吗 还交了11000元保证金 6000/年的年卡会员 多项收费 还扣这么多技术费 一个人一个月的工资才多少呀 凭良心做事 这样早晚会垮掉 大家一起抵制这种乱象收费行为': array([0.], dtype=float32),\n",
       " '楼主醒醒吧，八戒早就不满足百分之二十的佣金了。': array([1.], dtype=float32),\n",
       " '想创业的看过来，我等你': array([0.], dtype=float32),\n",
       " '像我这样的是不是不要去猪八戒做任务了，做了也不给结案是吗？': array([0.], dtype=float32),\n",
       " '我只是做网络推广类---就是那些很低单价的单，我没有交会员费，但是考试有通过，最近几天做的单没有一个有回应的，特来请各位大神指点': array([0.], dtype=float32),\n",
       " '现在一品挺好的啊，猪八戒已经日薄西山了': array([1.], dtype=float32),\n",
       " '我永远都忘不了你没有钱没有本事连你最亲的人都瞧不起你。当你急着用钱，又找不到有人愿意借给你。': array([0.], dtype=float32),\n",
       " '很多威客网发展的最终方向 卸磨杀驴：用入驻商的钱把网站搞起来，发现那个项目赚钱就搞自营挤死入驻商，或者榨干入驻商，': array([1.], dtype=float32),\n",
       " '你用别人交的钱扣掉一部分，再拿去给你网站做推广，入驻的人接单靠运气，中国也没有多少这样的傻子 网站大部分任务自己编，大部分店铺自己造由于不是众包，自己的产品出现问题，雇主不满意，就来个客服介入，其实就是自己又是被告，又是庭长，这个情况谁输谁赢你知道的，盲目扩张，把收取入驻商做为赢利的根本，单子跟不上，用节操换利益，入驻商多了，锅里的稀饭不够分，想办法清除一些入驻商，最简单有效的方法就是扮演雇主，诱导入驻上去线下交易网站那个项目赚钱，你就搞自营，养个亲儿子，各种扶持自己亲儿子去和你网站同类型店铺竞争，': array([0.], dtype=float32),\n",
       " '源码交易都上传到他服务器了，也是招好棋。目前投标已经遇到许多疑似假单。': array([0.], dtype=float32),\n",
       " '首先，该平台肯定是个靠谱的平台，但是也要懂得如何避免上当，比如拒绝线下，否则无保障。如果遇到雇主不诚信的行为，可以通过平台进行举报。': array([0.], dtype=float32),\n",
       " '有好多人说自己在哪个平台上被坑了多少多少钱，其实话说回来，真正意义上的那不叫坑。而是自己的“试错成本”中的一部分哦！': array([0.], dtype=float32),\n",
       " '刚进这个吧是想了解猪八戒怎么样的，结果前几篇都是什么点一下就过了什么的 ，好奇进去看了一下。  结果是什么华信宝，原来是一个借钱网站，然后跟帖的都是什么楼主厉害，我下款了，什么新口子不多了，然后本着好奇心我去百度了一下，结果TM全是投诉和辱骂。   在此发帖，此贴吧的借款帖子都是骗人的，不要上当受骗， 还好我机智...': array([0.], dtype=float32),\n",
       " '其实不止可以去猪八戒网啊，八戒网适合做创意类型的任务，比如说，设计一个LOGO,起个产品名等，而且基本上只是个任务发布平台，平台没有任务的完成过程的环节，也不专注，五花八门的，什么任务都有，别人推荐我去YesPMM接项目，在线签署合同，投标比较有保障，再者钱是托管的，分阶段给付，比较看好这种方式': array([1.], dtype=float32),\n",
       " '看不懂': array([0.], dtype=float32),\n",
       " '虽然也断断续续做了几年任务，头一次遇到啊，规则不熟悉，请问是允许这样的吗？先是被选中备选，还按照要求进行了修改，突然任务没有了，简直像骗稿。': array([0.], dtype=float32),\n",
       " '敢于向黑暗宣战的人，心里必须充满光明。': array([1.], dtype=float32),\n",
       " '成功的秘诀：珍惜 在乎 感恩。': array([0.], dtype=float32),\n",
       " '甚至有的人不信任第三方，为什么呢？黑中介，高抽成，赚差价......因为这些中间人没有保障双方权益不说，甚至损害了双方的权益。那么对于第三方担保自然缺乏信任。': array([1.], dtype=float32),\n",
       " '反正先从最简单的会员做起，说句不好听的，就算被骗了也不过28，假如你成功了的话随随便便就一天赚回来了😁': array([0.], dtype=float32),\n",
       " '猪八戒网怎么接单呢  一直没找到': array([0.], dtype=float32),\n",
       " '直接问官方首页右边的客服问，简单又直接': array([0.], dtype=float32),\n",
       " '直接上猪八戒网找翻译服务商吧，准确率高很多，而且价格不贵的': array([0.], dtype=float32),\n",
       " '因为我受益，所以我推荐，因为我认同，所以我分享六个努力了三个多月还是慢慢的上来了 希望自己的经历的那么多以来 能帮到需要帮助的人 让跟多的人和我一样慢慢的起来不要继续这里撸那里撸的维持生活 到头来还是一样头疼': array([0.], dtype=float32),\n",
       " '我从去年开始接触到网带 家里条件不是那么好 自己大大小小外面搞了一大堆狗屎事 后来自己真的没办法 以带养带的方式 欠了六个多 也是因为网带让我一个月稳定收入..丢了的工作.当初真的是很后悔的 但是后悔没用': array([0.], dtype=float32),\n",
       " '后来我也是在网上跟人家学习软件开发类的工作 因为自己也是读过书的人 所以接触这些还是比较容易上手 毕竟自己拿手的东西 然后我也是通过这些软件 才慢慢起以回想起来年轻人的路就是那么多的坎坷 就看自己 能不能熬过去了好不容易找到法子把这六个多清了 终于可以过上正常人的生活了 不用每天到早晨才能睡着 晚上疯狂抽烟 再也不怕被爆通讯录了 再也不用担心 催收来家了 每个月还能给家里一点小补贴 所以说自己赚到钱了 就是人 赚不到钱也没有多少人去可怜': array([0.], dtype=float32),\n",
       " '其实做起来并不难，难的是自己没有下决定的心，没有勇气，只会空谈。俗话说的好，世上无难事只怕有心人，所以，天无绝人之路，只要想去做。': array([1.], dtype=float32),\n",
       " '猪八戒网注册类任务发布不了了，让雇主和发布者情何以堪': array([0.], dtype=float32),\n",
       " '在此贴吧 被爆过的 就绕道吧': array([0.], dtype=float32),\n",
       " '没有一家正规公司 敢接招啊~ 这太...了': array([0.], dtype=float32),\n",
       " '一直好奇猪八戒网是怎么赚钱的，我们在猪八戒网上又如何能高效地获取利益，达到双方共赢。这是一个研究猪八戒上网民如何才能更好获利的基金项目，你的出力将会对电子商务的发展提供宝贵的经验，请将你的意见填写于问卷星上的问卷。链接https://www.wjx.cn/jq/21288670.aspx  你的一念之间，就是一个勤奋学习的大学生的生死存亡。一分钟而已，求发发善心，好人终有好报。': array([1.], dtype=float32),\n",
       " '真个威客的模式需要创新重构，照抄国外模式不做变通，在国内最后死路一条，如淘宝架构COPY国外电商，但马云聪明在学而后变了解本土根据本土情况作了很多变通采取得成功': array([1.], dtype=float32),\n",
       " '很多人来里面的目的就是为了打广告吗': array([0.], dtype=float32),\n",
       " '怎么发布计件任务，找了好久都找不到？': array([0.], dtype=float32),\n",
       " '某网的模式有问题。它把服务产品按淘宝的实物产品的方式进行销售了。服务产品和实物产品的定价模式有根本区别。实物产品是已经制造出来了，或者说成本是基本确定的。但服务产品不一样，销售前定价只是一个参考价，不是确定的。所以如果你把不能完全确定价格的产品去进行竞标销售，那就没法保证质量。没法保证质量那也没办法保证消费者的满意度。导致两头失望': array([0.], dtype=float32),\n",
       " '起早摸黑，忙忙碌碌就这样一天一天地过着重复的生活你会发现，只会有人问你挣多少钱却很少有人问你累不累？开不开心生活就是这样别人只看结果，自己独撑过程有时你会觉得莫名的累身累？心累？所有的累只能一笑而过': array([0.], dtype=float32),\n",
       " '这一路走来，最不容易是自己病了得撑着，累了得扛着难了得顶着，苦了得藏着烦了得憋着，痛了得忍着哭了得躲着，输了得挺着生容易，活容易，生活真的不容易你不易，我不易，其实谁都不容易': array([0.], dtype=float32),\n",
       " '这客服打从我注册号起就天天打电话让我买旺铺，跟我说现在不买就以后上市就贵了，然后帮助我扶持什么的，我说暂时先不用了！然后说大哥现在是赚钱的好时候，我说我忙不过来！好像我就要给他送钱什么的！我就算在电商平台买东西什么的，售后都没这么热情，这我还没买呢！就这样，有问题吧！大家给看看': array([0.], dtype=float32),\n",
       " '还找我，我的天，销售这么执着真是行业的典范！我的妈，传销过来的吧！': array([0.], dtype=float32),\n",
       " '太能说了，可见在八戒工作压力有多大': array([1.], dtype=float32),\n",
       " '机制太垃圾  不公正 只知道捞金  不请个顾问 你还想发的出需求 被看到，做梦了': array([0.], dtype=float32),\n",
       " '推销很正常，慢慢就习惯了，拒绝他就行，实在不行就拉黑呗': array([0.], dtype=float32),\n",
       " '为什么别人敢得罪你，因为你太简单，心眼很少，手段不高，人又不坏。': array([0.], dtype=float32),\n",
       " '越是说好话的人，别人越是得寸进尺，越是不计较的人，别人越是变本加厉，好人被欺，善人被弃。': array([1.], dtype=float32),\n",
       " '元宵将至，祝吧友们团团圆圆！和和美美！顺顺利利！': array([1.], dtype=float32),\n",
       " '元宵节到了！朋友，我对你的思念，就像这元宵一样，塞得鼓鼓的，捏得圆圆的，煮在锅里沸了，盛在碗里满了，含在嘴里，呀，太甜了！元宵快乐': array([1.], dtype=float32),\n",
       " '我在猪八戒，服务全世界。': array([0.], dtype=float32),\n",
       " '有点不太实际': array([0.], dtype=float32),\n",
       " '很实际': array([0.], dtype=float32),\n",
       " '这么多钱都托管了。到时间拿不到东西，楼主还是不要找什么协助了。直接申请退款。解除合约吧。': array([0.], dtype=float32),\n",
       " '心里简直拔凉拔凉的      办各类的证件,跑的时间,交际方面的开销,租的办公室等等,都以经超出了这些钱,到头来项目没能交付,钱不退,我的要求也不高既然没能按要求出就退还本金,      以经在预算中,如果这个月内退不了钱,直接起诉': array([0.], dtype=float32),\n",
       " '希望楼主能获得自己应得利益': array([0.], dtype=float32),\n",
       " '希望楼主早日能拿到自己的钱钱，坑爹的猪八戒': array([0.], dtype=float32),\n",
       " '我也是这样被骗的！加入我们一起维权吧！372907959': array([0.], dtype=float32),\n",
       " '我也是这样被骗的！加入我们一起维权吧！qq群：372907959': array([0.], dtype=float32),\n",
       " '猪八戒大部分收益都来源于服务商缴纳的服务费！所以人家向着服务商能说啥': array([0.], dtype=float32),\n",
       " '再也不要相信猪八戒这种垃圾平台，服务商水平不到位，做东西拖时间，还有猪八戒平台售后拖拖拉拉的，上辈子倒了血霉，为什么会相信了猪八戒在他这里做东西。': array([0.], dtype=float32),\n",
       " '变得**都不如，老是欺骗消费者。愿这间公司的骗人员工活不过2018': array([0.], dtype=float32),\n",
       " '坑啊': array([0.], dtype=float32),\n",
       " '怎么写完就没啊，是不是给我删了？？？': array([0.], dtype=float32),\n",
       " '众包这块会员不出售了，天天说悬赏上线，都说了大半年，不想做投标': array([0.], dtype=float32),\n",
       " '收分账 太高了': array([0.], dtype=float32),\n",
       " '哎、一个字失望': array([0.], dtype=float32),\n",
       " '曾经在猪八戒上发起服务交易，后面没有选到合适的标，联系网站方称不能退款，帮你选到合适的为止，就跟在中介交了中介费找房子一个道理，大家千万不要轻信承诺': array([0.], dtype=float32),\n",
       " '猪八戒网真TM坑啊，来找我提供资金与技术支持。年末人手紧张，想搞一波的速度': array([1.], dtype=float32),\n",
       " '猪八戒网现在个人还能发布需求不？像图片这种的。设定多少人一人多少钱的这种？好久没用了找不到发布的地方😭': array([0.], dtype=float32),\n",
       " '既然贴吧 就此成立 就应该有官方出来解决 上当人的问题！ 企业要做持久 售后是必须的！！！': array([0.], dtype=float32),\n",
       " '这个吧 肯定是 猪八戒网 相关人员在运营！ 请你们引起重视！！！': array([0.], dtype=float32),\n",
       " '虽然 我并没有在猪八戒 下订单以及被骗  但 这是人民的名义！！！': array([0.], dtype=float32),\n",
       " '我在猪八戒的微博提建议，他们居然吧我拉黑，不能评论了。这种企业迟早倒闭。': array([0.], dtype=float32),\n",
       " '我已经被猪八戒网骗了2万多': array([0.], dtype=float32),\n",
       " '应该被骗过的 集结到一起 群体反应！一个人 一家公司这样反应 毕竟力量太小': array([0.], dtype=float32),\n",
       " '其实这个社会是冷漠的 自己的问题 可以解决的相关单位太少': array([0.], dtype=float32),\n",
       " '看到大家被骗 真的想 干死 这些骗子！！': array([0.], dtype=float32),\n",
       " '我看猪八戒贴吧 反应被骗问题的客户 很多！ 但是 真正集结在一起去找这个公司的很少啊！ 人多力量大啊！': array([0.], dtype=float32),\n",
       " '哈哈 完美周末的开始 从一顿火锅开始': array([1.], dtype=float32),\n",
       " '人生在世 谁能不被骗': array([0.], dtype=float32),\n",
       " '猪八戒 的问题 这个贴吧里 全都再说 却没有真正集结一起解决的~ 大家是并没有那么想解决的吗': array([0.], dtype=float32),\n",
       " '被骗事件 没得到解决 心里每天都 堵堵堵': array([0.], dtype=float32),\n",
       " '我今天也被骗了！！！猪八戒真是太垃圾了，一点规则没有，一点保障都没有！！最气人的是骗子骗完我拉黑我之后用别的号给我发了封邮件！还他妈劝我长点心！！握草气死我了简直': array([0.], dtype=float32),\n",
       " '我并不是猪八戒的受害者 但是 我愿意集结大家一起来解决问题！': array([0.], dtype=float32),\n",
       " '八戒的本性 难道大家都忘了吗？哦，不对，是这种问题太多了，根本不怕开水烫、。刚被骗 太可恨': array([0.], dtype=float32),\n",
       " '政府部门应该管管，坑人太多了': array([0.], dtype=float32),\n",
       " '被骗的是大家 没人愿意集体解决 我更是无所谓咯': array([0.], dtype=float32),\n",
       " '我的天呐': array([1.], dtype=float32),\n",
       " '猪八戒是国内最大的在线服务平台了，你说哪个好呢～': array([0.], dtype=float32),\n",
       " '只能举报了，太坑了，': array([0.], dtype=float32),\n",
       " '取不出来的，太坑了，设计的都是什么玩意啊，系统还自动帮我评论了作品很好！': array([0.], dtype=float32),\n",
       " '以前那个保险模式还是不错的~现在直接让交钱，有点不能接受。不交吧~不买会员吧 20%的分账也太高了！！': array([0.], dtype=float32),\n",
       " '猪八戒是个什么网站，签了合同一点不保证我们的接单量，我就很不理解，就是那个对接我们公司的产品经理离职了竟然不通知我们，好歹也得找个人来接替一下啊！！！！难道我们每年花那么多钱就是买的这种服务？？？？？？': array([0.], dtype=float32),\n",
       " '哈哈，猪八戒浪费青春。': array([0.], dtype=float32),\n",
       " '这个吧的吧主不知道是不是猪八戒网的管理人。在你们网发的需求，但是质量有点差了，给郑州新风向代运营，一个月十单，没效果不说，还带欺诈，现在电话不接，公司座机与个人都联系不上。还是希望你们网上商家能信誉一点': array([0.], dtype=float32),\n",
       " '猪八戒就是一垃圾平台，和重庆地区的服务商沆瀣一气，不管消费者列举多少证据，就是一句话，他们不负责这，不负责那！劝大家小心这垃圾平台！': array([0.], dtype=float32),\n",
       " '同为普通服务商每天只能看到那几个悬赏，每天如此，现在连app都把悬赏取消了辣鸡网站还要收20％平台费，特么怎么不上天啊，是要封杀普通服务商吗': array([0.], dtype=float32),\n",
       " '几年前才加入的时候，还觉得不错，虽然抽成20%，觉得勉强还可以接受，毕竟网站要运营嘛。现在再看看，尼玛各种级别的保证金啊，各种级别的VIP啊，各种花样要钱各种剥削。尼玛让小服务商怎么活。退出算了。': array([1.], dtype=float32),\n",
       " '我也这么觉得啊，活不下去啦，找别的工作啦~~~': array([0.], dtype=float32),\n",
       " '猪八戒会员买不出去了、半价了、真恶心': array([0.], dtype=float32),\n",
       " '垃圾平台': array([0.], dtype=float32),\n",
       " '辛辛苦苦做的东西雇主根本看不到，而且并不知道为啥会被淘汰，为了不被淘汰，买了那个众包个人会员，但依然没有卵用，一天十五个稿件，对那种认认真真来做的个人来说，15个根本做不完，坑啊~~~': array([0.], dtype=float32),\n",
       " '我在上面干了多年的老威客 已经选择离开了': array([0.], dtype=float32),\n",
       " '我对猪八戒网站选稿的人员的能力表示质疑。要是猪八戒吧这些负责筛选稿件人的，个人相片和履历都公布出来。我觉得可信度还高点。别让一群不会绘画的人去选稿件。虽然感觉猪八戒会干的出这样的事情。毕竟，平台的游戏规则是它定的。别人只能接受霸王条款。要不就闪人。': array([0.], dtype=float32),\n",
       " '感觉猪网是要做死的节奏，简直就是一个只想敛财的无良商家，三天两头的改模式，把一众服务商逼的无路可走，现在搞什么众包，根本就是不把服务商的劳动成果当一回事，就是这样非会员连这10元20元的还难挣到，这样下去迟早有一天服务商和雇主都会不满意，最终不知这贪得无厌的猪又会整什么新样花来！最近我已开始不在猪网头标了，已另寻出路，目前在一品威客和时间财富网，各位前辈不知有没有好的靠谱威客网站介绍下': array([0.], dtype=float32),\n",
       " '确实作死，我旁敲侧击过其他加入什么金牌，银牌，八戒通....好多服务商，都反应交了钱就给你些没品质的散单应付你，累得要死还赚不到钱，现在不同的客服不停的打又要加入什么众包，费用更高，都是坑你没商量，我目前有几单正在交易中不让扯资（就是原创保证雇主保证金），等交易完后申请要回保证金，和这头猪就要拜拜了！': array([0.], dtype=float32),\n",
       " '从14年底开始，猪头的各种不充值“保证金”就不能交稿完全可以看出，它加快了融资的步伐。大家都不交的话，可能还好些：可是一旦它尝到甜头了，就会变本加厉了!它既然有胆量怎么做，得到众多威客的口水话，还在于它业务量的庞大，一副店大欺客的嘴脸！看看现在几万个未选标任务和屈指可数的的几个新任务，大家作何感想？水能载舟，也能覆舟；猪网玩得太过，毫无人性化可言，从宽厚平和向势利苛刻蜕变，脱离了更多中小威客的支持和厚爱，关门大吉也就指日可待了。': array([1.], dtype=float32),\n",
       " '看了大家的吐槽才知道原来不只我一个不爽猪八戒，做了三年了，越来越坑，也是想放弃了': array([0.], dtype=float32),\n",
       " '顶一下，感觉以后威客会慢慢发展成一种固定工作模式。而且这个时间的到来会很快。因为感觉文化等数字化升级非常快。信息的更新也是。所以觉得威客会成为以后人们个人寻求发展一种新产能方式。就跟播客一样。不同的是在传播和发展平台不同，发展的载体不一样罢了。': array([1.], dtype=float32),\n",
       " '让自己多些经历，别贪图安逸和享受': array([0.], dtype=float32),\n",
       " '而猪八戒，以前也是打着免费的旗号，让威客蜂拥而至，要知道，免费的话，平台直接就是亏本的，但是推手能多赚很多的，但是，做着做着，就开始店铺收费，不买店铺的，就很难接到单，有店铺的，一年辛辛苦苦，大部分也就只能赚到店铺费用，也让很多的威客心灰意冷！很多推手转战线下，但是又有一个问题，线下的雇主，基本都很皮，被骗也在所难免，虽然不骗钱，但是，很多需要花钱让别人做，亏一次，也够自己累活半个月的，可以说，现在的威客，不管是新手还是老手，都是活在了水生火热之中，自己有满身的能耐，确有无从下手，漠然离开自己喜爱的威客赚钱行列！': array([0.], dtype=float32),\n",
       " '说实话，我也是上面说的其中一个，13年的时候，赶上了猪八戒大潮，那时候，QQ群任务超级多，我自己那时候有1000多个QQ群，那时候加群也不限制，而且QQ也不会那么多问题，每天指着这群，都能赚100~300元，加上一些其他任务，那时候一个月赚万把来块钱，很是轻松，而且那时候猪八戒也很棒，各方面服务很到位，后面，又到了三打哈，几个平台一起做，那一两年，真实无比滋润，活的精彩呀！好景不长，后面平台都慢慢不好做了，知道前段时间，三打哈突然关闭，我里面还有600多元在里面没提现出来，找客服，客服总是说服务器被攻击，在维护，遥遥无期！心灰意冷，直到我一个以前一起做威客的朋友告诉我，他发现一个叫”黄蜂兼客吧”的威客平台，这个平台有四点好处：': array([0.], dtype=float32),\n",
       " '没加入前，业务员各种承诺：1.永远不收佣金，现在变个说法你必须交！2.不用交保证金，不交的后果是干预成交！3.保证在地方上做各种地推（楼宇广告、dm推广），除了几次招服务商的培训会，一片纸都没投放过！4.所谓的88节第一年坑了广大服务商，今年更是搞得屎一样。.....做为店销平台，不把重点放在引流上，而是想尽一切办法和手段坑服务商的钱！1.不分轻重，一个规定就直接把你保证金扣完。存在严重的自己裁决自己现象。自己风控举报，然后自己直接判定服务商败诉！': array([0.], dtype=float32),\n",
       " '别再说朝令夊改了！众包产品已运行接近一年了，从没见改过！坑爹的事儿绝不会轻易改的！': array([0.], dtype=float32),\n",
       " '猪网自打成立之起就一直在挖坑，从不埋坑，需要自己来埋、来跳！那些不会埋坑和跳不过去的，就只能掉坑里了！号称3600万服务商，如果不挖坑的话，估计这个数字早过就亿了！': array([0.], dtype=float32),\n",
       " '我没拍之前 问一句回一句！ 拍了之后没声了！ 我去他们八戒交易平台 说QQ跟我说 QQ一直没声，不回复 我是第一次在八戒网上交易！ 谁不慌了！ 180虽然不多 也是钱！ 我就退单了！ 退了单就开始说话了！ 啥也别说了！': array([0.], dtype=float32),\n",
       " '举报他们线下交易就好了，叫我雷锋': array([0.], dtype=float32),\n",
       " '这个要给举报了，猪八戒肯定封它的号，而且最近猪八戒升级了一次。服务商要缴纳押金了。也就是各种保障金。不然何种任务有一部分不能参与投标。这对雇主是中保障。': array([0.], dtype=float32),\n",
       " '以后别上猪八戒。坑死人不偿命': array([0.], dtype=float32),\n",
       " '猪八戒网很坑的，注册也收费，还要押金。没提供任何服务就要收取费用，可惜我们国家的网警是摆设，放在别的地方，早就被查封不知多少次了。': array([0.], dtype=float32),\n",
       " '猪八戒的服务，不管是对威客，还是对商家，都是像钱看，我感觉这样的平台很叫人寒心！': array([0.], dtype=float32),\n",
       " '我不知道你们为什么要喷八戒？八戒的项目不够好吗？收的钱还不够少吗？客服态度不够好吗？我的项目在八戒上就运行的不错，才被坑10来万而已！': array([0.], dtype=float32),\n",
       " '楼主说得很多，八戒做得很好，你看到坑你只是表象、暂时的，坑着坑着你就习惯了。': array([0.], dtype=float32),\n",
       " '首先感谢一下猪八戒。这些年，威客的变化，就是单子的价格，慢慢上去了，这还得归功猪八戒，这是好事，价格上去了，才会有，有实力的设计师加入进来，才会提升和优化这个行业。才会给这个行业尊严。做设计的都知道，做一个标志，其实远远没有想象中的那么简单。像以前一样，一个标志两百元，就算是真正有实力的设计师，谁他妈想给你做，做了谁他妈想给你改？？客户还觉得，我他妈花了两百元，还得不到一个好的标志？？这就形成了个恶性循环，设计师不想好好做设计，投出来的东西越来越槽糕，客户不想做花钱，因为花钱也得不到多好的东西。前些天，其他网站，有个任务下，有条留言，大意是，一个新的设计师，看到有个任务，做了，才注册，结果发现，才注册的不能提交稿件，他就抱怨，要不是最近真的手头紧也不会来这种平台跟那些街边打印店设计师抢活。我也在那些专业设计公司工作过，专业设计公司里面，对威客这个行业，就在存在这前几年的认知，觉得都是低价，可笑，不屑一顾，上面的设计师，都是街边打印店的水准。感谢猪八戒对这个行业的价格，所有改善。虽然距离专业设计公司，一个标志，动辄十几万甚至几十万的价格，还差了天远，但是，再小进步也是进步。那为什么又希望猪八戒垮掉？难道不应该是双方合作，互利互惠么？因为猪八戒一次次伤害中小型服务商的心，一次次损害中小型服务商的利益（大型的不知道，就不说了，毛主席说过，没有调查就没有发言权）我对这个平台和这个平台的未来，完全不抱任何期待。是人都会犯错，错个三四次、五六次都可以原谅，如果一直错，并且没有任何悔改，任何的进步，反而变本加厉，那么一定是这个人的本性有问题。陈浩南说过，每个人都会做错事，但不要做坏事。猪八戒就不是做错事，是做坏事。任何行业都是先来的有肉吃，后来的屎都抢不到吃的。猪八戒起步早，又渐渐拉到不少投资，；理所当然的成了龙头老大，有了客户流量，有流量就是有一切，（举个例子，你去一线城市人多的地方摆个地摊，同等资源下，一天的收入，绝对比你在一个小县城开门市要赚得多）哪怕我强硬，哪怕我欺诈，走了一个你，还有千千万万个你，更不用说，随着流量而来的，也有优质的设计师，真正为客户做了不少好单子的。但是我相信，随便换个公司来来做龙头老大，威客的行业，都比现在要成熟和完善许许多多。猪八戒C轮融资后，开始飘飘然起来，为了上市，更是不择手段变本加厉的捞钱。客户花了钱，没有得到理想的稿件，服务商花了钱，也没有得到应有的客户流量。有人说，猪八戒如果成功上市，上市之后，会重新整顿平台。只要平台还在，流失一些客户也无所谓。对于这个说法，首先我个人的看法有如下两点1、猪八戒根本不值得我信任了。即使上市，即使整顿，中小型服务商，也只是以另一种形式作为炮灰出现。2、帝国都有垮掉的时候，更不用说一个公司，一个还在发展中的公司，如今的种种作为，真的是自取灭亡。那我为什么希望这个网站垮掉，仅仅是因为心里不痛快，过过嘴瘾？非也，如今猪八戒占据着整个市场80%的流量，只有猪八戒垮掉了，流量释放出去了，其他企业崛起了，把这个行业做好了，做成熟了，才能看到这个行业真正的希望，服务商与平台才能真正的互利互惠。一个好的市场，好的平台，应该是包罗万象的。比如淘宝，有大型电商，也有小店铺，大型电商当然能赚钱，小店铺，哪怕做为一个兼职，业余打理一下也能赚钱。而不是像猪八戒一样，中小型服务商做为炮灰，生存艰难，或者根本没有生存的空间。最后，说一下我的威客历史。我是2010年开始接触威客的，当时还没毕业，是我们老师给推荐的，推荐的是威客中国（现时间财富）在威客中国上，做了几笔单子后，发现单子有点少，这时候就找到了猪八戒。然后从2010年到2014年，断断续续，在做威客，有时候是兼职，有时候是全职。我在猪八戒做的单子最多的。2014年中旬开始，猪八戒就开始翻天覆地的改动，感觉到不给他们交钱的话，我的投入和产出就不划算了，就彻底放弃了做威客，不久之后，我认识的一些全职威客也放弃了猪八戒。去上了班。2017年，6月，辞职在家，因为有些事，暂时不打算去上班，重新抄起了威客行业。发现一些变化，写下一些心得': array([1.], dtype=float32),\n",
       " '猪网一时半会儿可垮不掉的！因为国情在这儿。中国互联网公司没什么发展力和创新力的，看看抄袭界老大疼讯的市值和排名就明白这个道理了。猪网虽然非常垃圾，但其他网站就不垃圾吗？就有创新力和潜力吗？现实是并没有！非但没有，而且在模式上还照抄照抄猪网的模式，甚至连缺陷bug都一并抄袭！都说中国慢慢崛起了，这名话如果用在威客网上，那绝对就是一个玩笑！': array([0.], dtype=float32),\n",
       " '看来，猪八戒是不能玩了。刚接触的时候，我还幻想着能赚个小钱花花。现在看来，不能这么干了～再见了！（老猪的客服给我打了可多电话，让我交会费，做会员啥的，我都不干，希望以后的人也不要干！）': array([0.], dtype=float32),\n",
       " '就没有个正经的威客网吗？偌大个中国，就没有个正经的威客网吗？我～！～！～！～！～！～！～！～！～！～！～！～！～！～！': array([0.], dtype=float32),\n",
       " '本来网络平台就存在太多的不确定性，得抱着游击战的心态，一旦得手就赶紧抽身，可不能跟他们耗着。做了几年的威客，各种要求买服务的电话自然少不了，且不论真假如何，单单交了钱能不能得到回报就存在很大的疑问，到现在来，外省电话一律不接不听了，除了中标的客户。': array([0.], dtype=float32),\n",
       " '八戒大坑': array([1.], dtype=float32),\n",
       " '一个三四年前在猪八戒投标的设计稿件，发现给人投标用了。算是盗用吧？连一丝山寨修改都没有，是一个才刚注册的服务商号。结果去举报都给举报证据不足，驳回了。那个盗用作品的，竟然还反咬一口，骂恶意举报。这样的事情怎么弄。主要是猪八戒近几年的改版，以前的参与交易数据都没有了。无法查找截图。是不是这样就没办法解决了啊？': array([0.], dtype=float32),\n",
       " '怎么反馈？那么多的骗子。。。济南弘海网络科技公司 看公司网站弄的那么好 操 原来也是骗子 还有另外一个人 QQ没在了 昨天被骗了三百': array([0.], dtype=float32),\n",
       " '永远是这个.............你绝对联系不上客服': array([0.], dtype=float32),\n",
       " '每周24*7在线一直是前面超过一百人': array([0.], dtype=float32),\n",
       " '以前的账号，进不去了，而且不让密码找回，客服找不到。': array([0.], dtype=float32),\n",
       " '艹，什么玩意！！！！什么公平？？ 我在一个竞标中，被恶意举报，扣除了信用分，竞标的内容被删除了，本来一点破分也无所谓，只是弄得心情很郁闷，不过是弄不清楚做的哪家的任务了，发了两条竞标方案，却被恶意举报我举报那个恶意举报我的人，却又被扣除了信用分！！！你们审核的有没有认真审核过？本来分数也无所谓，可弄得心情很差，打算继续玩下去的，现在看来，只能呵呵了里面的钱不多，我也不要了你们这样弄下去，我只能呵呵了也没什么公平可言！！！投诉无门': array([0.], dtype=float32),\n",
       " 'MD猪八戒垃圾网站，处理不公，蛇鼠一窝，判垃圾骗子胜诉，我发布的投标任务，骗子虚假交稿，我不合格加举报，他也举报我，进而举证判定，我上传了N项证据可以证明那人多次行骗，结果什么垃圾委员会还是判骗子胜，真是垃圾和垃圾蛇鼠一窝，这种网站不上也罢': array([0.], dtype=float32),\n",
       " '我举报  博阳创意（9月7日改为 正翔科技） 被驳回，说是证据不足。这个人  是重庆的，电话号码是重庆的， 改名后资料又改为黑龙江的。有多个QQ  微信，加别人，首先就问 做了任务怎么给钱。接了任务后，先给一张草图，叫别人选他中标 然后再给完美的图。选中标后，就不太好联系了，随意弄几张 图片拿来糊弄。就结束了，完工了，要求再修改，言辞很好，态度很好，然后马上就把你删掉，QQ，微信，全部删掉，联系不到了。还说发布任务的是骗子，骗他的图。在猪八戒上投诉了，被驳回。心里冤屈没有地方申诉。图片没选到好的，钱也没有了。如果猪八戒上面，都是这样操作，还有谁去发布任务呢？还有谁敢用猪八戒？': array([0.], dtype=float32),\n",
       " '我在猪八戒网发布需求。。系统判定违规给关闭了，关闭也行。把钱给我返回来呀。这都3 . 4天了。钱没回来，什么破客服就是个空摆设。根本不说话。难道说我这钱就打水漂了不成': array([0.], dtype=float32),\n",
       " '猪八戒网站不知道有什么BUG,左上角的消息通知一直闪，没有消息它也闪，就那个信封一样的图标！': array([0.], dtype=float32),\n",
       " '我就在那个标那里问了这么一句话，就是多次提交？还是那小子胜诉？你再看看那sb投诉了多少人！！！还有一大堆不止这些，他就投诉其他什么都没干，这样都行？': array([0.], dtype=float32),\n",
       " '能不收那么高的平台费吗?辛辛苦苦的做任务还要那么高的平台费，体现、服务商一扣根本就没钱了~': array([0.], dtype=float32),\n",
       " '实名认证不了': array([0.], dtype=float32),\n",
       " '我想取消我的任务！行吗？没人做，已经沉了，估计没人看见了': array([0.], dtype=float32),\n",
       " '猪八戒客户端的发布任务bug让我损失310元 同样是一模一样的计件任务 单价1元数量5个  用手机客户端发布以后就变成单价5元需求数量1   而用网页登录猪八戒网发布同样的任务后 则不会出现这种情况': array([0.], dtype=float32),\n",
       " '我认为猪八戒网对投标商收取的手续费太高了，而且除去手续费还要扣除税款，而且提现也要手续费。我接了800元的单子到手就600，即使我知道猪八戒靠收取手续费维持运行，这个数额未免也太大了，你们有没有考虑过这样会流失客户什么的？我的建议是尽量降低扣率什么的，保障投标商的收入。我所想说的就这么多，请问你们会关注并改进吗？': array([0.], dtype=float32),\n",
       " '这世道骗子防不胜防呀！': array([0.], dtype=float32),\n",
       " '投诉又有何意义？正想投诉的一些问题发现早有人在去年就投诉过了，眼看2015年就要来了，有用吗，投诉了你们有去解决吗，就在这里回复我们威客有意思吗？！': array([0.], dtype=float32),\n",
       " '猪八戒网为什么要求服务商交保证金，保证金能退吗？': array([0.], dtype=float32),\n",
       " '个人觉得，那么多线下都是猪八戒逼的，佣金那么高': array([0.], dtype=float32),\n",
       " '猪八戒迟早把自己坐死，服务商搞些垃圾新手做案子，不合格还有脸要钱，真他妈的蛇鼠一家。找的一个大连公司，没有缴费前打电话一个一个催你付款，付完款就不管了，然后说是我的责任。大家一定要谨慎，不要在在这里找了': array([0.], dtype=float32),\n",
       " '猪八戒网，地地道道的骗子网站，蛇鼠一窝，请大家一定要搽亮眼睛看清楚，猪八戒的真面目。猪八戒和服务商串通一气，欺骗雇主。所以这样的网站大家不上为好。我已经在这个平台上交了血淋淋的学费了，被抓八戒骗的伤心至极，在中国这样的骗子网站竟然能够一直活下来。希望其它的朋友引以为戒，远离骗子不要再上当受骗。猪八戒的创始人，如果你还没有死，请尽快处理我们这些用的的投诉。你门平台上处理投诉的人和你们说是一伙的骗子。就是它们创始人  蛇鼠一窝猪八戒网创始人兼CEO朱明跃   大家看看像不像大骗子网站的舵主。': array([0.], dtype=float32),\n",
       " '服务商一个，打电话过去，全都是不知道，不是我点的，手机不是我的，打错电话了，各种都有': array([0.], dtype=float32),\n",
       " '各种描述不清楚，我有想法，我考虑考虑，还有明显就是假的，描述乱写一通，这都能贴出来坑人': array([0.], dtype=float32),\n",
       " '办会员时候说的是不再收取任何费用，现在每个订单扣款2%说的是保障完成，我们按时完成了，客户也满意了，为什么还扣？扣的钱去哪了？': array([1.], dtype=float32),\n",
       " '这个保单写着保障中，是不是可以理解为，过了时间期，保障金就退还给服务商了呢？？谁知道？？？': array([0.], dtype=float32),\n",
       " '做大了自然就不要脸了，你这还好啊，我店铺开发一个游戏几万块，这2%收的那酸爽': array([0.], dtype=float32),\n",
       " '同问，都过了1个多月了，还是显示保障中！这不是明显的扣住保障金不退嘛，下次接项目再也不走猪八戒了！': array([0.], dtype=float32),\n",
       " '有没有在猪八戒网被坑过的各种小伙伴 ，鉴于对方公司一直不处理，我觉得 大家可以考虑集体的去维权，单独的一个一个的电话，他们的客服就是各种推诿，各种去反应，然后就是不给你处理。有没有人愿意提供证据之类的 ，我们可以具体去维权。': array([1.], dtype=float32),\n",
       " '有被众包骗的吗，集合下': array([0.], dtype=float32),\n",
       " '这家骗子公司大家一定要看清了': array([0.], dtype=float32),\n",
       " '猪八戒网上骗子横行，猪八戒网不负责任无人管，投诉无门。集体维权群：372907959': array([0.], dtype=float32),\n",
       " '猪八戒不刷单不可能上去的，被发现找律师起诉猪八戒': array([0.], dtype=float32),\n",
       " '有，我也是受骗的！太坑人了！40天工期！做了快五个月还没做好！！！！！平台到现在也没结果！': array([0.], dtype=float32),\n",
       " '确实，猪八戒在这点上真的不能跟大大神比': array([0.], dtype=float32),\n",
       " '没办法，店大骗客，纯骗子，都不讲诚信了这网站，看来就是骗钱卷钱，不想发展下去了': array([0.], dtype=float32),\n",
       " '怎么办啊！咋们服务商被它骗的团团转，咱们又比较分散，怎么才能制裁这样的***': array([0.], dtype=float32),\n",
       " '一个人 5000 元。你妹的，融资': array([0.], dtype=float32),\n",
       " '不要个比脸': array([0.], dtype=float32),\n",
       " '5000到50000确实太贵了  这就是变相让服务商自己走嘛！然后好把你交了的钱名正言顺的收到自己的钱包里': array([0.], dtype=float32),\n",
       " '我是一个猪八戒的服务商，至于是哪家的，我就不说了，不过我今天想说的是，猪八戒的服务商真的很傻很天真，有时候明明给你们说的实在价，不相信，就想占便宜，最后被骗了，就在这里说猪八戒的不好，你们自己傻还要怪社会了，占小便宜的有几个能好的，几百就想做网站，那你还去猪八戒干嘛，还不如去网上自己去自建，': array([0.], dtype=float32),\n",
       " '人傻不能怪社会，天真不能怪平台，自己傻，就该去多学习一下。': array([0.], dtype=float32),\n",
       " '说真的，不少雇主都已经在Z网吃亏了。Z网上的价格比市场价低那么多，还有人能接，我想不出是些神马公司！几千块一个APP？反正我们是接不了的，所以猪八戒这条线早就放弃了。一个程序员有经验的，一个月1w工资，不算高，那么给你开发个APP少说一个月周期，你几千块钱一个程序员的工资都不够好么？而且你以为一个APP就一个程序员在开发么？真的，自己找线下实体公司吧，欢迎广州的雇主来咨询我司Q 1244393005，或上门谈谈需求。异地雇主我们也接，只要雇主那边不介意不是同个地方就好。': array([0.], dtype=float32),\n",
       " '这种价格开发网站？？？？？居然还有公司接、？然后又怪服务商坑！这种价格接的想都不用想 好么，百分之90骗子，剩下百分之十开发出来后期问题你不知道还要再花多少！': array([0.], dtype=float32),\n",
       " '这个贴吧，猪八戒的人就不看一下吗？全是维权的，可见猪八戒骗人不轻呀': array([0.], dtype=float32),\n",
       " '猪八戒网是骗子！怎么维权！': array([0.], dtype=float32),\n",
       " '及时审核稿件 不拖欠': array([0.], dtype=float32),\n",
       " '远离猪网吧，越改越垃圾。我现在已经不怎么做了，有主动联系的接个，没 有就拉倒。': array([0.], dtype=float32),\n",
       " '可以给重庆市政府信箱写信投诉猪八戒这个诈骗网站': array([0.], dtype=float32),\n",
       " '合着猪八戒员工还有创意审稿的任务 天天就那么俩破任务 还瞎得瑟': array([0.], dtype=float32),\n",
       " '不错的项目，新兴行业，自用省钱，推广赚钱，不用投资一分钱，日入几百，找人，一起努力做，愿意的来，': array([1.], dtype=float32),\n",
       " '猪八戒到底怎么样啊，老板想入住猪八戒的那个综合设计专场，让我这边先了解一下情况，请各位吧友指导一下呗': array([0.], dtype=float32),\n",
       " '劝楼主暂时还是观望一下的好。感觉最近，猪八戒任务大厅发布新的任务少了很多。相比较以前。': array([0.], dtype=float32),\n",
       " '天天给我打电话，加会员，张口就是几千上万的，呵呵，我在你们平台好像挣了什么钱似的': array([0.], dtype=float32),\n",
       " '先不要买会员，我是八月份买的悬赏高级版，那时加上派单一个月会员费就能回来了，现在每天做众包算是咬着牙做，越做越没信心，所以等完善了再买会员吧': array([1.], dtype=float32),\n",
       " '只看见骂声一片': array([0.], dtype=float32),\n",
       " '不能说不好，但是为什么不选择最好的。只有经历过才知道好不好。还是多出去体验，可以参加事了了的活动来了解一下事了了。': array([1.], dtype=float32),\n",
       " '猪八戒论坛也是这样，说不好的，都给删帖。论坛也是一片吵闹。': array([0.], dtype=float32),\n",
       " '垃圾猪八戒 都去百度口碑曝光它们！': array([0.], dtype=float32),\n",
       " '猪八戒网站会员费很高，所以暂不说有没有效果，还没赚到钱就花一堆钱，那样还不如线下接单安全稳心点。不过很多个平台都在接单，希望能够接的多一点吧。但是就是麻烦了。最近看有个新平台叫：接单多，反正是免费的，就像威客搜索引擎似的，什么平台的任务都有。还有个接单管理系统，在别的地方是没见过的。用的还不错，主要是免费就够了。省的又被坑一堆钱=w=': array([0.], dtype=float32),\n",
       " '这个垃圾网站吃枣药丸，坑人的': array([0.], dtype=float32),\n",
       " '已打算退出了，超级大坑': array([0.], dtype=float32),\n",
       " '猪八戒离倒闭不远了，有钱的赶紧都提出来，有1元提1元': array([0.], dtype=float32),\n",
       " '20个稿件只中了5个，其他的还没通知，天天盼啊念啊，原来任务早结束了': array([1.], dtype=float32),\n",
       " '猪八戒贴子内的评论全是吐槽众包的，猪八戒全部删除，现在直接关闭主题评论了，真是笑死了': array([0.], dtype=float32),\n",
       " '系统选搞入围之后就有保底创意费，听起来不错，所以我回归了，没想到这比以前还坑，因为你没买高级会员的话，你的稿件可能要好几天才见到客户，或许干脆见不到客户就给淘汰了。我操他大爷的': array([1.], dtype=float32),\n",
       " '今天认真做的稿子又被系统淘汰了，雇主看都没看到。问猪八戒工作人员，为何把我的稿件淘汰，他说综合评分不够；问他什么是综合评分，他说 ，你不是高级会员，然后活跃度不够，，， 我真日他大爷的。。。': array([0.], dtype=float32),\n",
       " '说得好.现在网站真的垃圾的很...而且不是一般的黑....': array([0.], dtype=float32),\n",
       " '现在搞个屁，以前计件只收取百分之20，现在收取百分之24，今天居然一元的任务到手只有毛9，半个月没有做到以前3天的任务量，都混不下去了。': array([0.], dtype=float32),\n",
       " '感觉猪八戒LOGO设计专场，应该竞争很激烈。我投两三次猪八戒众包的。基本都中赏了。不过，感觉这个创意费给的限定的有点低。毕竟普通会员收20%费用的。60一单，才赚48。成手快的一天发三单，才赚144，这还是顺利的。一个月按30天算，就赚4320元。要是一单48的扣20%赚38.4元。感觉差距不少。这还不主要问题。主要感觉中赏的稿件。雇主没原始文件。创意稿雇主也是能用的吧？可以随便使用吗？不能吧。没版权。也就是，最坑的是雇主了。中赏的稿件，还可以二次出售的。毕竟没出售版权。': array([0.], dtype=float32),\n",
       " '众包，已再无希望，心死，我失业啦': array([0.], dtype=float32),\n",
       " '对的，他们就是忽悠人，本来订单没有几个，但是不停的让人开会员，最后只能是人多没饭吃，而且中赏率很低，本人已经在猪八戒四年了，之前都是做悬赏，虽然收20%佣金，但是可以理解，毕竟平台要运营，但是众包推出了，还得交最低4800的费用，一天投标15个，一周中标一个，等你买会员以后，隔两三月给你更改规则，到时坑你没商量，这种就是骗子公司，玩儿的是文字游戏！今年推出了各种通，八戒通，悬赏通，众包会员，性质都一样，真正挣钱的没几个，个人观点，同意顶起，不喜欢勿喷': array([0.], dtype=float32),\n",
       " '谁能出来灭了这家骗子公司，太他么恶心了': array([0.], dtype=float32),\n",
       " '自己作死，快过年了，过年要挨刀啊': array([0.], dtype=float32),\n",
       " '买了高级会员的可以哭了，只能怪自己太年轻，把世界想得太美好': array([0.], dtype=float32),\n",
       " '猪八戒做的太杂不专业看看“八百威客”只做电商垂直类平台': array([0.], dtype=float32),\n",
       " '就我六年的威客生涯接触的大批老客户基本都选择了离开猪八戒，这个网站发展到上市之后开始跑偏，悲哀的竟然开始行骗的营销套路，基本一直是在往绝路上走。': array([0.], dtype=float32),\n",
       " '网站想要操纵交易捞钱，结果服务商饿死了，雇主吓跑了……': array([0.], dtype=float32),\n",
       " '事实他比悬赏模式更坑爹。系统从几百个稿了筛选出几十个。嗯。看似很美好。第一对服务商来说，比悬赏还坑爹。他要过系统选稿，雇主都没看过就淘汰了，凭什么。第二对商家来说，比悬赏还坑爹，他要过系统选稿，然后你也不知道他排除的是好是坏。第三，对高级会员（RMB玩家）来说不坑爹，系统默认先选高级会员（RMB玩家）稿件第四，对高级会员来说坑爹，因为任务量很快就会变少了，你还赚不回本。第五，最后只有网站笑了第六，宠物小猴子哪里有卖http://www.houzi668.com': array([0.], dtype=float32),\n",
       " '猪八戒网这个骗子公司，当时他们销售员说购买八戒通会送3个月等我付款了，就说抱歉活动做完了不能送了，***真是能忽悠人': array([0.], dtype=float32),\n",
       " '投诉没毛用，直接上CQZF公众信箱写信，慢是慢了点，但都能退': array([0.], dtype=float32),\n",
       " '猪八戒的口碑怎么样？在网上能随便搜出一大片负面新闻，可惜楼主没注意啊，因为马云做平台挺不错，就理所当然认为猪八戒也差不多，可是楼主真天真了，真的低估了猪的胃口，猪为了那点粮可以说是毫无底线，所幸楼主保留了通话录音，所以决定对猪八戒发起诉讼。有同样诉求的伙伴们一起来吧，让我们集体诉讼，把事情搞大，曝光猪八戒的真是嘴脸。我们的外包合同是11号到期，但是看证据，对方12号还在修改一个功能，已经涉嫌逾期违约，我三叔是西北政法大学毕业的法院系统，在所有材料交给他看后认为对方已经构成违约，但猪八戒睁眼说瞎话认定对方完成开发，真可笑，一个功能多次出现bug的软件也叫完成开发？上图': array([0.], dtype=float32),\n",
       " '刚才猪八戒不经允许操作我的账户付款，这算不算侵犯别人财产安全呢？所以，有软件外包的同行，不懂得IT的一定要睁大眼睛，哪怕在本地找个靠谱的程序员或者软件公司开发，也要慎用猪八戒，切记啊': array([0.], dtype=float32),\n",
       " '有要维权的朋友留个联系方式吧，我们一起维权，人多力量大，一起曝光猪八戒，有同样诉求的朋友可以联系我哦，我的QQ346301534': array([1.], dtype=float32),\n",
       " '这个网站确实恶心，我也发了个需求。完全没人做，18号发的，在24号提交了53个但完全没有按我的要求来的。全瞎搞的，估计是网站自己乱搞的': array([0.], dtype=float32),\n",
       " '你自己发个帖子我语气有什么吗？猪八戒是我开的？你说话厉害死了吧。不会好好说人话是吧。你上当了？你受骗了？即使你受骗了我是猪八戒的老总吗？那么多服务商，有骗子就都是，骗子是吧？服务商是猪八戒的员工吗？有的只不过是接个兼职养活自己。有几个骗子然后都是骗子是吧？猪八戒看偏袒服务商是吧？有哪个店铺没经历过幸幸苦苦写完了，最后客户不给尾款？被骗了就去维权。大家一起想办法。你咋了？不是人就他妈不会说人话是吧': array([0.], dtype=float32),\n",
       " '大家都是在这有问题找解决办法的，****在这乱咬人。爷还就不给你脸了': array([0.], dtype=float32),\n",
       " '我觉得说的很在理。就像我说的，有几个是骗子你不能说所有的服务商都是骗子': array([0.], dtype=float32),\n",
       " '可能都觉得服务商发帖少抱怨的少，都觉得偏袒服务商。反正我是遇到过熬夜写了几天代码，最后让付款雇主一直不付款直接扣走我代码。': array([0.], dtype=float32),\n",
       " '选服务商的时候慎重点，多看几家，好歹你也能比比价，签合同的时候要求分阶段付款，完成一阶段你觉得没问题在去确认付款那一阶段的款。': array([1.], dtype=float32),\n",
       " '别还没给代码就提前给款。': array([0.], dtype=float32),\n",
       " '垃圾猪八戒': array([0.], dtype=float32),\n",
       " '刚开了八戒通，店铺没运营起来的。  别在那闲着了。    回收店铺Q.Q： 4.5.1.4.8.1.6': array([0.], dtype=float32),\n",
       " '今天早上就接到了那个客服打电话来说我店铺没装修，没人看，让我开个3600多的店铺装修。本来想着交了多接几单能赚回来，毕竟一年嘛。本来是没什么疑问的，就是她一直打电话来催我交钱，我就上了贴吧看看，，才发现是骗人的，还好没上当，感谢贴吧。另外有人需要设计或者网页之类的么，或者工业建模之类的都行、。。。。或者有什么好平台也可。另外问问淘宝开设计店怎么样': array([0.], dtype=float32),\n",
       " '我也是猪八戒的威客，实话说，猪八戒现在是越来越让人失望了': array([0.], dtype=float32),\n",
       " '钱是丢的不多,但是TMD太可怕了啊,猪7戒都有在骗定金的..平台可信度在哪里?有什么说什么,本案我也有错,直接支付宝了钱...': array([0.], dtype=float32),\n",
       " '私下付款风险很大，最好还是通过平台担保。不过八戒抽成太厉害了。': array([0.], dtype=float32),\n",
       " '垃圾猪八戒，服务太差了！': array([0.], dtype=float32),\n",
       " '我是猪八戒的一个小服务商，并不是什么高级会员，也不是什么多大的公司。我和两个小伙伴只是想自己做做试试。但是我发现，刚开始的做的店铺是没人去访问的，没有开钻石皇冠的浏览量远没有开那些的多。很多个说猪八戒没有好的服务商，都是骗子，其实还是有的，只不过我们可能成交量少，但是我们不刷单去提高我们的销量。选择服务商去多看她们的评价。回头客多的也去看下他们的案例。多看看几家。现在的市场我也不想说什么，价格简直被同行弄的太恶心了，一个页面竟然还有30一页的，时间工作量在那放着，价钱低也不会去付出太多的经历。现在的猪八戒什么水平的都有，才学会前端的就去接活，价钱还低的离谱。我已经不想说啥了。现在就是好的技术遇不到好的客户，好的客户遇不到好的技术。': array([0.], dtype=float32),\n",
       " '30块钱一页只会做烂市场，做烂平台，自己花费了时间还赚不到钱': array([0.], dtype=float32),\n",
       " '被骗人真的多！': array([0.], dtype=float32),\n",
       " '猪都没人管了，广告贴一大堆': array([1.], dtype=float32),\n",
       " '不知道什么时候才能取消猪八戒众包？？不知道什么时候才能取消猪八戒众包？？不知道什么时候才能取消猪八戒众包？？因为猪八戒众包太垃圾了。。。。': array([0.], dtype=float32),\n",
       " '猪网说实话真的挺垃圾的，但就是没人能干得过他！猪网的长处其他威客网无法企及！猪网的短处其他威客网又都视而不见，想和猪网竞争我估计比超越米国都难！': array([0.], dtype=float32),\n",
       " '猪八戒霸王条款，保障完成，每个单扣2%。': array([1.], dtype=float32),\n",
       " '属于强制的，无语了。': array([0.], dtype=float32),\n",
       " '交了保证金 还要扣2%，，这样早晚被别的网站干掉': array([0.], dtype=float32),\n",
       " '被骗过的把qq发一下，我们组织个群，我这有证据，我们一起整理，告猪八戒网！同意的点赞！': array([0.], dtype=float32),\n",
       " '这是怎么了，猪八戒网好像最近有点坑啊': array([0.], dtype=float32),\n",
       " '猪八戒众包就是个骗子谁开谁倒霉': array([0.], dtype=float32),\n",
       " '个人认为不会值，骗创意的太多了，中标的感觉都是托。。。。内定了。有单他自己不做吗？招几个人来不就行了。': array([0.], dtype=float32),\n",
       " '确实坑了很多人，还不能退钱': array([0.], dtype=float32),\n",
       " '当时一看要一万的会费，稿费还那么低，我就直接放弃了，想不通居然还有人去买这会员': array([0.], dtype=float32),\n",
       " '众包这么垃圾........': array([0.], dtype=float32),\n",
       " '众包这个概念被八戒玩坏了': array([1.], dtype=float32),\n",
       " '刚才发现雇主保障要到期了，一点进去才发现。。。涨价了。。，那些吃比稿的人一年得交780.。。，这是限定最低的价格，以前保证原创是三个月是15块 1000保额，保证完成是三个月30 1000保证金，现在原创涨成三个月45，3000保额（限定最低），，保证完成是三个月150 5000保证金（限定最低），不知道还和等级有关系没有。': array([1.], dtype=float32),\n",
       " '有没有发现，一旦众包出售一个版权，后面几天稿件使劲给BAN。。然后才恢复正常，这众包就是根据等级人为在限制收入。': array([0.], dtype=float32),\n",
       " '猪八戒网当初说什么钻石服务商，后面有一对一的扶持，有什么百万服务商成长计划，公司有专人负责。还会免费宣传店铺。这些都是卵的。 收了会员费4万元后，后续的服务根本跟不上，而且网站本身；流量很差，派单基本全是无关痛痒，毫不对口的垃圾单。很多好点的业务，都被内部派单人员截取，私派给关系好的服务商，缺乏公平公证。 本人还是重庆本地服务商，对猪八戒这种服务真的是无语。猪八戒十年的短片拍摄，开始喊我们服务商投标，写方案。积极联系之后，后面工作人员说老板给了熟人电视台一个记者做。网站一点信誉都没有，这么多服务商花钱成为会员，自己的业务都不找自己的服务商，太黑了。 浪费大家的创意和精力！': array([0.], dtype=float32),\n",
       " '希望各位被坑的吧友，大家可以冷静下来，大家一起去想办法。同时希望猪八戒网吧在负面消息爆满时不要只会偷偷的谁 帖子！': array([0.], dtype=float32),\n",
       " '大家买毕设的注意骗子啊，前几天就被这个家伙骗了，虽然只有100多，也是自己的不够谨慎！买毕设的时候这个骗子说有做过类似的，看着价格便宜就买了。17758249312电话号码是这个。下面是支付宝帐号。大家都小心点【图片】': array([0.], dtype=float32),\n",
       " '也是自己傻，贪图小便宜了': array([0.], dtype=float32),\n",
       " '妈蛋，原来是骗子，差点上当了': array([0.], dtype=float32),\n",
       " '大家买毕设的注意骗子啊，': array([0.], dtype=float32),\n",
       " '可耻': array([1.], dtype=float32),\n",
       " '早就已经退坑了。猪八戒上面服务商很多都是3流的，说实在的。还有些服务商是把东西外包': array([0.], dtype=float32),\n",
       " '好久没上去做了，什么保证原创保证完成，钱交就交了。结果泥马才做了五个，就无法投稿了。这是什么荒唐无耻的设置？原来我兴致来了，一下午可以搞30稿。现在一天才5稿，妈蛋，白瞎了我二个烧鸡钱。还有那什么八戒通，据说要3600，呵呵，真是见钱眼开狮子大开口啊，就让专职高手们去做吧。照这个趋势发展下去，以后指不定还会搞出什么新的搜刮民脂民膏的制度来。此情此景让吾等草民不寒而栗，只能退避三舍，先行告退了。': array([1.], dtype=float32),\n",
       " '猪八戒辣鸡': array([0.], dtype=float32),\n",
       " '建议别再里面做了，价格低而且还会被网站扣掉很多': array([0.], dtype=float32),\n",
       " '我也觉得是这样，网站稍微做大了点就开始圈钱了，以前还好，现在各种各样的门槛，计划，光实名还没用，他们的重心是让服务商开店，开了店网站收入就多了。总之，在服务商没有赚到钱之前先得一笔，赚到钱后再敲一笔。划不来就坚决不去做': array([0.], dtype=float32),\n",
       " '不加会员，基本没什么收益。八戒这就是圈钱运动': array([0.], dtype=float32),\n",
       " '比稿的东西从来不玩，浪费精力': array([0.], dtype=float32),\n",
       " '现在把原来积攒的猪几戒 也给消除了 变法儿 想榨钱 真垃圾': array([0.], dtype=float32),\n",
       " '早已脱坑，我现在都去创品客，他们不管你入驻先后、等级高低，全一视同仁，都可以接所有的单子': array([1.], dtype=float32),\n",
       " '看到的，哪个存了那几个图的，给我发个呗，谢谢了。发那个图的大神看到回个我呗。': array([0.], dtype=float32),\n",
       " '猪八戒网还有那么多过期未定标的任务，几时处理，可别再糊弄大家了！': array([0.], dtype=float32),\n",
       " '本人自去年5月7日通过猪八戒平台与平台上的服务商（暂且隐去此公司的名字） 签订了开发一个小网站的服务合同。开发商答应1个月交稿，但一直到10月份都没有交稿，而且还在我通讯不方便的时候把款给划走了，我2周后发现，随后开始了通过猪八戒平台的追诉，一直到了2017年5月2日，猪八戒官方服务给出了以下答复：【你好先生，这个款项服务商不同意退还平台最终建 你们寻求法律援助，去起诉服务商。】虽然钱不多，但是我要追求一个说法回顾以下：2016年10月18日服务商提现，我一周后发现了服务商把钱申请走了，就在猪八戒发起了维权，2016-10-28日猪八戒回信称我手机停机，因工作变故，留在平台的手机确实关机了，但我还有邮件。这么大的平台只发站内消息，我们留的邮箱没有接收到任何一封有平台发出的服务提醒。2016年11月7日等待无果，继续申诉，提交了与服务商技术们的聊天记录。2016年12月12日没有得到答复，继续提交申诉中间打了无数个电话2017-02-15终于等来了一个客服用私人QQ邮箱回复了一封邮件，让我给他回电话，因为我接听电话不方便。一番诉求后了毫无音讯，一等就是一个月，中间也不知打过几次电话了。2017年-03-15日发邮件询问进展。2017-03-20日回复说 “一周内给结果”2017-04-11日再次询问进展，没有回复2017-04-25日再次询问进展，依然没有回复以上过程中，打电话无数（记不清打多少次电话了）后来有个猪八戒纠纷处理人给我主动联系了，但在最后的回复中让我自己去拿起法律的武器（或许没有错），那你平台是干什么的？ 我曾与这位服务人员举例淘宝客服的经验，用服务商的保证金保护在猪八戒平台上的消费者，他们不以为然（或许是真的我错了，对不起！不该这么对比）我诉求很简单：猪八戒是个服务平台也是个仲裁员，根据我们双方提供的证据，谁对谁错，一目了然，给个公平的评判。不要说服务商不同意退款就交代了，已经收到了的钱，我也不会同意吐出去，但关键是拿了钱没办事。先啰嗦这么多。。。': array([0.], dtype=float32),\n",
       " '猪八戒真的不靠谱 我也是受害者 这个平台在处理纠纷时有严重的倾向性，倾向对服务商有力的判决': array([0.], dtype=float32),\n",
       " '骗子网站如果能够听得进去别人的建议就不叫骗子了!说到建议，有多少雇主、服务商是磨破了嘴皮子而最终失望又绝望的!!!': array([0.], dtype=float32),\n",
       " '很久没去猪网了，前段时间无聊了了，进去一看，多了一个所谓“”八戒通“的东西，但是要通过是有条件的。右边是让回答一大堆不知所云的所谓考试题目，其实就是猪网的各种坑人的手段，可以把人搞精神分裂的那种；不回答也可以，左边选项叫交钱！！！呵呵，堂堂一个所谓中国最大的威客网站就是这样一幅恬不知耻的嘴脸！所谓众包“，我没有去趟这个浑水，但是看大家的反应，就是交了大把的银子得不到回报，从而怨声载道的；要我说，这个便宜还真不是那么容易到手，有这样的单子，人家为什么不去找几个关系户关起门来做呢？': array([0.], dtype=float32),\n",
       " '猪八戒网内部把高质量的任务都放到后台，让我们必须交钱才提供对接，就不能统一放到前台大家一起公平竞争吗，这么做看不出来是大平台的所为': array([0.], dtype=float32),\n",
       " '那你们岂不是都接不到好的单子，叫你们交多少钱才会给你高质量的任务': array([0.], dtype=float32),\n",
       " '开始不知道，现在用了才知道全是骗子，平台和服务商是一伙的。': array([0.], dtype=float32),\n",
       " '猪八戒上都是骗子，被骗了平台也不管，看来只能认栽了。搜搜百度知道，一堆被骗不知道怎么办的。': array([0.], dtype=float32),\n",
       " '等级在八戒以下的，哪怕是高级会员，无论怎样交稿基本都不会获赏的:无论提交多少数量的稿件，提交多有质量的稿件!就是这类服务商，被猪网坑得最惨!但猪网当初推销时可不管你是什么级别或信用，只要是人，就向你推销，逮住一个算一个，半夜11点甚至更晚都能给你打电话，骗子嘴脸暴露无遗!': array([0.], dtype=float32),\n",
       " '要死不活和死有什么区别吗？三月收入4500够吃还是够喝呢？不算房租费、交交电话费、电费、水费、网费，还能剩下几个子？!而且猪网统计的收入时间段偏长，三月收入其实按正常生活期是4-5个月，一个设计师四个月四千的收入该怎么形容呢？真不如去做零工甚至是卖煎饼果子来钱呢？!好多中小服务商就是因此被迫转行了啊！现在全世界都在努力脱贫减贫，但猪网却在靠骗术制造失业拉仇恨!为了圈钱不择手段，什么招都敢用!还就是没人能管!': array([0.], dtype=float32),\n",
       " '从清明开始众包这块大厅任务明显没以前更新的多了，而且选稿件也没有以前及时都是拖到最后一天随便选几个。高级会员的商机推送也开始乱七八糟的推送招标的项目。有个员工跟我说悬赏又要重做上线。众包肯定做不下去了，真特么恶心，变着花样作。': array([0.], dtype=float32),\n",
       " '我是高级会员，现在没有一个商机推送！前两天偶尔还有一两个，现在完全没有！虽说买了高级会员，但获赏率低得可怜，一天提交20稿左右，一个月下来最高收入1300，最低时400！这怎么让人生活！生存！鬼才知道他们是怎么个算法、分配规则！！': array([0.], dtype=float32),\n",
       " '1.悬赏是有消息说要上了。2.年中有个报表做出来给股东看的，所以改版圈钱老套路。3.电话轰炸即将到来。': array([0.], dtype=float32),\n",
       " '本人在zbj上开了个店铺，做品牌设计方面，现在不知道如何开始需求大厅里有比稿的，这个我知道 还有招标的，这个先不说一堆认证保障门，投标就像滴滴打车一样，还得给雇主打电话，真烦，雇主都很不耐烦的关闭交易 所以招标这条路基本没法做请问还有什么办法可以接单吗 我不想花钱加什么会员 只想从0开始 难道只能做比稿了吗 请各位能赚到钱的高人指点一下 应该怎么开始做': array([0.], dtype=float32),\n",
       " '醉了，哈哈哈哈': array([1.], dtype=float32),\n",
       " '让重庆的号自己去响吧，不接他的。接了就是不停的给你洗脑，然给你入会员。': array([1.], dtype=float32),\n",
       " '过年给我两次电话了，第一次没接，第二次接了直接说我不会购买会员的': array([1.], dtype=float32),\n",
       " '刚刚给一个客服骂了。。。吗的。。再打我就报警': array([0.], dtype=float32),\n",
       " '我们这在南宁开了没几天，就开始打电话，大概说的意思就是我们公司的订单是线下拉到线上操作的，有可能刷单，风控部会查。如果交钱办了钻石店铺，我们就有保障了。来公司谈的领导是个东北人，我是东北人，不是黑，真的是一股流氓气。。然后也没办，但是最近店铺从前五页展示7.8个服务到现在只展示1.2个，，不知道是不是分公司搞鬼，没事客服还是打电话说这个会那个会的。': array([0.], dtype=float32),\n",
       " '大家知道吗？猪八戒网是中国最大的骗子俱乐部！': array([0.], dtype=float32),\n",
       " '我被猪八戒骗了11000元，怎么去告他们？谁知道？': array([0.], dtype=float32),\n",
       " '骗一万就别想要了!还不够起诉费、律师费还有什么保全费的呢！死猪就是看准了这一点才肆无忌惮地诈骗呢！': array([0.], dtype=float32),\n",
       " '不按合同办事欺骗我们当初协商好的功能一样没做，而且服务商提供的app是已经开发好的APP，对接人员在协商过程删减功能坐地起价！': array([0.], dtype=float32),\n",
       " '他要不骗你就不是猪了！': array([0.], dtype=float32),\n",
       " '哈哈，感觉自己受骗，应该看看': array([1.], dtype=float32),\n",
       " '牙快笑掉了。猪八戒还能编得更离谱点么？': array([0.], dtype=float32),\n",
       " '还有那些被猪八戒吹出来几个顶级服务商，都是猪八戒后台帮他们改数据的，阿里巴巴朋友做数据库架构的，他们的刷单IP都是指向重庆一台电脑硬盘Ip，三个月3千万一个店铺收入都是假的，猪八戒是为上市造势帮几个服务商后台刷单。服务商也很乐意，因为有吹牛行骗的本钱。半年前我看他们店铺收入400多万倒有可信度。还有各种骗会员收了钱又限制服务的。真是奇葩公司。又想从牛身上挤奶又不让牛吃草，限制牛吃多少草。服务商挣不到钱。猪八戒能好过？猪八戒吃相真的太难看。到处骗别人加会员。还有众包更是骗，还限制了普通和个人价格300元和800元的档，你限制了个人价格，高级会员定价就上不去，最多也就2500元左右。远远不如比稿。比稿至少有高价，雇主直接看。众包是猪八戒电脑和人工筛选的。普通的基本不会让你过，个人的通过率20%。钱交的越多通过创意的概率就越多。第二道关才给雇主看。这也是客服自己说的。也许是说漏嘴了。太黑了。': array([1.], dtype=float32),\n",
       " '我迷失了方向': array([1.], dtype=float32),\n",
       " '捞钱无下限的坑爹网站': array([0.], dtype=float32),\n",
       " '谁买会员谁是傻子，纯粹给网站当苦力，连本钱都回不来': array([0.], dtype=float32),\n",
       " '不论什么任务，项目，接触客户环节第一步，就要求把合约先签订了，不要为了拿到该任务就按客户说的，给先修改看看，完了再说。这样是不行的。最近进出一个客户，就是这么样。结果修改了，完善了，辅助图做了，表情包弄了。发给客户一看。客户一看失踪了。没联系了。也不说明情况。去信问询，也不给回复！然后，再去任务下面一看，别人出售版权了。这个说明什么。1，服务商自己***大意了。2，急于求成了。3，太早放心了。4，该客户本就没想诚信诚心的交易。存在骗稿潜力。5，总结，不论什么交易任务，第一沟通一定要把合约先定下来。定了在给修改完善。': array([0.], dtype=float32),\n",
       " '我也是被骗稿了': array([0.], dtype=float32),\n",
       " '楼主说的恶略现象估计会有。但是感觉不多吧？？不过，就俺参与的驻扎的综合专场，感觉出现的任务确实少了很多很多。以前都没人抢，都参与不过来。如今就众包，也要间隔3四天出来一两个新任务。结果，中赏的基本都是高级金银服务商。没普通服务商。': array([0.], dtype=float32),\n",
       " '听你这样说我都不敢买八戒通了，一年5600，感觉是个坑啊，可能连本都赚不回来，但是真的没那么多任务吗？': array([0.], dtype=float32),\n",
       " '大家去问下律师、法院和公安部门，众包绝对是利用虚假广告诈骗会员费的行为，推销时说一个月至少27000，尼玛最牛逼的服务商拼了命也赚不到27000，还有什么每日兼职两小时，轻松月入5000元，哪个服务商达到这水平了？这不是虚假广告是啥？不是诈骗是啥？这些广告现在为啥都没有了？不见了？只不过受骗的服务商作为个人拿猪网无办法算了，个人想起诉或立案来对付猪，比登天还难！如果是集体诉讼或什么的，或许还有些效果！': array([0.], dtype=float32),\n",
       " '从清明开始，综合设计这块好像稿件都不怎么选，要么就草草了事，这是什么情块，雇主都粗投诉吗？': array([0.], dtype=float32),\n",
       " '八戒众包这套营销方案是搞烂了，去小鱼儿网看看吧。': array([0.], dtype=float32),\n",
       " '刚去LOGO专场看了一个选稿的任务，大家都看看，按截图是能看见中赏金的稿件。没一个符合任务要求的，人家卡户要求的是绿色为主，看看这个三个能看见的稿件。没一个主色调是绿色的。这说明，猪八戒选稿是公平的，大家都靠运气，看谁的活跃度高，级别的，谁就拿赏金了。至于版权就算了。服务商和客户都没沾便宜。': array([0.], dtype=float32),\n",
       " '看来，众包服务真的有待改进啊。客户也不是没有意见的啊~~作为服务商，心里感到欣慰，不光是自己掉坑里，挨坑啊': array([0.], dtype=float32),\n",
       " '还可以吧，不是你发悬赏，他们投标么': array([0.], dtype=float32),\n",
       " '本人曾因猪八戒与客户结缘，在后续合作期间，客户反馈：经常接到猪八戒服务商骚扰电话（介绍业务）。一、经客服反馈：该服务商隶属于猪八戒自营服务商。Q：在任何人不知情的情况下，猪八戒既做运动员（自营服务商），又做裁判员（任务中介平台）。这行为不是垄断行为？入驻服务商利益如何得到保障？二、一般而言，进驻服务商需：入驻-投标-联系客户。而猪八戒自营服务商利用自身优势（掌握全部客户信息），无需入驻，无需在平台投标单，即可私自联系客户。经询问，却被客服告知该前述行为猪八戒内部流程，无需对外告知服务商/雇主Q：在任何人不知情系统且平台未有任何投标痕迹的前提下，猪八戒自营服务商私下骚扰客户，严重损害入驻服务商，侵犯公平交易权利。经对质，客服还振振有此解释道：这逻辑正常，无需-如此不公平、不公正的暗箱操作行为，简直令人恶心、发指。再退一万步而言，猪八戒如此劣迹斑斑，恐怕平台内全部客户信息早已被对外泄露、被贩卖盈利-未经同意而侵犯个人信息的行为，不是刑事犯罪吗？So真心求解，难道猪八戒就可以如此无法无天？': array([0.], dtype=float32),\n",
       " '这是坑雇主和服务商，不是看作品是看会员级别，他们知道服务商的审美和想法？猪八戒就是贪得无厌的骗子': array([0.], dtype=float32),\n",
       " '我在猪八戒，服务全世界！猪八戒网欢迎你的加入～': array([0.], dtype=float32),\n",
       " '我也是90后创业，自己公司做技术开发，项目没收到尾款，还有17万': array([0.], dtype=float32),\n",
       " '猪八戒网这个平台还是很好的': array([0.], dtype=float32),\n",
       " '我在猪八戒，服务全世界！猪八戒网欢迎你的加入': array([0.], dtype=float32),\n",
       " '最近想开始在八戒众包上接些单来做。不过做了1个礼拜之后发现自己的稿件都没有通过审核，跟客服沟通之后对方的意思是一定要加入高级会员才能通过审核... 想请问一下有付款购买会员的朋友，是否都有通过审核？经过这次事件实在觉得猪八戒这个平台黑箱很多，可是又找不到其他更好的平台...': array([0.], dtype=float32),\n",
       " '我就是高级会员，中标率低的吓人，绝对是坑，千万别买': array([0.], dtype=float32),\n",
       " '我是一名设计师，因为大学时用过猪八戒网，印象还可以，再加上销售员的不实承诺，就购买了高级会员9800元。现在已经发现被骗了！！！原本我买的猪八戒网---高级悬赏会员，他网站会派单子给我做。11月份不经过我同意，强硬把我改为众包会员，众包会员服务非常差，我没接到一个单子，所以要求退出退钱，猪八戒QQ服务员说不退，后来被问的多了，也不理我，再后来说辞职了。打猪八戒投诉电话，客服小妹一直说：会向相关人员转达。可是现在已经3个月了，也没收到猪八戒人员的一个电话。打的次数多了，直接挂断。非常窝火，窝火，有时候真想骂她，想想她也只是个打工的，就强压下怒火。可是，猪八戒其他人员，一直不露头，这样的情况，可怎么办才好呢？求大神出个主意': array([0.], dtype=float32),\n",
       " '在他那累死也赚不到几个钱，': array([0.], dtype=float32),\n",
       " '在猪八戒接了个单，为了便于理解，翻译为生活场景：雇主说我要买苹果（这是任务需求），接下来我接单自然要和客户确定买多少苹果多少钱一斤这些，对吧，结果那人付了一斤苹果的价钱然后要拿走我整个摊位的苹果，理由是她发的任务是买苹果而且付过钱了（是不是很熟悉，电影里黑社会就这样，明显的强盗逻辑，对吧）。强盗很常见，倒也没什么值得说的，问题在于我申请维权时猪八戒网维权平台工作人员竟然讲同样的逻辑，这就很难让人接受了，因为这已经有点反社会逻辑了。尤其之后我提供了非常详实的证据之后，他们的工作人员竟然说我单方面证据无效，而他们维权平台是双方都可以提交证据的。整个维权过程就好像  检察院提交了足以判嫌犯死刑的证据后，法官出于私利在法庭公然说检察院单方面证据无效。我个人认为这很反人类。一个服务交易平台，完全不讲诚信和公平，当下再好看，格局也有限。': array([1.], dtype=float32),\n",
       " '我还打算注册一个号在上面接活呢 看到这个 我犹豫了': array([1.], dtype=float32),\n",
       " '对猪八戒的会不会遭遇黑客黑，表示担忧啊！这程序员干活不细心啊。想知道，一共30个交稿机会，怎么交的，能有76个？翻一倍还多6次机会。服务商个个成黑客么？': array([0.], dtype=float32),\n",
       " '猪八戒网只在乎自己的客户量，但是客户质量并不是他们主打的，贴吧里好多讽刺他们这种业务行为的。': array([0.], dtype=float32),\n",
       " '不是威客不好做了，是威客越来越不靠谱了，我就被坑了一个多月时间，什么结果都没有试问还有人会去找威客做东西么？': array([0.], dtype=float32),\n",
       " '因人而异，好做的觉得越来越好做，不好做的觉得越来越难做': array([1.], dtype=float32),\n",
       " '我是做前端开发的 ，感觉不好做，迄今为止只接了一单': array([0.], dtype=float32),\n",
       " '平台垃圾': array([0.], dtype=float32),\n",
       " '感觉还好吧！': array([0.], dtype=float32),\n",
       " '没办法啊，会员多，单子少，导致竞争大。': array([1.], dtype=float32),\n",
       " '说白了还是有信誉的服务商越来越少，大多数只想着怎么拿单子，涨业绩了。别看什么千树艺点泽楷这些千万级的服务商多NB。潜规则了解吧？这些大服务商和猪网嘿嘿嘿的。现在猪网为什么很多服务商拿不到单子了？因为猪网有效单子里，百分之八十的单子集中在这四五家手里，剩余百分之二十，谁交钱多，派给谁。这就造成了，小服务商收钱不办事，大服务商不鸟你。平台也是只管拿钱不办人事。': array([0.], dtype=float32),\n",
       " '妈的，上次找人做微博推广，被骗了': array([0.], dtype=float32),\n",
       " '竞争加剧，什么行业都不好做，但你总归要活在这个世上。我知道一个网站，八百威客800vk.com，专业做电商威客的。新成立，很有前景！': array([0.], dtype=float32),\n",
       " '越改越恶心': array([0.], dtype=float32),\n",
       " '何必非要在他家网站上面做，我今年就换到了别家去了，比这个要好很多，人家也不乱收费什么的': array([0.], dtype=float32),\n",
       " '对此众包获赏的稿件无语了，这么垃圾的稿件给人家雇主，猪八戒这不仅仅是在圈钱了。简直是在抹黑猪八戒的众多服务商的设计质量。拉低服务商的设计能力。自毁城墙之举啊！对猪八戒众包的，人工审核员鉴赏和审核能力，深深报以质疑。': array([0.], dtype=float32),\n",
       " '我刚知道这个网站，看大家对他的评论不高，感觉好失望。猪八戒网吧究竟能不能做成功？': array([0.], dtype=float32),\n",
       " '这个抄袭的骗子叫“潜龙文丰”   买家不要上当。': array([0.], dtype=float32),\n",
       " '既然抄袭证据确琢，猪八戒你为什么不能明确告诉买家呢？如果买家明确说我不在乎抄袭，你可以把之前的任务要求搬出来啊，里面不是明确写着严禁抄袭吗？猪八戒你难道没一点正义感吗？为了所谓的利润完全不要道德底线？整个中国的创意人才被你们伤了一遍又一遍，流汗又流泪，你们真是要摧毁中国的创意产业吗？': array([0.], dtype=float32),\n",
       " '其实你中了，只不过那是他的小号。八戒虚假交易的太多了。': array([0.], dtype=float32),\n",
       " '我在猪八戒交易 线下俩天答应我  做不了不用付款  这句话大家说什么意思  可笑的是猪八戒上面的人解释是  不用付款不代表一分不用付款   大家别在猪八戒交易 给骗了1万什么都没得到  血的教训': array([0.], dtype=float32),\n",
       " '我是个写文案的，有活给我干吗？唉，越来越觉得这个世界黑暗了，为什么总有潜规则呢？': array([0.], dtype=float32),\n",
       " '千万不要写那些什么文案 logo之类的 人家看到明明好 也说不好 然后偷偷的弄': array([0.], dtype=float32),\n",
       " '这类骗稿很多。所以咱们服务商挑选任务时候，一定要谨慎。不要看任务价格高就投稿。我也遇上过。修改重设计，结果别人中标。事后也要检讨自己。太不谨慎。备选不行，最好是中标再给弄就好了。还有就是举报一定要在公示期时间内。出了就不行了。找猪八戒它是管不了的。公示期就是给大家举报监督的三天时间。': array([0.], dtype=float32),\n",
       " '以前的模式好多了': array([1.], dtype=float32),\n",
       " '个人觉得这存在漏洞，要是恶意站位呢。别人无法提交呢。毕竟猪审核稿件速度堪忧的啊': array([0.], dtype=float32),\n",
       " '我在想所谓的占位或许就是猪八戒内部操作自己的人投满，然后猪八戒通吃了稿费': array([0.], dtype=float32),\n",
       " '垃圾玩意 直接连稿件都发不上去了': array([0.], dtype=float32),\n",
       " '改不了版就不要改，已经告诉过你猪网了，技术力量薄弱，改不好、改不了！服不服！': array([0.], dtype=float32),\n",
       " '猪八戒真是这么删选稿件的吗？表示质疑啊！': array([0.], dtype=float32),\n",
       " '最近发布任务发现原来的计件任务没有了，突然改为众包模式，感觉很不方便。1 雇主不能随意定单价2 稿件居然是系统选的，也就是雇主连稿件都没见过就选上，有些任务需要雇主看后台记录才能确定合不合格，系统选的能保证符合雇主的需求？3服务商的门槛提高了，需要交会员费或参加考试。4 选稿倾向于高级会员，对于普通会员来说有点不公平，高级会员成了类似游戏中的人民币玩家。5 短期内，网站是最大赢家，可能会促进一些人交会员费，但这种雇主和服务商双输，不方便的模式没有进一步的改变，导致效率低下，有可能雇主和服务商会流失。大家对众包模式是怎么看的？': array([0.], dtype=float32),\n",
       " ...}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zbj_dic = {}\n",
    "i = zbj.values[0]\n",
    "zbj_dic[i[0]] = lstm_predict(i[0])[0]\n",
    "zbj_dic\n",
    "for i in zbj.values:\n",
    "   zbj_dic[i[0]] = lstm_predict(i[0])[0]\n",
    "zbj_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>八戒，陪你玩了7年了，感觉你现在眼里除了钱就是钱，我们像是被你锁在笼子里开膛破肚取胆汁的月熊...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>哎 现在想进入其实不是好时候了</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>打算进去做推广 看见现在这版面 直接退出了</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>猪八戒已经不是以前的猪八戒，唯利是图</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>是的..猪八戒现在就是个LJ...我也离开了...以前还是挺感激猪八戒的..也赚到了第一桶金...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1173</th>\n",
       "      <td>然后细心看了一下那个雇主的任务，所有交稿的人都不合格！！虽然没去看其他人的稿子有没有用过，但...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1174</th>\n",
       "      <td>我又看了看这个人的资料，他提出的需求中，别人交稿的基本上没几个是合格的。所以说，这个人骗人已...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1175</th>\n",
       "      <td>所以，建议大家在猪八戒做任务的时候注意一些无良雇主。第一，不要看着价格高点儿就做，有些时候很...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176</th>\n",
       "      <td>自言自语了这么多，说出来就舒坦些了。但愿对大家有些帮助，谨防骗子！！！</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1177</th>\n",
       "      <td>还是蛮多的，现在官方都在考虑雇主，却很少考虑到一些小服务商的利益，时间精力很多都白搭</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1178 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                content  label\n",
       "0     八戒，陪你玩了7年了，感觉你现在眼里除了钱就是钱，我们像是被你锁在笼子里开膛破肚取胆汁的月熊...      0\n",
       "1                                       哎 现在想进入其实不是好时候了      0\n",
       "2                                 打算进去做推广 看见现在这版面 直接退出了      0\n",
       "3                                    猪八戒已经不是以前的猪八戒，唯利是图      0\n",
       "4     是的..猪八戒现在就是个LJ...我也离开了...以前还是挺感激猪八戒的..也赚到了第一桶金...      0\n",
       "...                                                 ...    ...\n",
       "1173  然后细心看了一下那个雇主的任务，所有交稿的人都不合格！！虽然没去看其他人的稿子有没有用过，但...      0\n",
       "1174  我又看了看这个人的资料，他提出的需求中，别人交稿的基本上没几个是合格的。所以说，这个人骗人已...      0\n",
       "1175  所以，建议大家在猪八戒做任务的时候注意一些无良雇主。第一，不要看着价格高点儿就做，有些时候很...      0\n",
       "1176                自言自语了这么多，说出来就舒坦些了。但愿对大家有些帮助，谨防骗子！！！      0\n",
       "1177         还是蛮多的，现在官方都在考虑雇主，却很少考虑到一些小服务商的利益，时间精力很多都白搭      0\n",
       "\n",
       "[1178 rows x 2 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final = pd.DataFrame(zbj_dic.items(),columns=['content','label'])\n",
    "final['label'] = final['label'].astype(int)\n",
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.to_csv('../data/zbj_lstm_result.csv',index=False,encoding='gb18030')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
